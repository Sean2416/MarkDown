# Docker

## 基本概念

### Docker Daemon

- ###### Docker Client通过命令与Docker Damon通信，完成Docker相关操作。Daemon的主要功能包括镜像管理、镜像构建、REST API、身份验证、安全、核心网络以及编排。

### IMAGE

- ###### Docker 映像檔就是一個唯讀的模板

- ###### 例如：一個映像檔可以包含一個完整的 ubuntu 作業系統環境，裡面僅安裝了 Apache 或使用者需要的其它應用程式。

- ###### 映像檔可以用來建立 Docker 容器。

- ###### Docker 提供了一個很簡單的機制來建立映像檔或者更新現有的映像檔，使用者甚至可以直接從其他人那裡下載一個已經做好的映像檔來直接使用。

- ###### `docker rmi $(docker images -q)` 快速清除所有image


#### Build Image

- ```powershell
  # ImageName 需小寫
  # 須注意 Dockerfile 的路徑
  docker build -t [ImageName]:[Tag] -f [Dockerfile Name] .
  
  #1. 準備好DockerFile
  #2. 建立image
      # 啟動 Powershell 或 cmd
      # 移至專案 Dockerfile 所在位置的上層資料夾
      # 執行 Docker build 指令, 建立 Image, 參考指令如下
      # -t: Image 名稱及 Tag
      # -f: Dockerfile 檔案路徑
   注意：確保在名稱後面放置一個空格和句點 - 很容易錯過！
   
   docker build -t icw_biosecurity_api:latest -f .\ICW.BioSecurity.Api\Dockerfile .
    
  #OR直接到DockerFile那層
  
  docker build --build-arg DEPLOY_ENV=Stage  -t icw_biosecurity_api:latest .
  
  ```

- ##### 傳遞參數

  - ###### 使用`docker build` 命令中使用 `--build-arg` 選項

  - ```powershell
    docker build --build-arg DEPLOY_ENV=Stage -t image-hub.tutorabc.com/twm/clientserviceapis:Stage-master-20231215_1252 
    ```

  - ###### 在這個例子中，ASPNETCORE_ENVIRONMENT 環境變數的值將會被設定為建構時提供的 DEPLOY_ENV 的值

    - ###### 對應docker file裡面定義的參數 -   ARG DEPLOY_ENV

#### Tag

- ###### 在編譯的時候，適時的將 image 加上版號，並且保留上一版 (或幾版的) 的 image，當最新版本發生錯誤時，可以快速回滾。

- ```powershell
  # image name 後方加入 :{版號}
  docker build -t my-nginx:1.0.0 .
  
  docker run -d --name my-nginx -p 8080:80 my-nginx:1.0.0
  ```

  

------

### Container	

- ###### Docker 利用容器來執行應用

- ###### 容器是從映像檔建立的執行實例。它可以被啟動、開始、停止、刪除。每個容器都是相互隔離的、保證安全的平台。

- ###### 可以把容器看做是一個簡易版的 Linux 環境（包括root使用者權限、程式空間、使用者空間和網路空間等）和在其中執行的應用程式。

- ###### 映像檔是唯讀的，容器在啟動的時候建立一層可寫層作為最上層

- ###### `docker stop $(docker ps -aq)` 快速停止所有container

- ###### `docker rm $(docker ps -aq)` 快速清除所有container

- ##### 狀態

  - ###### Exited表示container暫時性地被關閉，並且不會在使用環境的任何資源，下次再啟動時，必須重新執行該container。
  
  - ###### Paused表示container暫時性地被暫停，但依舊會使用著環境資源(memories)，下次在unpause同時，會從上次暫停的地方繼續執行。
  
  - ![](https://ithelp.ithome.com.tw/upload/images/20200919/20129737XZeelnsEOj.png)
  

#### Run Container

- ```powershell
  # icw 代表Container Name
  # icw_cloud代表Image Name
  # -it: 啟動互動式容器
  # --rm: exit 後刪除 container
  # -p: Port 對應 [外部 IP]:[內部 IP] (可設立多個 mapping)
  # -d: 背景執行
  # docker run  -p  -d [外部 ip]: [內部 ip] --name [容器名稱] [RepositoryName]:[Tag]
  #-e 設定環境變數
  #-v 綁定Volume
  docker run -e "ASPNETCORE_ENVIRONMENT=Dev" -v "/log:/app/data" -d -p  9000:80 --name icw icw_biosecurity_api
  
  #使用已經建立的volumes:logs binding
  docker run -e "ASPNETCORE_ENVIRONMENT=Dev" -v logs:/app/data -d -p  9000:80 --name coupon coupon_api:1.0.0
  ```



------

### Registry

- ##### 將Image Push到Registry

  - ```powershell
    # login to docker hub (如果要 push 到 DockerHub, 若是 Private docker registry 則不需 login)
    docker login -u 帳號 -p 密碼
    # 將Image重新標註為上傳的Image檔案
    #確認 image 的前置詞需是自己的 docker user id (若是 Private docker registry 則需定義 domain ip 以及 Port)
    # ex. docker tag icw_cloud sean2416/docker-demo:latest
    docker tag [ImageName/ID] [DockerUserID]/[REPOSITORY_NAME]:[Tag]
    # push image to docker hub
    #docker push sean2416/docker-demo:latest
    docker push [DockerUserID]/[REPOSITORY_NAME]:[Tag]
    ```

  - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202206172150475.png)

- ##### Private registry 安裝

  - ##### crceate private registry

  ```powershell
  # 下載 registry image
  docker pull registry
  # 建立 container
  # ex: docker run --name [私人註冊庫名稱] -p [外部 IP]:[內部 IP] -v [實體檔案路徑]:[Container 路徑]
  docker run --name icw-registry --restart always -p 5000:5000 -v D:/docker/registry:/var/lib/registry -d registry
  
  # 建立 WebUI 管理介面
  # docker run -d -p 8080:8080 --name registry-web --link [Name] -e REGISTRY_URL=http://[IP]:5000/v2 hyper/docker-registry-web
  docker run -d -p 8080:8080 --name registry-web --link icw-registry -e REGISTRY_URL=http://192.168.1.177:5000/v2 hyper/docker-registry-web
  
  # 需開啟防火牆 Port: 5000, 8080
  ```

  ### 本機(開發)端設定 (錯誤訊息: server gave HTTP response to HTTPS client)

  * docker config 設定
    * 進入 Docker 的 settings. 選擇 Daemon.
    * 於 Insecure registries 新增 registry 的 ip:port
  * restart docker

- ##### 參考

  - [ 上傳 Docker Image 到 Docker Hub](https://ithelp.ithome.com.tw/articles/10192824)



------

### Volume

![img](https://myapollo.com.tw/images/docker-volumes/volume-types.png)

- ##### 在機器上產生一個實體的資料路徑，將對應目錄內的檔案同步到Volume目錄下

  - ###### Container的檔案在Container移除時會跟著消失，如果想要保存則使用Volume產生對應關聯將檔案持久化保存

  - ###### 重新啟動Container後，若Volume對應設定不變的情況下原先的檔案及內容都會同步回Container中

  - ###### 使用情境: API 內的Log紀錄需要永久保存，可以透過Volume達成

- ##### 啟用方式

  - ###### 啟動container時給定 `-v`參數: `docker run -ti -v "/dev/log:/dev/log" .....`

    - ###### 這邊建立的是bind mount，不會出現在docker Volumes內

  - ###### docker run -it -v myvolume:/data nginx /bin/bash

    - ###### 這邊產生的是mount，對應到docker內的volumes

    - `docker volume create logs`

  - ######  docker compose 時在yml設定

    - ```yaml
      version: '3'
      #在機器上設定Volume空間進行持久化保存
      volumes:
          mongo-mount-data:
      services:
        cliApi:
          build:
            context: .
            dockerfile: Dockerfile  
          environment:
           - ASPNETCORE_ENVIRONMENT=Dev
          image: clientservice-api  
          container_name: clientserviceapi
          restart: always
          ports:
            - "9000:80"
            - "9010:443"
          volumes:
          	#將Container內檔案對應的路徑map到上方宣告的volume
            - mongo-mount-data:/app/data
      ```

      

- ##### Docker實現Volume的原理

  - ###### Volume: Container將Volume存放在Docker area，以Linux來說預設為Var/lib/docker/volume。

  - ###### BindMount: 可以為主機路徑下任何地方。

  - ###### tmpfsMount:主機的memory。
  
    

------

### Docker File

- #####  `YAML` 格式的純文字檔，由許多命令所組成。而這些命令就是在描述產生 Image 所需要的內容和要做的事情。

#### 指令

- ##### FROM

  - ######  以哪個 Image 做為基底進行修改

- ##### WORKDIR

  - ###### 設定當前工作目錄

  - ###### Docker 會將當前的工作目錄移到指定的目錄下，若是沒有這個目錄則會自動建立一個。這裡的工作目錄是指 Image 的目錄不是本機專案下的目錄。

- ##### RUN

  - ###### 執行命令，可以是安裝軟體、建立檔案和目錄或是建立環境設定等等。

  - 透過`&& \ `可以連接多個指令

- ##### COPY

  - ###### 複製來源的目錄或是文件到 Image 中的目錄下

  - `COPY [SourcePath, TargetPath]`

- ##### ADD

  - ###### 除了等同於 COPY 的複製功能，還可以複製 URL 規格的檔案及解壓縮檔案。

- ##### ENV

  - ###### 設定環境變數

  - ```yaml
    ENV <key> <value>
    ENV <key>=<value>
    
    ENV k1 v1
    ENV k2 v2
    ENV k3 v4 k4 v4
    
    ENV k5=v5
    ENV k6=v6 k7=v7
    
    #環境變數可以透過 docker inspect 來查看，也可以在啟動 Container 時使用 --env 或 -e 修改，
    docker run --env <key>=<value> -e <key>=<value>
    ```

- ##### ARG

  - ###### 宣告建置 Image 時要使用的參數

  - ###### `ARG` 和 `ENV` 功能非常相似，都可以設定變數，但是差別在於 `ARG` 只提供在建置 Image 時使用，而 `ENV` 還可以在後續建立起來的 Container 使用。

  - ```yaml
    ARG <argName>
    ARG <argName>=<value>
    
    #傳入之後需要在 Dockerfile 中宣告同樣的參數名稱才可以使用。
    docker build --build-arg <argName>=<value> .
    ```

- ##### EXPOSE

  - ###### 宣告要對外開放的 Port Number

  - ```yaml
    EXPOSE <port>
    EXPOSE <port>/<protocol>
    
    #預設使用 tcp 協定，若是需要使用 udp 也可以指定
    EXPOSE 80/udp
    ```

- ##### CMD

  - ###### 設定 Image 啟動為 Containre 時預設要執行的指令

  - ###### Dockerfile 中 `CMD` 只能有一行，若有多行則只有最後一行有效。如果在 `docker run` 的時候有指定參數，那 `CMD` 就會被覆蓋掉。

  - ###### `CMD` 和 `RUN` 是不一樣，`CMD` 在建置時期不會執行，是在 Image 啟動成 Container 時才執行；而 `RUN` 是在建置時期執行並且 Commit 結果。

  - ```yaml
    # shell form
    CMD command parameter1 parameter2
    
    # exec form，官方推薦
    CMD["executable", "param1", "param2"]
    
    # 適用有定義ENTRYPOINT
    CMD["parameter1", "param2"]
    ```

- ##### ENTRYPOINT

  - ###### 和 `CMD` 一樣在啟動為 Container 時才會被執行，而且還可以和 `CMD` 合用。但是和 `CMD` 不同的是，`ENTRYPOINT` 一定會被執行，不會被覆蓋掉。

  - ###### 如果每次都要執行相同的指令建議用 `ENTRYPOINT`，而若是需要替換則使用 `CMD`

  - ```yaml
    # shell form
    ENTRYPOINT command param1 param2
    
    # exec form，官方推薦
    ENTRYPOINT ["executable", "param1", "param2"]
    ```

#### Example

##### .Net for N-Layer

- ```yaml
  # 使用官方的.NET Core SDK作為基礎映像，用於建置應用程式
  FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build
  
  # 設定工作目錄為應用程式的根目錄
  WORKDIR /src
  
  # 複製.csproj文件以進行獨立的邏輯分層
  COPY *.sln .
  COPY src/MyNLayerApp.Web/*.csproj ./src/MyNLayerApp.Web/
  COPY src/MyNLayerApp.Services/*.csproj ./src/MyNLayerApp.Services/
  COPY src/MyNLayerApp.Data/*.csproj ./src/MyNLayerApp.Data/
  
  # 恢復相依項目
  RUN dotnet restore
  
  # 複製整個專案並建置應用程式
  COPY . .
  RUN dotnet build -c Release -o /app
  
  # 使用官方的.NET Core Runtime作為最終運行時映像
  FROM mcr.microsoft.com/dotnet/core/aspnet:3.1 AS runtime
  
  WORKDIR /app
  
  # 從build階段複製已經建置好的應用程式
  COPY --from=build /app .
  
  # 定義在容器啟動時運行的命令
  ENTRYPOINT ["dotnet", "MyNLayerApp.Web.dll"]
  ```

##### Vue

- ```yaml
  # 使用官方的Node映像作為基礎映像
  FROM node:14
  
  # 設定工作目錄為應用程式的根目錄
  WORKDIR /app
  
  # 將本地的應用程式代碼複製到映像中的/app目錄
  COPY . .
  
  # 安裝應用程式相依項目
  RUN npm install
  
  # 建構Vue.js應用程式
  RUN npm run build
  
  # 指定Nginx作為最終運行時映像的基礎
  FROM nginx:alpine
  
  # 複製建置好的Vue.js應用程式到Nginx的靜態檔案目錄
  COPY --from=0 /app/dist /usr/share/nginx/html
  
  # 暴露Nginx的80埠
  EXPOSE 80
  
  # 啟動Nginx
  CMD ["nginx", "-g", "daemon off;"]
  ```

- ```yaml
  #使用到的 Docker Image 名稱，今天使用 CentOS
  FROM centos:7
  
  #RUN 指令後面放 Linux 指令，用來執行安裝和設定這個 Image 需要的東西
  RUN yum install -y wget
  RUN cd /
  
  #把 Local 的檔案複製到 Image 裡，如果是 tar.gz 檔複製進去 Image 時會順便自動解壓縮。
  ADD jdk-8u152-linux-x64.tar.gz /
  
  RUN wget http://apache.stu.edu.tw/tomcat/tomcat-7/v7.0.82/bin/apache-tomcat-7.0.82.tar.gz
  RUN tar zxvf apache-tomcat-7.0.82.tar.gz
  
  #用來設定環境變數
  ENV JAVA_HOME=/jdk1.8.0_152
  ENV PATH=$PATH:/jdk1.8.0_152/bin
  
  #在指行 docker run 的指令時會直接呼叫開啟 Tomcat Service
  CMD ["/apache-tomcat-7.0.82/bin/catalina.sh", "run"]
  ```

  



------

### Docker-compose

- ##### 可以將一群服務依據`yml`設定進行快速佈署

- ##### 包含產生/pull image、建置container

- #### up (Startup)

  ```powershell
  # 啟動 docker container (移動至 docker-compose 檔案目錄)
  docker-compose up -d
  ```

- #### stop

  ```powershell
  # 停止 docker container (移動至 docker-compose 檔案目錄)
  docker-compose stop
  ```

  

#### Docker-compose.yml

- ```yaml
  version: '3.4'
  
  #在機器上設定Volume空間進行持久化保存
  volumes:
      mongo-mount-data:
  
  # 定義了一個或多個服務，每個服務通常對應一個 Docker 容器
  services:
    catalogdbSrs:
      #對應docker image名稱，沒有的話會去register下載
      image: mongo
      
    #服務名稱，用於識別應用程序的一部分或服務
    catalog.api:
       #定義了該服務的映像名稱。這將是構建的映像的名稱，並在後續的容器啟動中使用
      image: ${DOCKER_REGISTRY-}catalogapi
       #建置Image檔案
      build:
        #構建上下文的目錄，指定 Dockerfile 和其他構建相關的文件所在的目錄。在這裡，. 表示使用當前目錄。
        context: .
        #指定使用的 Dockerfile 的名稱
        dockerfile: Services/Catalog/Catalog.API/Dockerfile
       #設定環境變數
       environment:
       - ASPNETCORE_ENVIRONMENT=Prod
      volumes:
      	#將Container內檔案對應的路徑map到上方宣告的volume
        - mongo-mount-data:/app/data
  ```

#### Docker-compose.override.yml

- ```yaml
  version: '3.4'
  
  services:
  	#對應yaml檔案 services名稱，去做覆寫動作
    catalogdbSrs:
      container_name: catalogdb
      restart: always
      ports:
          - "27017:27017"
      volumes:
          - mongo_data:/data/db
  
  
    catalog.api:
      container_name: catalog.api
      environment:
        - ASPNETCORE_ENVIRONMENT=Development
        #連線字串須由localhost變更為Container_name
        #測試結果會變更appsettings內的字串
        - "DatabaseSettings:ConnectionString=mongodb://catalogdb:27017"
        - "ElasticConfiguration:Uri=http://elasticsearch:9200"
      depends_on:
        #必須要在catalogdb container啟動時才能用
        - catalogdbSrs
      ports:
            - "8000:80"
  
  ```
  
- `docker-compose -f .\docker-compose.yml -f .\docker-compose.override.yml up -d`



### [Docker Hub](https://hub.docker.com/_/mysql)

- 倉庫是集中存放映像檔檔案的場所。有時候會把倉庫和倉庫註冊伺服器（Registry）混為一談，並不嚴格區分。實際上，倉庫註冊伺服器上往往存放著多個倉庫，每個倉庫中又包含了多個映像檔，每個映像檔有不同的標籤（tag）。
- 倉庫分為公開倉庫（Public）和私有倉庫（Private）兩種形式
- 當使用者建立了自己的映像檔之後就可以使用 `push` 命令將它上傳到公有或者私有倉庫，這樣下次在另外一台機器上使用這個映像檔時候，只需要從倉庫上 `pull` 下來就可以了。
- Docker 倉庫的概念跟 [Git](http://git-scm.com/) 類似，註冊伺服器可以理解為 GitHub 這樣的託管服務。




## 資料庫

### MSSQL安裝

```powershell
docker pull mcr.microsoft.com/mssql/server

docker run -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=Sean0721" -v sqlvolume:/var/opt/mssql -p 1433:1433 --name sql2019 -h sql2019   -d mcr.microsoft.com/mssql/server
```



### MySql 安裝

```powershell
docker search mysql

docker pull mysql
# docker run --name [MySql 名稱] -e MYSQL_ROOT_PASSWORD=my-password -d -p 3306:3306 mysql
# MYSQL_ROOT_PASSWORD = root 的密碼
docker run --name mysql -e MYSQL_ROOT_PASSWORD=Sean0721 -d -p 3306:3306 mysql
```

### Mongo DB

```powershell
> docker pull mongo

> docker run -d -p 27017:27017 --name shopping-mongo mongo

#安裝Mongo GUI
> docker run -d -p 3000:3000 mongoclient/mongoclient

#透過CLI操作mongo db
> docker exec -it shopping-mongo /bin/bash

# 執行 mongosh
> docker exec -it shopping-mongo mongosh

> show dbs
admin   0.000GB
config  0.000GB
local   0.000GB
> use CatalogDb
switched to db CatalogDb
> db.createCollection('Products')
{ "ok" : 1 }
> db.Products.insert({"Name":"SSSSS"})
WriteResult({ "nInserted" : 1 })
> db.Products.find().pretty()
{ "_id" : ObjectId("62bedb028d0493cc5f765dd9"), "Name" : "SSSSS" }
```

### Redis

- ```powershell
  > docker pull redis
  
  > docker run -d -p 6379:6379 --name  my-redis redis
  
  #透過CLI操作redis
  > docker exec -it my-redis /bin/bash
  root@e7b360d360b3:/data# redis-cli
  127.0.0.1:6379> ping
  PONG
  127.0.0.1:6379> test
  (error) ERR unknown command 'test', with args beginning with:
  127.0.0.1:6379> set key value
  OK
  127.0.0.1:6379> get key
  "value"
  127.0.0.1:6379> set test AA
  OK
  127.0.0.1:6379> get test
  "AA"
  ```






# Jekins

- ##### Docker 安裝

  - ```powershell
    docker run --name jenkins  -d --restart always  -p 8080:8080 -p 50000:50000  -v jenkins:/var/jenkins_home jenkins/jenkins:lts
    ```

## Pipeline

- ##### agent

  - ###### 指定整個 pipeline 或特定的 stage 將執行在 jenkins 的哪個位置

  - ###### 參數

    - ###### any:在任何可用的機器上執行 pipeline

    - ###### none:代表不設定 global 的 agent, 這樣的話就要在 stage 上去設定 agent

    - ###### docker

    - ###### dockerfile

- ##### stage

  - ###### pipeline 的執行階段, 由多個 steps 所組成

- ##### steps

  - ###### pipeline 主要執行的任務步驟

- ##### environment

  - ###### 設定變數給 stage 使用

- ##### when

  - ###### 可以用來執行程式碼執行的邏輯

- ##### post

  - ###### 在 pipeline 或 stage 結束時的操作，可以根據 pipeline or stage執行狀態去執行特定的操作, 需搭配 post-condition (always 、changed 、 failure、success、unstable、aborted)

  - ###### always:無論 pipeline 執行的狀態為何都要執行

  - ###### changed:當前的 pipeline 與先前的 pipeline 執行狀態不同時執行

  - ###### failure:pipeline 執行失敗時執行

  - ###### unstable:當前 pipeline 具有不穩定狀態才會執行

  - ###### aborted:pipeline 被終止時執行

- ##### Example:

  - ```
    pipeline {
        agent any
    stages {
            // 抓取專案
            stage('git clone') {
                steps {
                    git branch: 'main',
                        url: 'https://github.com/xgaryng/test_php.git'
                }  
                post {
                    // git clone 失敗
                    failure {
                        echo "[*] git clone failure"
                    }
                    // git clone 成功
                    success {
                        echo '[*] git clone successful'
                    }
                }
            }
            // more stage
    
        }
    }
    ```

### Jenkinsfile　

- ##### 將Pipline語法想成文字檔放在專案中，Jekins建置的時候會自動在專案的根目錄中尋找Jenkinsfile





# Vault

- ##### 主要解決機敏資料保護問題(如，資料庫帳密、三方串接的key...)，透過統一集中管理並且規範連線IP名單、帳號權限來保護資料(像Apollo)

- ##### 可以產生暫時性資料庫或其他服務(AWS, Azure, Google Cloud, LDAP, SSH)的credential ，透過時效性及權限來保護資料庫

  - ######  credential 會動態的產生，所以每一個元件都會拿到不一樣的 credential。

  - ###### 如果發現已經洩漏，也可以透過 audit 模組知道是哪個元件使用的 credential 洩露了，接著用 vault 撤銷憑證的功能把特定的 credential 撤銷。

  - ![img](https://miro.medium.com/v2/resize:fit:1000/1*l77RDhHFWmAia9gvlhqzZA.png)


## DB Credential

- ##### 透過Vault跟資料庫取得一組有時間性的驗證給AP端

  - ![应用程序通过 Vault 获取动态数据库凭据的流程](https://raw.githubusercontent.com/lonegunmanb/essential-vault-pic/main/20220131122650.png)

  - ##### MSSQL設定

    - ##### Enable the database secrets engine 

      - ```powershell
         #启动 Vault-使用 root 作为根令牌
        vault server -dev -dev-root-token-id root
        export VAULT_ADDR=http://127.0.0.1:8200
        export VAULT_TOKEN=root
        
        #启用数据库机密引擎
        vault secrets enable database
        ```

    - #####  設定Vault database

      - ```powershell
        vault write database/config/my-database \
            plugin_name=mssql-database-plugin \
            connection_url="sqlserver://{{username}}:{{password}}@localhost:1433" \    
            #設定那些Vault role可以使用
            allowed_roles=admin-role 
            #資料庫登入帳號
            username=${MYSQL_ROOT_USERNAME} 
            #資料庫登入密碼
            password=${MYSQL_ROOT_PASSWORD}
        ```

    - ##### 建立role腳色

      - ##### 設定資料庫權限

        - ###### `GRANT SELECT ON SCHEMA::dbo TO [{{name}}]` 將指定權限賦予該腳色

        - ###### `GRANT ro TO "{{name}}`將db內ro這個腳色賦予新建的credential

      - ```powershell
        vault write database/roles/admin-role \
        #設定對應的vault database
        db_name=discountdb \
        #設定建立該使用者時的 SQL 語法，在這邊也可以設定這個使用者對資料表的存取權限
        creation_statements="CREATE LOGIN [{{name}}] WITH PASSWORD = '{{password}}';CREATE USER [{{name}}] FOR LOGIN [{{name}}];GRANT SELECT ON SCHEMA::dbo TO [{{name}}];" \
        # 建立後1h鐘後會過期
        default_ttl="1h"  \
        #最多可以延長到 24h
        max_ttl="24h"
        ```

    - ##### 透過rolef取得登入credential

      - ```powershell
        vault read database/creds/my-role
        
        Key                Value
        ---                -----
        lease_id           database/creds/admin-role/pBZw6hJGmrOGxs7Qjn4xkiIA
        lease_duration     1h
        lease_renewable    true
        #臨時性登入帳密
        password           DCR-iLpYeEUHqCRLrG16
        username           v-token-admin-role-Cy6SNY7WsVamuXg9kuBa-1704613584
        ```

- ##### PostgreSQL

  - ```powershell
     #配置使用的 Postgres 连接凭据
     vault write database/config/postgresql \
         plugin_name=postgresql-database-plugin \
         connection_url="postgresql://{{username}}:{{password}}@localhost:5432/postgres?sslmode=disable" \
         allowed_roles=readonly \
         username="root" \
         password="rootpassword"
         
     #创建角色
     vault write database/roles/readonly \
          db_name=postgresql \
          creation_statements="CREATE ROLE "{{name}}" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}' NHERIT;  		 GRANT ro TO "{{name}}";" \
          default_ttl=1h \
          max_ttl=24h
     
     #透過rolef取得登入credential
     vault read database/creds/readonly
     
     #列出所有credential
     vault list sys/leases/lookup/database/creds/readonly
    ```

- ##### 流程

  - ###### 初始時會跟 vault 動態的索取一組 credential，此時 Vault 連結 MySQL 幫你動態生成一組帳號密碼，並且在期限後幫你刪除。


    - ###### 程式透過此 credential 讀取 MySQL 內的資訊


    - ###### 到達過期時間的一半（五秒）時，跟 vault 拿一組新的 credential


    - ###### 遇到無法存取資料的錯誤時，跟 vault 拿一組新的 credential


  - ###### 結束時會把正在用的 credential 註銷

      - ![img](https://miro.medium.com/v2/resize:fit:700/1*0kTkAt13XTDLFoJ5DYhDaA.png)


## 參考

- [Vault](https://lonegunmanb.github.io/essential-vault/9.%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B/6.postgres_dynamic_secrets.html)
- 



# Authorization & Authentication 

## Base in .NET

- #####  .NET Core 2.0 中有三個 class 代表使用者的身份：**Claim**, **ClaimsIdentity**, and **ClaimsPrincipal**。

  - ##### Claims

    - ###### 代表使用者的單一事實，可能是姓氏、姓名、年齡、老闆或出生等，或者是任何關於該使用者的任何資料，一個 Claims 只能代表一種資料，如果是「張三」，則第一個 claims 則為「張」、第二個 Claims 則為「三」。

    - 在 ASP.NET Core 裡，Claims 係由 `Claim` class 作為代表，接受兩個字串作為最常見的建構子： `type` 和 `value`。type 代表 Claim 的名稱；value 則為該Claim 用來代表使用者的資訊

    - ```C#
      //This claim uses a standard string
      new Claim("FillName", "Dark Helmet");
      //This claim uses ClaimsType Class
      new Claim(ClaimTypes.Email, "dark.helmet@spaceballs.com")
      //ClaimsType Class 定義了業界標準的 claims types 的字串常數可以取用
      ```

  - ##### ClaimsIdentity

    - ###### 一個 `ClaimsIdentity` 實例可以是被認證過或未認證過的，但一旦設定過 `AuthenticationType` 後，`IsAuthenticated` 的屬性即為 true，因為如果你已經用任何一個方式認證過該身份後，那也就表示它已經是 `authenticated` 。

  - ##### ClaimsPrincipal

    - ###### 一個 Principal 代表一個真正的使用者，它包含著一個或多個 `ClaimsIdentity` 的實例，就像一個人可以同時擁有身分證、駕照或駕照等等，每個 Identity 都有不同的使用目的，也各自包含著其獨自的 Claims，但它們也都同時在某種形式代表一個真實的使用者。

- ##### Authentication Handlers

  - ###### ASP.NET  的預設 Authentication Handlers 為 `Cookies authentication handler`

  - ###### 必須先向認證系統註冊，以便其被呼叫使用並與方案(scheme)相關聯。所謂 scheme 即為字串，係用來在一連串的 auth handlers 識別一個獨特不重複的 auth handler。

- ##### Authentication Middleware

  - ###### Authentication Middleware 即為負責確認每次 request 中的使用戶是否被認證，因為上述的 Authenticate verb 僅在使用者資訊存在時才能夠作用，故需要有 middleware 做每次 request 的認證確認。

  - ###### 當 request 發起時，Authentication Middleware 要求 default scheme (例 cookies) 的 auth handler 執行它的 authentication 程式碼，然後 auth handler 返回用戶資訊給 authentication middleware 後，再使用返回的訊息作為填充 HttpContext.User 物件。

- ##### Authentication and Authorization Flow 

- ![img](https://miro.medium.com/v2/resize:fit:668/1*egLW5Hbzzed0sl8p8udHHQ.png)

  1. ###### The request arrives at the server.

  2. ###### The authentication middleware calls the default handler’s Authenticate method and populates the HttpContext.User object with any available information.

  3. ###### The request arrives at the controller action.

  4. ###### If the action is not decorated with the `[Authorize]` attribute, display the page and stop here.

  5. ###### If the action **is** decorated with `[Authorize]`, the auth filter checks if the user was authenticated.

  6. ###### If the user was not, the auth filter calls Challenge, redirecting to the appropriate signin authority.

  7. ###### Once the signin authority directs the user back to the app, the auth filter checks if the user is authorized to view the page.

  8. ###### If the user is authorized, it displays the page, otherwise it calls Forbid, which displays a ‘not authorized’ page.

     

- ##### Challenge

  - ##### 未驗證使用者要存取需驗證才能存取的資源時， 授權服務會叫用 [IAuthenticationService.ChallengeAsync](https://docs.microsoft.com/zh-tw/dotnet/api/microsoft.aspnetcore.authentication.iauthenticationservice.challengeasync?view=aspnetcore-3.1) 發起 challenge， challenge 被發起後所伴隨採取的行動稱為 challenge action， 且 challenge action 應讓使用者知道應該以哪一種驗證機制取得授權，常見的具體範例有：

    - ###### cookie 驗證方案將使用者轉址到登入頁面。

    - ###### JWT 回傳 401 Unauthorized 狀態碼，並在 Header 帶入 `www-authenticate: bearer`。

- ##### Forbid

  - ##### 已驗證的使用者要存取授權之外的資源時， 授權會叫用 [IAuthenticationService.ForbidAsync](https://docs.microsoft.com/zh-tw/dotnet/api/microsoft.aspnetcore.authentication.iauthenticationservice.forbidasync?view=aspnetcore-3.1) 發起 Forbid， Forbid 發起後所伴隨採取的行動稱為 Forbid action， Forbid action 的目的是要讓使用者知道自己已通過認證、且不具權限訪問所請求的資源， 常見的具體範例有：

    - ###### cookie 驗證方案：轉址到網站的 Forbidden 頁面。

    - ###### JWT 驗證方案：回傳 403。

    - ###### 自訂驗證方案：轉址到使用者可存取的特定頁面。



## Json Web Token

- ##### JWT是一種『有限時間內可利用認證令牌要求對應的操作權限』的一種方法

- ##### 使用者登入後產生Token，後續針對Request內夾帶的Token進行驗證。

  - ##### 客戶端從伺服器端取得認證簽名後，伺服器端只對認證簽名進行驗證，從認證簽名來判斷是不是具備指定的操作資格．除此之外還會判斷令牌是否過期、是否是黑名單等狀況。

- ##### 主要驗證內容為產生Token時的資訊內容。Ex.

  - ###### 相同的 **Issuer **設定值

  - ###### 相同的 **Audience **設定值

  - ###### 驗證 **Token **有效期限

    - ###### 符合對稱式加密的簽章

  - ###### Token內可包含自定義資訊，但驗證時不會針對使用者進行驗證，因為驗證時不會再連接DB。

  - ###### 因此，只要產生Token的設定一致，不同Service也可以透過相同Token驗證

- ##### 包含了 **header**、**payload**和**signature** 三個部分

  - **Header** 

    - ##### 包含了兩個主要資訊：使用的加密演算法和token的類型(基本上就是JWT)

    - ##### 這些內容通過 [Base64](https://zh.wikipedia.org/wiki/Base64) 轉化就能夠得到我們的第一段字串。

      - ```
        eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9
        ```

    ```C#
    // 使用HS256演算法來產生JWT token
    {
      "alg": "HS256",
      "typ": "JWT"
    }
    ```

  - **Payload**

    - ##### 包含了聲明的資料，帶有欲存放的資訊（例如用戶資訊）

    - ##### Payload 又可以被稱為 claims

    - ##### 定義上有 3 種聲明 (Claims)

      - ###### Reserved (註冊聲明)

      - ###### Public (公開聲明)

      - ###### Private (私有聲明)

    - ##### Reserved (註冊聲明)

      - ###### iss (Issuer) - JWT的發行人

      - ###### sub (Subject) - JWT的主題（用戶）

      - ###### aud（audience）：JWT的目標收件人

      - ###### exp（expiration time）：JWT到期的時間

      - ###### nbf（not before time）：不得接受JWT處理的時間

      - ###### iat（issued at time）：發布JWT的時間; 可用於確定JWT的年齡

      - ###### jti（JWT ID）：唯一標識符; 可用於防止JWT被重放（允許令牌僅使用一次）

    - base64 加密（該加密是可以對稱解密的)

    ```C#
    /*
        sub就是RFC7519中定義的基本資訊，
        age則是我們自己加上去的
    */
    
    {
      "sub": "wellwind",
      "age": 30
    }
    ```

  - **Signature**

    - ###### 將被轉換成 Base64 編碼的 Header、Payload 與自己定義的密鑰，透過在 Header 設定的雜湊演算法方式所產生的

    - ###### 用來確保資料完整性的一個雜湊簽章

    - ###### 可以選用任何雜湊演算法來進行處理

- 驗證流程

  ![img](https://dotblogsfile.blob.core.windows.net/user/wellwind/c93407af-3191-48e8-9029-2e02a7e03b1e/1479955047_94613.png)

- 流程

  1. 使用者登入進行身分驗證後產生Token

     ```C#
     [Route("api/[controller]")]
     [ApiController]
     public class AuthController : ControllerBase
     {
         private readonly IConfiguration _config;
     
         public AuthController(IConfiguration configuration)
         {
             _config = configuration;
         }
     
         // GET api/auth/login
         [HttpGet, Route("login")]
         public IActionResult Login(string name)
         {
             // STEP0: 在產生 JWT Token 之前，可以依需求做身分驗證
     
             // STEP1: 建立使用者的 Claims 聲明，這會是 JWT Payload 的一部分
             var userClaims = new ClaimsIdentity(new[] {
                 new Claim(JwtRegisteredClaimNames.NameId, name),
                 new Claim(JwtRegisteredClaimNames.Jti, Guid.NewGuid().ToString()),
                 new Claim("CustomClaim", "Anything You Like")
             });
             // STEP2: 取得對稱式加密 JWT Signature 的金鑰
             // 這部分是選用，但此範例在 Startup.cs 中有設定 ValidateIssuerSigningKey = true 所以這裡必填
             var securityKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(_config["Jwt:Key"]));
             // STEP3: 建立 JWT TokenHandler 以及用於描述 JWT 的 TokenDescriptor
             var tokenHandler = new JwtSecurityTokenHandler();
             var tokenDescriptor = new SecurityTokenDescriptor
             {
                 Issuer = _config["Jwt:Issuer"],
                 Audience = _config["Jwt:Issuer"],
                 Subject = userClaims,
                 Expires = DateTime.Now.AddMinutes(30),
                 SigningCredentials = new SigningCredentials(securityKey, SecurityAlgorithms.HmacSha256)
             };
             // 產出所需要的 JWT Token 物件
             var securityToken = tokenHandler.CreateToken(tokenDescriptor);
             // 產出序列化的 JWT Token 字串
             var serializeToken = tokenHandler.WriteToken(securityToken);
     
             return new ContentResult() { Content = serializeToken };
         }
     }
     ```

  2. 專案內加入驗證

     ```C#
     public void ConfigureServices(IServiceCollection services)
     {
         services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_2);
     
         // STEP1: 設定用哪種方式驗證 HTTP Request 是否合法
         services
         // 檢查 HTTP Header 的 Authorization 是否有 JWT Bearer Token
         .AddAuthentication(JwtBearerDefaults.AuthenticationScheme)
         // 設定 JWT Bearer Token 的檢查選項
         .AddJwtBearer(options =>
          {
            options.TokenValidationParameters = new TokenValidationParameters
            {
                ValidateIssuer = true,
                ValidIssuer = Configuration["Jwt:Issuer"],
                ValidateAudience = true,
                ValidAudience = Configuration["Jwt:Issuer"],
                ValidateLifetime = true,
                ValidateIssuerSigningKey = true,
                IssuerSigningKey = new SymmetricSecurityKey
                    (Encoding.UTF8.GetBytes(Configuration["Jwt:Key"]))
            };
          });
     }
     ```

  3. 驗證API

     ```C#
     [Route("api/[controller]")]
     [ApiController]
     public class ValuesController : ControllerBase
     {
         // GET api/values/anonymous
         /// <summary>使用匿名登入，無視於身分驗證</summary>
         [AllowAnonymous]
         [HttpGet, Route("anonymous")]
         public IActionResult Anonymous()
         {
             return new ContentResult() { Content = $@"For all anonymous." };
         }
     
         // GET api/values/authorize
         /// <summary>使用身分驗證，HTTP 的 Authorization Header 必須設定合法的 JWT Bearer Token 才能使用</summary>
         [Authorize]
         [HttpGet, Route("authorize")]
         public IActionResult All()
         {
             return new ContentResult() { Content = $@"For all client who authorize." };
         }
     }
     ```

### JwtRegisteredClaimNames 屬性

- 在建立使用者的 Claims 聲明時，我們會用到很多 `JwtRegisteredClaimNames` 結構型別，來取得是先定義好的字串

- |   Claim    | 說明                                                 | 連結                                         |
  | :--------: | :--------------------------------------------------- | -------------------------------------------- |
  |    Jti     | 表示 JWT ID，Token 的唯一識別碼                      | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Iss     | 表示 Issuer，發送 Token 的發行者                     | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Iat     | 表示 Issued At，Token 的建立時間                     | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Exp     | 表示 Expiration Time，Token 的逾期時間               | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Sub     | 表示 Subject，Token 的主體內容                       | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Aud     | 表示 Audience，接收 Token 的觀眾                     | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Typ     | 表示 Token 的類型，例如 JWT 表示 JSON Web Token 類型 | http://tools.ietf.org/html/rfc7519#section-4 |
  |    Nbf     | 表示 Not Before，定義在什麼時間之前，不可用          | http://tools.ietf.org/html/rfc7519#section-4 |
  |   Actort   | 識別執行授權的代理是誰                               | http://tools.ietf.org/html/rfc7519#section-4 |
  |   NameId   | 使用者識別碼                                         | http://tools.ietf.org/html/rfc7519#section-4 |
  | FamilyName | 使用者姓氏                                           | http://tools.ietf.org/html/rfc7519#section-4 |
  | GivenName  | 使用者名字                                           | http://tools.ietf.org/html/rfc7519#section-4 |
  |   Gender   | 使用者性別                                           | http://tools.ietf.org/html/rfc7519#section-4 |
  |   Email    | 使用者的電子郵件                                     | http://tools.ietf.org/html/rfc7519#section-4 |
  | Birthdate  | 使用者生日                                           | http://tools.ietf.org/html/rfc7519#section-4 |
  |  Website   | 使用者的網站                                         | http://tools.ietf.org/html/rfc7519#section-4 |


### Bearer Token 

- HTTP 的認證「Authorization」方案有許多種格式，而 Bearer 就是其中一種且被定義在 Header 中的驗證方案，通常搭配於 JWT 上

- Resource server 是資源服務器，即後端存放用戶生成的 API Token 的服務器。 
- Authorization server 的意思是認證服務器，即後端專門用來處理認證的服務器
- 這些東西都是由 [OAuth 2.0](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html) 中所定義出來的，在定義中說明了 Client 如何取得 Access Token 的方法



## OAUTH

- ##### OAuth 2.0 是一個授權協議,它允許軟體應用代表(而不是充當)資源擁有者去訪問資源擁有者的資源。

  - ###### 應用向資源擁有者請求授權,然後取得令牌(token),並用它來訪問資源。這一切都不需要應用去充當資源擁有者的身份,因為令牌明確表示了被授予的訪問權。

- ##### 每一個服務無需自行設計登入與會員管理機制，透過Auth Server(GOOGLE、Line....)做集中管理。當使用者再一個服務驗證完取得Access Token後，可以拿著這組Token到其他服務進行操作達到SSO的功能

- ##### OAuth 2.0 基本上處理 Authorization(授權) 的部分，用來控制授權**誰**能存取**資源**，有四個基本元素

  - ###### **authorization server**: 用來發 access token 的 server

  - ###### **resource owner**: 有權限能存取資料的使用者

  - ###### **client**: 將 access token 傳給系統服務的應用程式

  - ###### **resource server**: 接受 access token 並驗證其合法性

    - ![image-20221030091611632](https://blog.kevinyang.net/2022/10/30/oidc-notes/image-20221030091611632.png)
    - ![img](https://lh3.googleusercontent.com/blogger_img_proxy/AJ0KDdXoD4D0oJaA09TAYG0CosH3z7XD7BOmcNAIUfaMoBlPgP8cRrgmkjqGx3t5YAcNXP6vkd7b9heosjhZ0YY6JJ4FvxMJMxIDch8jA1Ib5m2yZRfSOHP53ADyDFW-1DPha0-sYdCNZPQY60uB-FAZ9IBCdpjeVFh9Tw0I2u5v2WZVXePIWCMLqoM=s0-d)

  

### 驗證方式

#### Authorization Code Grant

- ##### 使用者再Auth Server登入驗證過後Server轉導至設定的redirecturl並且夾帶`Auth code`，Client拿著Auth Code至Auth Server換取access token

  

- ![img](https://miro.medium.com/v2/resize:fit:700/0*3PxRNz0tJZ94iUm8)

- ![img](https://jcbaey.com/static/abbc2ac38ff4ca76b85cfa61e3f3a939/60a48/authorization-code-spa.png)

- ##### 流程說明

  1. ##### User 透過Web browser進入Web App後，Web App至Backend api 驗證Token是否合法(或取得User Info)

    - ###### 若Token 合法則回傳User Info給Web App並進行後續動作

    - ###### 若不合法，則回傳401至Web App

  2. ##### Web App接到401回傳後，呼叫Backend Auth API轉導至Auth Server進行登入驗證動作

    - ###### Redirect至AuthServer時需附上的req內容

      - ```javascript
        let authorizationRequest = {
          "response_type": "code",
          "client_id": "123410928955-xxxxx19vm0fdh0d79qtmvomgkmh19ol8.apps.googleusercontent.com",
          "redirect_uri": "http://www.backendserver.com/callback", // 可選欄位
          "state": "xyz", // 建議欄位，可以用來維護request和backend callback的狀態，可用以避免cross-site request forgery
          // "scope": "", // 可選欄位
        };
        
        let searchParams = new URLSearchParams(authorizationRequest);
        ```

  3. ##### User驗證成功後，Auth Server依據Backend (Auth Client)設定將User畫面轉導回指定的redirect url並夾帶`authorization code`

    - ###### authorization server得到使用者（resource owner）的認證與授權過後，將以下auth code送去使用者當初Client所提供的endpoint

      - ```javascript
        let authorizationResponse = {
          "code": "SplxlOBeZQQYbYS6WxSbIA", // authorization code: 提供給 server POST access token request 使用
          "state": "xyz", // 要 reqeust 時有提供，response 才會有
        };
        ```

  4. ##### Backend接到request後，透過`authorization code`及ClientID透過Post方式向Auth Server交換Access Token

    - ```c#
      public ActionResult AuthRedirect(string code)
      {    
          //拿著傳進來的code及註冊時Auth Server給定的Client ID，取得access token
      
          //取完Access Token後將User轉回至前端
          return Redirect(model.ResultURL);
      }
      ```

  5. ##### Backend將User導回至Web App中，並將Access Token儲存至Cookie或Local Storage中

- ##### Notice

  - ##### 步驟2-4在.Net Identity 及 OIDC中已經封裝完成，只需要透過設定就可以走完流程

  - ##### 參考 https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/Practice/TestAPI

  - ##### 如果單純SPA沒有搭配後端時，可以透過[PKCE](#PKCE)進行上述流程。


#### Implicit Grant

- ##### 過程中沒有backend的參與，單純在Web App及Auth Server中完成

  - ![img](https://miro.medium.com/v2/resize:fit:700/0*asIJwovqFHWNPgBF)

- ##### 流程

  1. ##### Web Application（client）觸發request並導（Redirect）往Authorization Server進行驗證和授權

    1. ```html
      https://www.authserver.com/authorize？
      response_type=token
      &client_id=ZuGSLz6HjGRA8LMtopHBzcKHhCXFtMk8
      &redirect_uri=http://localhost:3000/
      &scope=openid profile email read:appointments
      &state=LxfKVRpEwa4lnPEvmx9LbbXSRIVUMaju
      ```

  2. ##### User至Auth Server進行身分驗證

  3. ##### 驗證與授權過後，透過 redirect 將access token置於parameter中回應給使用者

    1. ```html
      https://www.webapp.com/callback#
      access_token=xxx.yyy.zzz
      &token_type=bearer
      &expires_in=3600
      &scope=openid profile email read:appointments
      &state=LxfKVRpEwa4lnPEvmx9LbbXSRIVUMaju
      ```

  4. ###### web app可以透過access token去向resource server請求所需要的資料

##### Sample - Vue 

- ##### `yarn add oidc-client`

- ##### 建立傳送至 `IdSvr4` 資料

```javascript
auth: 
{
    authority: "http://192.168.1.102:13000",
    client_id: "icw_biosecurity",
    redirect_uri: "/Callback",
    response_type: "id_token token",
    scope: "openid profile icw.biosecurity.api",
    silent_redirect_uri: "/SilentRenew",
    automaticSilentRenew: true
}
```

- ##### 建立authService 產生`UserManager`設定

- ##### 建立導頁(login、callback、signOut)

- ##### HomePage透過 `getUser()` 判斷是否有Token

  - ###### 有 => 導致首頁

  - ###### 沒有 => 導致登入頁面

```javascript
async mounted() {
    let vi = this;
    userManager.getUser().then(function(user) {
        if (!user) {
       	 	vi.$router.push("login");
        }
        else
       		 store.commit('setUserProfile', user);     
    });
}
```

- ##### loginPage 處理導向 IdSvr4

```javascript
methods: {
		login() {
			userManager.signinRedirect();
		}
	}
```

- ##### 登入完成後，透過Callback判斷導向

```javascript
 mounted() {
    let vi = this;    
    userManager.signinRedirectCallback()
      .then(function() {
        vi.$router.push("/");
      })
      .catch(function(e) {        
        vi.$router.push("login");
      });
  }
```

- ##### `signoutRedirect()` 可登出

- ### IdSvr4:

  - 新增Client設定


```C#
new Client
{
	ClientId = "icw_biosecurity",
	ClientName =  "生物安全管理平台",

	AllowedGrantTypes = GrantTypes.Implicit,
	AllowAccessTokensViaBrowser = true,

	AccessTokenLifetime = 3600,
	RequirePkce = true,
	RequireClientSecret = false,
	RedirectUris =  
	new List<string>		{"http://localhost:8080/Callback", "http://localhost:8080/SilentRenew"},
	
PostLogoutRedirectUris = new List<string> {"http://localhost:8080"},

AllowedCorsOrigins = new List<string> {"http://localhost"},

AllowedScopes =
{
	IdentityServerConstants.StandardScopes.OpenId,
	IdentityServerConstants.StandardScopes.Profile,
	IdentityServerConstants.LocalApi.ScopeName,
	"icw.biosecurity.api"
},
	RequireConsent = false
}
```



#### Client Credentials Grant

- ###### 即 Client ID + Client Secret 。適用於跑在 Server 的 Client 

- ###### Server 與 Server間的溝通，不需要使用者的參與

  - ![img](https://miro.medium.com/v2/resize:fit:700/0*XJZ4jTC5xD6eTy9w)

- ###### backend server出發直接將註冊OAuth client時取得的client_id和client_secret送去給authorization server

  - ```javascript
    let accessTokenRequest = {
      "grant_type": "client_credentials",
      "client_id": "123410928955-xxxxx19vm0fdh0d79qtmvomgkmh19ol8.apps.googleusercontent.com",
      "client_secret": "GOCSPX--_EtxcDYVxxxxxxxx_C3Cixxxxxx",
      // "scope": "" // 是個可選欄位
    };
    ```

- ###### authorization server 在**驗證過 client 後**，直接將 access token response 回去給 backend server

  

#### 範例1

- ##### 現在有一個使用者，就假定是我自己本身。我的行事曆資訊都放在我的 Google Calendar 上。我現在想要使用一個可以做到比 Google Calendar 還要多功能的第三方行事曆服務。這時候我就會想要讓這第三方行事曆服務得到我在 Google Calendar 上的行事曆資訊。

- ##### 如果是在一個只有帳號跟密碼的世界上，我就必須要把我的 Google 帳號和密碼告訴給這第三方服務行事曆服務，它才有辦法取得這些資訊。但如果我把帳號密碼告訴了第三方，它可能就可以在暗地裡竊取行事曆以外的資訊，像是在 Gmail 裡的機密資訊。這時候就出現了使用 Access Token 來解決這個問題的協議，OAuth 2.0。

  - ![img](https://hennge.com/tw/blog/1_X0LkXQ0w5JxyZP5zPmATlg.png)

- ##### Access Token 就像是一張兌換卷，每一張 Access Token 上都有寫**「誰」「對誰」「給予什麼樣的權限」**，如此一來就可以在不告訴對方帳號密碼的情況下，給予對方最低限度需要的權限。這就是為什麼 OAuth 2.0 被稱為是一個授權的協議。

- ##### OAuth 2.0 的世界中，我這個使用者被稱為 Resource Owner；第三方行事曆服務被稱之為 Client；有放我行事曆資訊的 Google Calendar 稱為 Resource Server；幫忙發 Access Token 的伺服器稱之為 Authorization Server，在這例子中就會是 Google。

  - ![img](https://hennge.com/tw/blog/1_vL6Fi0RFSHvtxkkDQKAr9w.png)

#### 範例2

![img](https://miro.medium.com/v2/resize:fit:1434/0*iRHRtooOazuVuCy4)

![img](https://miro.medium.com/v2/resize:fit:1835/0*S-84-BQZPVQ5xbwO)

- ##### 圖中的步驟 1~7，用戶向 Google Account 要到 Authorization Code，然後轉交給 Slack。

- ##### 步驟 8~12，Slack 憑藉從用戶拿到的 Authorization Code，去跟 Google Account 換到 Access Token。Slack 換到 Access Token 以後，就可以存取 Google Drive，完成用戶要求的作業。

- ##### OAuth 2.0 可以讓用戶個別授權第三方應用不同的權限，限制存取特定範圍的資料。這在實際上就是在取 Authorization Code的時候，以 `scope` 這個欄位來指定的

- ##### 取得 Authorization Code 的過程中，用戶會依序連到 Client -> Authorization Server -> Client。這邊的切換是藉由 HTTP redirect 機制達成。`rediect_uri` 就是指定完成授權以後，要重導向回的位置。

- ##### Client 在部署階段必須先與 Authorization Server 照會，Authorization Server 會為每個 Client 配給 ID。在 OAuth 2.0 的流程中，Authorization Server 憑藉 Client ID 識別 Client 的身分。

   

### PKCE

- ##### Proof Key for Code Exchange

- ##### 主要目的是: 預防 CSRF 跟 Authorization Code(state) 被惡意攔截，補強了 OAuth2 的缺點。

- ##### PKCE是基於Code flow的安全強化版。在整個過程前後添加了兩個動作--產生`code_verifier`和`code_challenge`，並在最後透過`code_challenge`驗證`code_verifier`。

- ##### 由於 SHA256 是不可逆且較安全的加密模式，並且在資料的傳輸上先提供 `Code Chanllenge` 再來是 `Code Verifier` 可以確保著交握的兩端都是同一個人，因為必須要同時都有兩個才能正確地確認。 這樣就算原本的 `code` 被竊取到了，也會因為無法產生正確的 `Code Verifier` 讓惡意程式無法竊取到資料

  - ###### `Code Verifier`: 一個特殊字串，長度限制為 43 ~ 128 之間。

  - ###### `Code Chanllenge`: 透過 SHA 256 將 `Code Verifier` 加密過的字串。

- ##### 流程說明

  1. ##### Client 在轉導至Auth Server進行使用者驗證、授權時，同時加上`code challenge(加密字串)` 、`code_challenge_method(加密方法)`。

    - ###### Client在取得authorization code之前動態生成一個只有自己知道的密語(code verifier)，在這裡我們假設code verifier = “apple”

    - ###### Client將密語(apple)使用SHA-256進行hash, 變成code challenge = “3A7BD3E2360A3D29EEA436FCFB7E44C735D117C42D1C1835420B6B9942DD4F1B”

    - ###### 合法的Client用安全的TLS channel將code challenge (hash過的code verifer) 以及所使用的演算法 code_challenge_method = “S256” 傳給Authz Service

    - 

  2. ##### Auth Server在驗證完User後，將Auth Code及code challenge 、code_challenge_method進行binding以備後續查驗

  3. ##### Auth Server回傳Auth Code給Client

  4. ##### Client 將Auth Code 及`code verifier`傳到Auth Server以交換Access Token

    - ###### client為了證明自己是合法的client（證明自己是當初發出(2)request的一方），將自己的密語code verifier(apple)伴隨著authorization code一起傳到Authz Service。

    - ###### Authz Service為了驗證，將傳過來的密語(apple)經過code_challenge_method加密並比對與Auth Code binding的code challenge是否一致。一致的話發行access token, 不一致的話拒絕。

- ##### 比較(Line 為例)

  - ##### 不使用PKCE

    - ###### 使用者透過手機上有串接 OAuth2 的 App 來做 Authorization

    - ###### 進入 OAuth2 服務提供商的帳號登入畫面

    - ###### 認證完成後， OAuth2 平台會根據當初登記的 URL （手機上為某個登入的 URI Scheme) ，開啟相關 App。

    - ###### 這時候，如果有使用者不小心安裝了惡意的 App ，他可以登記同一個 URI Scheme ，但是因為手機設計原理兩個 App 都會收到相關的 URI Callback 。

    - ###### `惡意程式(Malicious App)` 收到 URI Callback 呼叫並且取的 `code` 與 `state` 並且透過其他方式取得 Channel ID 跟 Channel Secret (原理透過 App 掃瞄，這裡就不詳細敘述)。

    - ###### 這時候，取的 `code` 與 `state` 的惡意程式，就可以透過呼叫 `GetAccessToken` 取的相關 Token 並且獲得權限。

    - ![img](https://developers.line.biz/assets/img/new-user-login-without-pkce-en.54bd0a4b.svg)

  - ##### 使用PKCE

    - ###### 產生 Web Login URL 的時候，先丟 `Code Chanllenge` 在傳遞參數中。

    - ###### 連接到 LINE 開始認證流程，完成認證流程後。透過 Callback URI 傳回 `code` 與 `state` 。

    - ###### 這時候認證方會將 `Code Verifier`送給認證伺服器來取得 Access Token 。

    - ###### 認證伺服器端會拿 `Code Verifier` 與 `Code Chanllenge` 來確認，是否是同一個需求端發出的需求。

    - ###### 返回 `Access Token` ，完成認證跟取得資訊的需求。

    - ![img](https://developers.line.biz/assets/img/new-user-login-with-pkce-en.8be182f5.svg)



### OIDC

#### ID Token

- ##### OpenID Connect 中定義的 ID Token 採取了 JWS的規格，收到這 ID Token 的服務即可以透過它的數位簽章確保此使用者的身分的正確性。

- ##### 基於 OAuth 2.0 的身份認證協議，允許使用者端通過 Authorization Server 驗證使用者身份，並以標準的 `ID Token` 獲取使用者的基本資訊。

- ##### 定義

  - ###### UserAgent (ResourceOwner): 資源擁有者，基本上就是使用者

  - ###### OIDC Client: 想要取得 user 認證及授權的 client 端，必須在 Authorization Server 有註冊。

  - ###### Authorization Server / OpenID Provider: 

    - ###### 身兼驗證跟授權功能

    - ###### 支援 SSO

    - ###### 提供 OPID Client 註冊申請，至少需要以下資料

      - | Attributes                | description                        | 範例                                                        |
        | :------------------------ | :--------------------------------- | :---------------------------------------------------------- |
        | client_id                 | OIDC Client ID                     | awesome-service                                             |
        | audience                  | 允許接受 ID Token 的 URI           | [https://awesome.burgess.com](https://awesome.burgess.com/) |
        | redirect_uri              | 登入後轉導的頁面                   | https://awesome.burgess.com/login/callback                  |
        | backchannel_logout_uri    | 主動發送登出請求給 client 端的 URI | https://awesome.burgess.com/logout/callback                 |
        | post_logout_redirect_uris | 登出後轉導的頁面                   | https://awesome.burgess.com/logout/backchannel              |

  - ###### 註冊後 Authorization Server 會發給 client 端一個 `client_secret`，之後換 `ID_TOKEN` 會用到

- ##### 基本流程

  - ##### User進入某個服務(OIDC Client)，服務將User導至Authorization Server進行登入

  - ##### User 至Authorization Server進行登入並取得Authorization Code

    - | parameters             | description                                            |
      | :--------------------- | :----------------------------------------------------- |
      | client_id              | OIDC Client ID，要跟 Authorization Server 註冊的一致   |
      | nonce                  | 隨機字串，驗證後會存在 ID Token 內                     |
      | backchannel_logout_uri | 主動發送登出請求給服務的 URI                           |
      | redirect_uri           | 登入後轉導的頁面，要跟 Authorization Server 註冊的一致 |
      | response_type          | 回應類型，通常固定填 code                              |
      | scope                  | 登入驗證並取得 ID Token 的 scope 為 `openid`           |
      | state                  | 為避免 CSRF 攻擊的一個隨機字串                         |

  - ##### 登入完成後回傳 Authorization code, state 及授權 scope 到 redirect_uri

    - ###### redirect_uri 必須是該 Client ID 在 Authorization Server 註冊的 uri

  - ##### OIDC Client呼叫Authorization Server透過 Authorization Code取得 `ID Token`

  - ##### 取得ID Token & access token

    - ###### 驗證成功後 redirect_uri 會拿到 `ID Token` & `access token`，

      - ###### ID Token 帶有使用者資訊，JWT 格式，通常 payload 會紀錄使用者 ID、token 有效期限、發行單位、發行時間、OIDC Client ID、Authorization Server Login Session ID 等等資訊。

      - ###### access token是使用者授權使用某些服務或取得某些資訊的權限，換句話說，得到授權的 service 可以透過 `access token` 呼叫授權方的 API，使用某些服務或取得某些資訊。

  - ##### Auth Server 會依據不同的Client 發送出的ID Token有所不同

    - ###### JWT內`Issuer`會等於Auth Server url，`Audience` 會是Client ID

    - ###### Client後續只要驗證Id Token的內容即可(如JWT驗證)

      - ###### 在OIDC Client 設定驗證

      - ```C#
        //Gets or sets the parameters used to validate identity tokens.
        options.TokenValidationParameters = new()
        {
            NameClaimType = JwtClaimTypes.GivenName,
            RoleClaimType = JwtClaimTypes.Role,
            ValidateLifetime = true,
            RequireExpirationTime = true,
        };
        ```

#### 實現SSO

1. ###### User 從Client A進行身分驗證

2. ###### Client A將User 轉到Auth Server 進行身分驗證及授權

3. ###### User操作Client B

4. ###### Client B將User轉至Auth Server進行身分驗證

   - ###### 因為使用者在步驟2進行過登入動作，Auth Server已經存在使用者登入的紀錄(Cookie/Session)

   - ###### Auth Server直接回傳Token給Client B



### OAuth 流程

#### Client 設定

- ###### 每一個三方服務都需要再Auth Server進行註冊設定(不論是要走User Grand Code或是後端ClientCredential)

- ###### Client 相關參數

  - | 屬性                     | 描述                                                         |
    | :----------------------- | :----------------------------------------------------------- |
    | `ClientId`               | 用戶端的唯一識別碼。                                         |
    | `ClientName`             | 用戶端顯示名稱，用於記錄和同意畫面。                         |
    | `AllowedGrantTypes`      | 指定用戶端如何與 IdentityServer 互動。 如需詳細資訊，請參閱[設定驗證流程](https://learn.microsoft.com/zh-tw/dotnet/architecture/maui/authentication-and-authorization#configuring-the-authentication-flow)。 |
    | `ClientSecrets`          | 指定向權杖端點要求權杖時所使用的用戶端密碼認證。             |
    | `RedirectUris`           | 指定允許接受傳回權杖或授權碼的 URI。                         |
    | `RequireConsent`         | 指定是否需要同意畫面。                                       |
    | `RequirePkce`            | 指定使用授權碼的用戶端是否必須傳送證明金鑰。                 |
    | `PostLogoutRedirectUris` | 指定登出後允許重新導向至的 URI。                             |
    | `AllowedCorsOrigins`     | 指定用戶端原點，讓 IdentityServer 得以允許來自原點的跨原點呼叫。 |
    | `AllowedScopes`          | 指定用戶端有權存取的資源。 用戶端預設無權存取任何資源。      |
    | `AllowOfflineAccess`     | 指定用戶端是否可以要求重新整理權杖。                         |

- ###### Constent Screen

  - ###### 使用者透過Client轉導進行身分驗證後，Auth Server會顯示一個同意畫面讓使用者確認Client可以使用的Scope有哪些

  - ###### 在Client中 設定`RequireConsent` 可以決定該Client是否需要請使用者提供授權，預設為false代表默認Client可以使用所有設定的Scope內容

  - ![img](https://i.stack.imgur.com/Rndfo.png)****


#### Authorization Code Grant

- ##### User使用Client(`movies_mvc_client`)想取得被保護資料`MovieAPI`裡的內容

- ##### Client轉至Auth Server進行身分驗證，若未登入會將使用者導向Auth Server的登入畫面

  - ###### 轉過去的過程中，Auth Server會先驗證Client的資訊是否與設定相符

  - ```bash
    /*
    	client_id = 該Client 向AuthServer註冊的ID
    	scope = 必須包含在當初AuthServer設定的內容不能超過
    	response_type = code 回傳Grand code
    */
    https://localhost:5006/connect/authorize?client_id=movies_mvc_client&redirect_uri=https%3A%2F%2Flocalhost%3A5002%2Fsignin-oidc&response_type=code&scope=openid%20profile%20address%20MovieAPI&code_challenge=mlB_su5XRePUde-Gp_phUtpx0FP6aFVnVlBAEKJHac0&code_challenge_method=S256&response_mode=form_post&nonce=638418697139251752.ZjViMGY2YzEtNzdhMS00ZTQ3LTg5NWQtNWNlYjAyNDg3Y2EyZmIzZTEwMDktZjdhMy00NDdlLTg4ZDEtZjc0ZDcwNGRmOTEy&state=CfDJ8Np58mawfGNFmdV8O_lOYKJnJD17jNGKDUdCYKQ0h61WIWJJgd9qyjqxgdSs23CTJPCe9SNAGdIjVtQ6JDnDsRXu5rpg3hhMcOwl6Jxdxl-HMTb1BZeTsTxmGRh2uHsbnaUvVzjwWlsIOxJzphLCb2x1zT_2GoLAuow-9nhUxZTGP2_Hkmt-fF6xwER0MN6WEJwrv4srHRs1hIE_z8KA4r-etfz4fGywMsjkHEzQey92ow7VtdKk2oBEnBbmBjyphkLvPLT8Zv0c4yoo7PZ4cipEhc4ltH3qiVp9NM5vk4iu7KLSRdUpL-rt2XSEgeNY0KiHPJDnZq8KQTHOIh9iguvuqHQpveG-YG0UJHnNyfaZIQjhA42Ge47KYnWOCmMMWg&x-client-SKU=ID_NET6_0&x-client-ver=6.35.0.0
    ```

  - ![ClientToAuth](https://raw.githubusercontent.com/Sean2416/Pic/master/img/AuthClient01.png)

- ##### User登入驗證成功後，轉回Client 並且帶上Auth Code

  - ![ClientToAuth](https://raw.githubusercontent.com/Sean2416/Pic/master/img/AuthClient02.png)

- ##### Client 取得GrandCode並附上Client資訊至AuthServer換取User 的AccessToken、ID Token

  - ###### 使用OpenID驗證時，後續User在操作Client可以直接透過ID Token驗證User身分，不需要再回到Auth Server

- ##### 前端將Token資訊儲存至Local Storage，並於每次打API時附帶

  - ![ClientToAuth](https://raw.githubusercontent.com/Sean2416/Pic/master/img/AuthClient04.png)

  - ![ClientToAuth](https://raw.githubusercontent.com/Sean2416/Pic/master/img/AuthClient05.png)

- ##### User透過Client呼叫Resource Server的API取得被保護資料

  - ###### 過程中會夾帶User Access Token供Resource Server至Auth Server驗證，若符合驗證範圍則回傳資訊

  - ```C#
    builder.Services.AddHttpClient("MovieAPIClient", client =>
    {
        client.BaseAddress = new Uri(builder.Configuration.GetConnectionString("MoviesApiGw") ?? throw new Exception("MoviesApi connection string is missing"));
        client.DefaultRequestHeaders.Clear();
        client.DefaultRequestHeaders.Add(HeaderNames.Accept, "application/json");
    })
    //Add user access token handler to an HttpClient
    .AddUserAccessTokenHandler();
    
    //參考(https://github.com/Sean2416/MicroservicePractice/blob/master/src/Services/Movies/Movies.Client/HttpHandlers/AuthenticationDelegatingHandler%.cs)
    
    ```

  - ```bash
     //AccessToken 內容
     "exp": 1706362173,
      "iss": "https://localhost:5006",
      "client_id": "movies_mvc_client",
      "sub": "88421113",
      "auth_time": 1706358573,
      "idp": "local",
      "jti": "A82304E3A1E610BAAF2DD2508D71884A",
      "sid": "25B160F4A80025E0C406C598834A2ED9",
      "iat": 1706358573,
      "scope": [
        "openid",
        "profile",
        "address",
        "email",
        "roles",
        "MovieAPI"
      ],
      "amr": [
        "pwd"
      ]
    }
    ```

#### Client Credentials

- ##### Client透過預先註冊在Auth Server的設定進行驗證、授權

- ##### 透過ClientId、ClientSecret及Scope進行身分驗證並取得AccessToken

- ##### 透過AccessToken至Resource Server換取被保護的資訊

  - ##### Auth Server會驗證Scope內容及Token

- ##### 範例

  - ```C#
    /// <summary>
    /// 使用Client Credential
    /// </summary>
    public async Task<IEnumerable<Movie>> GetMoviesOld()
    {
        TokenResponse token;
        var is4client = new HttpClient();
        var apiClientCredentials = new ClientCredentialsTokenRequest
        {
            //Auth Server位置
            Address = "https://localhost:5006/connect/token",
            ClientId = "MovieClient",
            ClientSecret = "testSecret",
            Scope = "MovieAPI"
        };
        var disco = await is4client.GetDiscoveryDocumentAsync("https://localhost:5006");
        if (disco.IsError)
        {
            throw new Exception(disco.Error);
        }
        
        //取得AccessToken
        token = await is4client.RequestClientCredentialsTokenAsync(apiClientCredentials);
    
        using var client = new HttpClient();
        //呼叫Resource API 並夾帶Token
        client.SetBearerToken(token.AccessToken ?? throw new Exception("Bearer token is null"));
        var response = await client.GetAsync("https://localhost:5001/api/movies");
        response.EnsureSuccessStatusCode();
        var content = await response.Content.ReadAsStringAsync();
        var movies = JsonSerializer.Deserialize<IEnumerable<Movie>>(content, new JsonSerializerOptions { PropertyNameCaseInsensitive = true });
        return movies ?? new List<Movie>();
    }
    ```



### SampleCode

#### Auth Server

- ##### 參考 : [Auth Server](https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/IdentityServer/NewServer)

- ##### 安裝套件 IdentityServer 4 

- ##### Start up導入.Net Identity做身分驗證

  - ```c#
     builder.Services.AddDbContext<AspNetIdentityDbContext>(options =>
        options.UseSqlServer(defaultConnString,
            b => b.MigrationsAssembly(assembly)));
    
    builder.Services.AddIdentity<ApplicationUser, IdentityRole>()
        .AddEntityFrameworkStores<AspNetIdentityDbContext>();
    
    ```

##### 加入Identity Server設定

- ```C#
  builder.Services.AddIdentityServer(options =>
  {
      options.Events.RaiseErrorEvents = true;
      options.Events.RaiseInformationEvents = true;
      options.Events.RaiseFailureEvents = true;
      options.Events.RaiseSuccessEvents = true;
  
      options.UserInteraction = new UserInteractionOptions
      {
          LogoutUrl = "/Account/Logout",
          LoginUrl = "/Account/Login",
          LoginReturnUrlParameter = "returnUrl"
      };
  })
      .AddAspNetIdentity<ApplicationUser>()
      .AddConfigurationStore(options =>
      {
          options.ConfigureDbContext = b =>
          b.UseSqlServer(defaultConnString, opt => opt.MigrationsAssembly(assembly));
      })
      .AddOperationalStore(options =>
      {
          options.ConfigureDbContext = b =>
          b.UseSqlServer(defaultConnString, opt => opt.MigrationsAssembly(assembly));
      })
      .AddDeveloperSigningCredential();
  
  app.UseIdentityServer();
  app.UseAuthorization();
  ```

##### 加入第三方登入

- ```C#
  builder.Services.AddAuthentication()
      .AddGoogle(googleOptions =>
      {
          //預設的External login方法會從這個Scheme取資料
          googleOptions.SignInScheme = IdentityServerConstants.ExternalCookieAuthenticationScheme;
          googleOptions.ClientId = "474316682203-bm7eh846qfm6kc2qs1e2uqm76bjso97b.apps.googleusercontent.com";
          googleOptions.ClientSecret = "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";
      })
  .AddLine(options =>
  {
       options.SignInScheme = IdentityServerConstants.ExternalCookieAuthenticationScheme;
          options.Scope.Add("real_name");
          options.Scope.Add("gender");
          options.Scope.Add("birthdate");
          options.Scope.Add("address");
          options.Scope.Add("phone");
          options.Scope.Add("email");
          options.ClaimActions.MapJsonKey(ClaimTypes.Email, "email");
          options.ClientId = "2003601821";
          options.ClientSecret = "f67d1c3871877619e842cb20c8f2db3e";
      });
  ```

##### 定義Client

- ##### ClientId、ClientSecret用於驗證Client身分

- ##### ClientScope用於初始化此Client 的權限範圍，登入時若不指定則以此Scope為主。若登入時指定不存在的Scope則驗證錯誤

- ```C#
  //定義OAuth Client資訊
  //定義OAuth Client資訊
  public static IEnumerable<Client> Clients =>
      new List<Client>
      {
        new Client
          {
              ClientId="MovieClient",
              AllowedGrantTypes=GrantTypes.ClientCredentials,
              ClientSecrets={new Secret("testSecret".Sha256())},
              AllowedScopes={ "MovieAPI" }
          },
          new Client
          {
              ClientName = "vuejs_code_client",
              ClientId = "vuejs_code_client",
              ClientSecrets = { new Secret("ClientSecret1".Sha256()) },
              AllowedGrantTypes = GrantTypes.Code,
               RedirectUris = new List<string>
              {
                  "https://localhost:44357",
                  "https://localhost:44357/callback.html",
                  "https://localhost:44357/silent-renew.html"
              },
                PostLogoutRedirectUris = new List<string>
              {
                  "https://localhost:44357/",
                  "https://localhost:44357"
              },
              AllowedCorsOrigins = new List<string>
              {
                  "https://localhost:44357"
              },
              AllowOfflineAccess = true,
              AllowedScopes = {
                  IdentityServerConstants.StandardScopes.OpenId,
                  IdentityServerConstants.StandardScopes.Profile,
                  IdentityServerConstants.StandardScopes.Address,
                  IdentityServerConstants.StandardScopes.OfflineAccess,
                  IdentityServerConstants.StandardScopes.Email,
                  "roles",
                  "MovieAPI"
              },
              RequireClientSecret = false,
              RequirePkce = true,
              //AccessToken的類型
              AccessTokenType = AccessTokenType.Jwt,
          },
      };
  ```
  
- ##### 登入測試

  - ###### Scope指定內容不存在於設定時，會導致驗證錯誤(大小寫也會判斷)

  - ```shell
    curl --location 'https://localhost:5005/connect/token' \
    --header 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'grant_type=client_credentials' \
    --data-urlencode 'scope=MovieAPI' \
    --data-urlencode 'client_id=MovieClient' \
    --data-urlencode 'client_secret=testSecret'
    ```

- ##### 定義Scope內容

  - ###### 列舉可使用的權限清單

  - ###### Scope是定義Client有沒有權限使用資料，而非針對User

  - ```C#
     public static IEnumerable<IdentityResource> IdentityResources =>
        new List<IdentityResource>
        {
            new IdentityResources.OpenId(),
            new IdentityResources.Profile(),
            new IdentityResources.Address(),
            new IdentityResources.Email(),
            new IdentityResource("roles","Your role(s)", new List<string>(){ "role" })
        };
      
    //定義Client可使用的Scope
    public static IEnumerable<ApiScope> ApiScopes =>
        new List<ApiScope>
        {
            new ApiScope("None", "None"),
            new ApiScope("MovieAPI", "Movie API", userClaims: new[] { "role" })
        };
    
    ```
    

##### Resource Server設定

- ###### 主要是解析Access Token內的值來驗證Client有沒有得到User 授權，而非驗證User身分

- ###### 設定Identity 引用及相關Policy

  - ```C#
    //加入OAuth驗證
    builder.Services.AddAuthentication("Bearer")
    .AddJwtBearer("Bearer", options => {
        options.Authority = "https://localhost:5006";
        options.TokenValidationParameters = new Microsoft.IdentityModel.Tokens.TokenValidationParameters
        {
            ValidateAudience = false,
        };        
    });
    
    
    builder.Services.AddAuthorization(options => {
        //定義授權策略，Claims裡面的Scope必須要有指定內容才符合規則
        //Scope是驗證Client有沒有權限使用資料，而非針對User
        options.AddPolicy("APIScopePolicy", policy => policy.RequireClaim("scope", "MovieAPI", "TestAPI"));
    });
    
    ```


#### Resource Server設定

- ##### 參考: [Resource Server](https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/Movies/Movies.API)

- ##### 引用 `Microsoft.AspNetCore.Authentication.JwtBearer`

- ##### 設定Startup

  - ```C#
    //加入OAuth驗證
    builder.Services.AddAuthentication("Bearer")
    .AddJwtBearer("Bearer", options => {
        options.Authority = "https://localhost:5443";
        options.TokenValidationParameters = new Microsoft.IdentityModel.Tokens.TokenValidationParameters
        {
            ValidateAudience = false,
        };        
    });
    
    //加入Policy作為驗證規則
    builder.Services.AddAuthorization(options => {
        //定義授權策略，Claims裡面的Client_id必須要為MovieClient才能使用
        options.AddPolicy("APIScopePolicy", policy => policy.RequireClaim("scope", "MovieAPI"));
    });
    
    app.UseAuthentication();
    app.UseAuthorization();
    ```

- ###### 指定驗證Policy

  - ```C#
    [ApiController]
    [Authorize("APIScopePolicy")]
    [Route("api/[controller]")]
    public class MoviesController : ControllerBase
    {
        private readonly IMovieRepository _repository;
    
        public MoviesController(IMovieRepository repository)
        {
            _repository = repository ?? throw new ArgumentNullException(nameof(repository));
        }
    
    ```

#### Ocelot設定

- ##### 透過Ocelot在每次request進來時先做Auth 驗證

- ##### [API Getway](https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/APIGetway/APIGetway)

- ##### 引用 `Microsoft.AspNetCore.Authentication.JwtBearer`

- ##### Program設定

  - ```C#
    builder.Configuration.AddJsonFile("ocelot.json", false, true);
    
    builder.Services.AddAuthentication()
        .AddJwtBearer("IdentitySetting", options =>
        {
            options.Authority = "https://localhost:5006";
            options.TokenValidationParameters.ValidateAudience = false;
        });
    
    builder.Services.AddOcelot(builder.Configuration);
    
    ```

- ##### Json 檔案設定

  - ```javascript
    {
      "Routes": [
        {
          //外部對應路徑 https://localhost:5010/movies
          "UpstreamPathTemplate": "/movies",
          "UpstreamHttpMethod": [ "GET", "POST" ],
          "AuthenticationOptions": {
          	//對應Program 中的Auth設定名稱
            "AuthenticationProviderKey": "IdentitySetting",
            //檢驗AccessToken裡面是否有指定的Scope
            "AllowedScopes": [ "MovieAPI" ]
          },
          //對應內部API實際位置
          "DownstreamPathTemplate": "/api/movies",
          "DownstreamScheme": "https",
          "DownstreamHostAndPorts": [
            {
              "Host": "localhost",
              "Port": 5001
            }
          ]
        },
        {
          "DownstreamPathTemplate": "/api/movies/{id}",
          "DownstreamScheme": "https",
          "DownstreamHostAndPorts": [
            {
              "Host": "localhost",
              "Port": 5001
            }
          ],
          "UpstreamPathTemplate": "/movies/{id}",
          "UpstreamHttpMethod": [ "GET", "PUT", "DELETE" ],
          "AuthenticationOptions": {
            "AuthenticationProviderKey": "IdentitySetting",
            "AllowedScopes": [ "MovieAPI123" ]
          }
        }
      ]
    }
    ```


#### SPA 設定

- ##### 參考: [Vue PKCE](https://github.com/Sean2416/MicroservicePractice/tree/master/ExternalSample/VueJsOidcClient/vue-js-oidc-client)

- ##### 建立 AuthService  處理驗證相關流程

  - ```javascript
    export default class AuthService {
        private userManager: UserManager;
    
        constructor() {
            const STS_DOMAIN: string = 'https://localhost:5006';
    
            const settings: any = {
                userStore: new WebStorageStateStore({ store: window.localStorage }),
                authority: STS_DOMAIN,
                client_id: 'vuejs_code_client',
                redirect_uri: 'https://localhost:44357/callback.html',
                automaticSilentRenew: true,
                silent_redirect_uri: 'https://localhost:44357/silent-renew.html',
                response_type: 'code',
                scope: 'openid profile MovieAPI',
                post_logout_redirect_uri: 'https://localhost:44357/',
                filterProtocolClaims: true,
            };
    
            this.userManager = new UserManager(settings);
        }
    
        public getUser(): Promise<User | null> {
            return this.userManager.getUser();
        }
    
        public login(): Promise<void> {
            return this.userManager.signinRedirect();
        }
    
        public logout(): Promise<void> {
            return this.userManager.signoutRedirect();
        }
    
        public getAccessToken(): Promise<string> {
            return this.userManager.getUser().then((data: any) => {
                return data.access_token;
            });
        }
    }
    ```

- ##### Call Resource API With Access Token

  - ```javascript
    public getProtectedApiData() {
    
        const authorizationHeader = 'Authorization';
        auth.getAccessToken().then((userToken: string) => {
            axios.defaults.headers.common[authorizationHeader] = `Bearer ${userToken}`;
    
            axios.get('https://localhost:5010/movieapi/movies')
                .then((response: any) => {
                    this.dataEventRecordsItems = response.data;
                })
                .catch((error: any) => {
                    alert(error);
                });
        });
    }
    ```

#### 其他設定

- ##### [Client MVC](https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/Movies/Movies.Client)

- [Client Backend](https://github.com/Sean2416/MicroservicePractice/tree/master/src/Services/Practice/TestAPI)

  

## 參考

- [OpenID Connect 是什麼？](https://hennge.com/tw/blog/what-is-openid-connect.html)

- [OIDC](https://hackmd.io/@Burgess/rkjLdxbmU)

- [以Line說明OAuth](https://petertc.medium.com/oauth-2-0-196a5550b668)

- [OAuth 流程](https://medium.com/@henry-chou/oauth-%E6%B5%81%E7%A8%8B-101-9a1575c422dc)

- [OAuth和SSO](http://studyhost.blogspot.com/2017/01/oauthsso.html)

- [OAuth 2.0 筆記 (1) 世界觀](https://blog.yorkxin.org/posts/oauth2-1-introduction/)

- [OAuth 2.0](https://blog.kenwsc.com/posts/2022/oauth-2-0-roles-and-channels/)

- [ASP.NET Identity 如何取得 Facebook 登入的 Access Token](https://blog.miniasp.com/post/2014/04/13/ASPNET-Identity-Get-Access-Token-Facebook)

- [ASP.NET Identity with Identity Server 4 | Tutorial](https://www.youtube.com/watch?v=SXJ377G5bOg)

- [在 ASP.NET Core 整合 Google 做為網站的第三方登入](https://dotblogs.com.tw/supershowwei/2022/11/10/integrate-google-login-in-asp-net-core)

- [Google OAuth 2.0 OpenID Connect with Authorization Code Flow](https://blog.maki0419.com/2022/09/angular2-aspnet-webapi-google-oauth2-oidc-auth-code-flow.html)

- [Vue with pkce sample](https://github.com/damienbod/IdentityServer4VueJs)

- [Securing a Vue.js app using OpenID Connect Code Flow with ...](https://damienbod.com/2019/01/29/securing-a-vue-js-app-using-openid-connect-code-flow-with-pkce-and-identityserver4/)

  ##### 

# Ocelot

##  Api Gateway

- ##### API閘道器是一個伺服器，是系統的唯一入口。API閘道器封裝了系統內部架構，為每個客戶端提供一個定製的API。

- ##### 所有的客戶端和消費端都通過統一的閘道器接入微服務，在閘道器層處理所有的非業務功能。通常，閘道器也是提供REST/HTTP的訪問API。服務端通過API-GW註冊和管理服務。

- ##### API 閘道器是客戶端訪問服務的統一入口，API 閘道器封裝了後端服務，還提供了一些更高階的功能，例如：身份驗證、監控、負載均衡、快取、多協議支援、限流、熔斷等等。

  - ###### 限流：實現微服務訪問流量計算，基於流量計算分析進行限流，可以定義多種限流規則。

  - ###### 快取：資料快取。

  - ###### 日誌：日誌記錄。

  - ###### 監控：記錄請求響應資料，api耗時分析，效能監控。

  - ###### 鑑權：許可權身份認證。

  - ###### 灰度：線上灰度部署，可以減小風險。

  - ###### 路由：路由是API閘道器很核心的模組功能，此模組實現根據請求，鎖定目標微服務並將請求進行轉發。

- ![img](https://images2018.cnblogs.com/blog/381412/201806/381412-20180611222135221-64112379.png)

## Implement

### 實作步驟

1. ##### 建立空白套件

2. ##### Install-Package Ocelot

3. ##### 設定`Program.cs`

   ```C#
   public class Program
   {
       public static void Main(string[] args)
       {
           CreateHostBuilder(args).Build().Run();
       }
   
       public static IHostBuilder CreateHostBuilder(string[] args) =>
           Host.CreateDefaultBuilder(args)
           //對於 Ocelot 而言，此處的重點是您必須透過 AddJsonFile() 方法提供給產生器的 configuration.json 檔案
               .ConfigureAppConfiguration((hostingContext, config) =>
               {
                   config.AddJsonFile($"ocelot.{hostingContext.HostingEnvironment.EnvironmentName}.json", true, true);
               })
               .ConfigureWebHostDefaults(webBuilder =>
               {
                   webBuilder.UseStartup<Startup>();
               });
   }
   ```

4. ##### 設定 `Startup.cs` 

   ```C#
   public void ConfigureServices(IServiceCollection services)
   {
       services.AddOcelot();
   }
   
   // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.
   public async void Configure(IApplicationBuilder app, IWebHostEnvironment env)
   {
       ...
           
       await app.UseOcelot();
   }
   ```

5. ##### 建立設定檔案

### Ocelot .Json

- ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/91882e5808b330a088525cb2ff2d4c99d8b471d70dc895f9c6c079277aa86ad3.png)

#### 基本架構

- ###### Routes 是告知 Ocelot 如何處理上游要求的物件

- ###### Ocelot API 閘道的主要功能是接受傳入 HTTP 要求並將其轉送到下游服務 

- ###### BaseUrl定義對外的URL

- ###### Route

  - 當Client發送一個Request`GET https://api.mybusiness.com/Catalog`

  - ###### ApiGetway根據設定內容，找到Upstream設定為/Catalog 且方法為Get的設定檔

  - ###### 導引至對應的URL `http://localhost:8000/api/v1/Catalog`

  - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207092303548.png)

- ```C#
  {
      "Routes": [
          //Catalog API
          {
            //Downstream 對應內部服務設定
            "DownstreamPathTemplate": "/api/v1/Catalog",
            "DownstreamScheme": "http",
            "DownstreamHostAndPorts": [
              {
                "Host": "localhost",
                "Port": "8000"
              }
            ],
            //外部服務呼叫路徑
            "UpstreamPathTemplate": "/Catalog",
            "UpstreamHttpMethod": [ "GET", "POST", "PUT" ],
            "FileCacheOptions": { "TtlSeconds": 30 }
          },
          {
            "DownstreamPathTemplate": "/api/v1/Basket/Checkout",
            "DownstreamScheme": "http",
            "DownstreamHostAndPorts": [
              {
                "Host": "localhost",
                "Port": "8001"
              }
            ],
            "UpstreamPathTemplate": "/Basket/Checkout",
            "UpstreamHttpMethod": [ "POST" ],
            "RateLimitOptions": {
              "ClientWhitelist": [],
              "EnableRateLimiting": true,
              "Period": "3s",
              "PeriodTimespan": 1,
              "Limit": 1
            }
          }
      ],
      "GlobalConfiguration": {
          "BaseUrl": "https://api.mybusiness.com"
      }
  }
  ```

#### 區分大小寫

- ###### 預設不區分

- ###### 想要過濾大小寫的話可以在設定檔加入`"RouteIsCaseSensitive": true`

#### 流量限制- RateLimitOptions

- `ClientWhitelist` - 設定Client白名單清單，在清單內的Client不會受到流量限制。

- `EnableRateLimiting` - 是否開啟流量限制。

- `Period` - 指定流量限制時間，例如1s，5m，1h，1d等,

- `PeriodTimespan` - 恢复等待时间，當訪問次數超過限制數時，需等待多長時間才能再次訪問

- `Limit` - 指定Client在時間(`Period` )內允許的最大請求數

- ##### 下方設定檔案說明

  - ##### 指定Client在1分鐘之內僅能發起一次請求，超過則block request

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101016301.png)
    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101008111.png)

  - ##### 在block 30後秒才能再次發送請求

- ```C#
  {
    "DownstreamPathTemplate": "/api/v1/Catalog",
    "DownstreamScheme": "http",
    "DownstreamHostAndPorts": [
      {
        "Host": "localhost",
        "Port": "8000"
      }
    ],
    "UpstreamPathTemplate": "/Catalog",
    "UpstreamHttpMethod": [ "GET", "POST", "PUT" ],
    "RateLimitOptions": {
      "ClientWhitelist": [],
      "EnableRateLimiting": true,
      "Period": "1m",
      "PeriodTimespan": 30,
      "Limit": 1
    }
  ```

#### Cache

- 加入方法

  - 下載`Install-Package Ocelot.Cache.CacheManager`

  - 調整`ConfigureServices`

    - ```C#
      s.AddOcelot()
          .AddCacheManager(x =>
          {
              x.WithDictionaryHandle();
          })
      ```

  - ##### 加入設定檔

    - ```C#
      "FileCacheOptions": {
        "TtlSeconds": 300, // Cache保留時間
        "Region": "somename" //自定義區域名稱,代表Cache要配置到哪個暫存區
      }
      ```

- 使用結果

  - ###### 可以看到Ocelot 在第一次取得Catalog資料後就存入Cache中(由於Cache保留時間為五分鐘)，因此後面雖然更新了`62bf05b24f0daf9c82e4810d`的資料內容

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101041771.png)

  - ###### 但是透過Ocelot取得的資料依舊是舊的，必須等到Cache被清除後資料才會回去本地端服務蟲抓

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101040433.png)

  - ##### 不透過Ocelot，直接呼叫API看資料確定是更新過

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101043563.png)

#### Request Aggregation

- ##### 將多個request聚合成一個response

- ##### 配置步驟

  1. ######  給定每一個要聚合的request 唯一key值

  2. ######  新增聚合設定`Aggregates`

     - ```C#
       {
           "DownstreamPathTemplate": "/api/v1/Catalog",
           "DownstreamScheme": "http",
           "DownstreamHostAndPorts": [
             {
               "Host": "localhost",
               "Port": "8000"
             }
           ],
           "Key": "Catalog", //給定每一個要聚合的request 唯一key值
           "UpstreamPathTemplate": "/Catalog",
           "UpstreamHttpMethod": [ "GET", "POST", "PUT" ],
           "FileCacheOptions": {
             "TtlSeconds": 30,
             "Region": "somename"
           }
         },
         {
           "DownstreamPathTemplate": "/api/v1/Discount/{Name}",
           "DownstreamScheme": "http",
           "DownstreamHostAndPorts": [
             {
               "Host": "localhost",
               "Port": "8002"
             }
           ],
           "Key": "Discount",
           "UpstreamPathTemplate": "/Discount/{Name}",
           "UpstreamHttpMethod": [ "GET", "DELETE" ]
         }
       ],
       "Aggregates": [
         {
           "RouteKeys": [ //對應步驟1建立的key清單
             "Catalog",
             "Discount"
           ],
           "UpstreamPathTemplate": "/GetDetail/{Name}" //開放給Client呼叫的API端
         }
       ],
       "GlobalConfiguration": {
         "BaseUrl": "http://localhost:5010"
       }
       ```

  3. ##### 如果要針對各聚合做處理，可以建立繼承`IDefinedAggregator`的類別

     1. ###### 建立繼承`IDefinedAggregator`的類別，並實作Aggregate

        ```C#
        public class MyAggregator : IDefinedAggregator
        {
            public async Task<DownstreamResponse> Aggregate(List<HttpContext> responses)
            {
                var one = await responses[0].Items.DownstreamResponse().Content.ReadAsStringAsync();
                var two = await responses[1].Items.DownstreamResponse().Content.ReadAsStringAsync();
        
                var contentBuilder = new StringBuilder();
                contentBuilder.Append(one);
                contentBuilder.Append(two);
        
                var stringContent = new StringContent(contentBuilder.ToString())
                {
                    Headers = { ContentType = new MediaTypeHeaderValue("application/json") }
                };
        
                return new DownstreamResponse(stringContent, HttpStatusCode.OK, new List<KeyValuePair<string, IEnumerable<string>>>(), "OK");
            }
        }
        ```

     2. ###### 於ConfigureServices進行註冊

        ```C#
        public void ConfigureServices(IServiceCollection services)
        {
            services.AddOcelot().AddCacheManager(x =>
            {
                x.WithDictionaryHandle();
            })
            .AddSingletonDefinedAggregator<MyAggregator>();
        }
        ```

     3. ###### 新增至設定檔

        ```C#
        {
        	"Aggregates": [
                {
                  "RouteKeys": [
                    "User",
                    "Product"
                  ],
                  "UpstreamPathTemplate": "/UserAndProduct",
                  "Aggregator": "MyAggregator"
                }
              ],
        }
        ```

#### 啟動所有Route

- ###### 这个配置将会把路径+查询字符串统统轉發到本地端.

- ###### URL只是變數名稱，可隨時替換

  - ###### 這種配置方式優先權最低，如果request在設定檔中有對應的設定會優先配對

- ```C#
  {
      "DownstreamPathTemplate": "/{url}",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
              {
                  "Host": "localhost",
                  "Port": 1001,
              }
          ],
      "UpstreamPathTemplate": "/{url}",
      "UpstreamHttpMethod": [ "Get" ]
  }
  ```

#### 優先權設定

- ###### 在route裡面可以設定Priority指定配對全縣

- ###### 0 是最低優先級

- ```C#
  {
      "UpstreamPathTemplate": "/goods/{catchAll}"
      "Priority": 0
  }
  
  {
      "UpstreamPathTemplate": "/goods/delete"
      "Priority": 1
  }
  //上面两个路由中，如果向Ocelot发出的请求时/goods/delete格式的话，则Ocelot会优先匹配/goods/delete 的路由。
  ```

#### Docker設定

- ##### 在Docker中，服務之間可以透過`ContainerName`進行呼叫而不用指定URL(就像在YML檔裡面設定連接資料庫也是直接使用Container Name同理)

  - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207101100714.png)

- ##### 因此，JsonFile內的`DownstreamHostAndPorts`也可以直接使用Container做設定

  - ```C#
    {
      "DownstreamPathTemplate": "/api/v1/Catalog",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "catalog.api", //ContainerName
          "Port": "80" //Port 為Image設定的內部Port，並非Container對外的Port
        }
      ],
      "UpstreamPathTemplate": "/Catalog",
      "UpstreamHttpMethod": [ "GET", "POST", "PUT" ],
      "FileCacheOptions": { "TtlSeconds": 30 }
    },
    ```


#### Load Balancer

- ##### Ocelot可以針對每一個request進行load balanceg設定

- ##### 演算法如下

  - ###### LeastConnection : 將request導向最少request的service

  - ###### RoundRobin : 依序呼叫

  - ###### NoLoadBalancer : 直接使用第一個能夠運行的服務

  - ###### CookieStickySessions : 依據Client Cookie導向特定服務

- ##### 建立步驟

  - ###### 針對服務加入Load Balancer

    - ```C#
      "Routes": [
      //Catalog API
      {
        "DownstreamPathTemplate": "/api/v1/Catalog",
        "DownstreamScheme": "http",
        "DownstreamHostAndPorts": [
          {
            "Host": "localhost",
            "Port": "8900"
          },
          {
            "Host": "localhost",
            "Port": "8000"
          }
        ],
        "LoadBalancerOptions": {
          "Type": "RoundRobin"
        },
      }
      ]
      ```

  - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207111352561.png)

### Service Discovery





### With  IdSvr

- ##### Program

  - ```C#
    builder.Configuration.AddJsonFile("ocelot.json", false, true);
    
    builder.Services.AddAuthentication()
        .AddJwtBearer("IdentitySetting", options =>
        {
            options.Authority = "https://localhost:5006";
            options.TokenValidationParameters.ValidateAudience = false;
        });
    
    builder.Services.AddOcelot(builder.Configuration);
    
    ```

    

- ##### Json 檔案設定

  - ```javascript
    {
      "Routes": [
        {
          //外部對應路徑 https://localhost:5010/movies
          "UpstreamPathTemplate": "/movies",
          "UpstreamHttpMethod": [ "GET", "POST" ],
          "AuthenticationOptions": {
          	//對應Program 中的Auth設定名稱
            "AuthenticationProviderKey": "IdentitySetting",
            //檢驗AccessToken裡面是否有指定的Scope
            "AllowedScopes": [ "MovieAPI" ]
          },
          //對應內部API實際位置
          "DownstreamPathTemplate": "/api/movies",
          "DownstreamScheme": "https",
          "DownstreamHostAndPorts": [
            {
              "Host": "localhost",
              "Port": 5001
            }
          ]
        },
        {
          "DownstreamPathTemplate": "/api/movies/{id}",
          "DownstreamScheme": "https",
          "DownstreamHostAndPorts": [
            {
              "Host": "localhost",
              "Port": 5001
            }
          ],
          "UpstreamPathTemplate": "/movies/{id}",
          "UpstreamHttpMethod": [ "GET", "PUT", "DELETE" ],
          "AuthenticationOptions": {
            "AuthenticationProviderKey": "IdentitySetting",
            "AllowedScopes": [ "MovieAPI123" ]
          }
        }
      ]
    }
    ```

    



## 參考

- [Ocelot_實用技巧 - 程式人生](https://www.796t.com/article.php?id=123886)
- [Ocelot簡易教程](https://github.com/yilezhu/OcelotDemo/wiki)
- [Getting Started — 官網](https://ocelot.readthedocs.io/en/latest/introduction/gettingstarted.html)
- [NET Core 微服務—Request Aggregation](https://codingnote.cc/zh-tw/p/172313/)
- [net core使用ocelot-](https://www.zendei.com/article/80621.html)



# Kubernetes 

## Quick start

1. #####  安裝K8S及Docker

   - 確認本機開啟Hyperv
   - 確認本機模擬開啟
     - 開啟方式: 進入Bios >  CPU選項> 開啟虛擬化
     - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202206190955608.png)
   - 安裝minikube 、 kubectl 套件

2. ##### 製作Docker Container

   - 實作Docker Image並推行上Register(此處使用[Docker hub](https://hub.docker.com/)， Docker 必須啟動)

   - ```powershell
     > docker login -u sean2416 -p A128277902
     
     > docker tag icw_cloud sean2416/docker-demo:latest
     
     > docker push sean2416/docker-demo:latest
     ```

3. ##### 啟動 Minikube 

   - `minikube start --vm-driver=hyperv`

4. ##### Minikube 上跑起你的 Docker Containers 

   - 透過Container 建立 K8S pod

   - 撰寫yaml檔案

     - ```yaml
       # my-first-pod.yaml
       apiVersion: v1
       kind: Pod
       metadata:
         name: my-pod
         labels:
           app: webserver
       spec:
         containers:
         - name: pod-demo
           image: sean2416/docker-demo
           ports:
           - containerPort: 80
       ```

   - 建立Pod

     - ```yaml
        kubectl create -f my-first-pod1.yaml
       ```

   - 查看Pod

     - ```
       kubectl get pods 
       ```

5. ##### 與 Pod 中的 container 互動

   1. 透過kubectl port-forward

      - 將Container所在的 80 port 對應到外部8000(內部Port參考Image建置時所指定的Port號)
      - `kubectl port-forward my-pod 8000:80`
      - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202206191010205.png)

   2.  建立一個 Service

      - **kubectl port-forward 是將 pod 的 port mapping 到本機端上，而 kubectl expose 則是將 pod 的 port 與 Kubernetes Cluster 的 port number 做 mapping。**

      -  `kubectl expose` 指令，創建 `my-pod-service` 的 Service 物件

        - ```powershell
          > kubectl expose pod my-pod --type=NodePort --name=my-pod-service
          service/my-pod-service exposed
          ```

      - 查看Service狀態

        - ```powershell
          > kubectl get services
          NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
          kubernetes       ClusterIP   10.96.0.1        <none>        443/TCP        36h
          my-pod-service   NodePort    10.107.219.187   <none>        80:32446/TCP   2s
          ```

      - 取得service URL

        - ```
          > minikube service my-pod-service --url
          http://172.31.143.191:30447
          ```

6. ##### 建立Deployment

   1. 建立yaml檔案

      - ```yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: hello-deployment
        spec:
          replicas: 3
          selector:
            matchLabels:
              app: my-deployment
          template:
            metadata:
              labels:
                app: my-deployment
            #在一個Pod中 產生兩個Container
            spec:
              containers:
              - name: my-pod
                image: zxcvbnius/docker-demo:latest
                ports:
                - containerPort: 3000        
              - name: pod-demo
                image: sean2416/docker-demo
                ports:
                - containerPort: 80
        ```

   2. 新增Deployment `kubectl create -f ./my-deployment.yaml`

   3. 查看Delplyment ` kubectl get deployments`

7. ##### 建立Service

   - 建立yaml檔案

     - ```yaml
       # service-example.yaml
       apiVersion: v1
       kind: Service
       metadata:
         name: hello-service
       spec:
         type: NodePort
         ports:
           - name: http-test1
             port: 80  #對應Container Port
             protocol: TCP
             nodePort: 30390
           - name: http-test2
             port: 3000
             protocol: TCP
             nodePort: 30391
         selector:
           app: my-deployment
       ```

   - ##### 產生Service

     - ```
        kubectl create -f ./my-service.yaml
       ```

     

- ###### 參考文章

  - [How to install Kubernetes on windows 10](https://github.com/twtrubiks/k8s-tutorial/tree/master/How_to_install_k8s_on_win10)
  - [Minikube 安裝與配置](https://ithelp.ithome.com.tw/articles/10192490)
  - [Kubernetes - minikube (輕鬆建立本地端的 K8S 集群工具) 安裝教學](https://blog.kennycoder.io/2020/03/15/Kubernetes-minikube-%E8%BC%95%E9%AC%86%E5%BB%BA%E7%AB%8B%E6%9C%AC%E5%9C%B0%E7%AB%AF%E7%9A%84K8S%E9%9B%86%E7%BE%A4%E5%B7%A5%E5%85%B7-%E5%AE%89%E8%A3%9D%E6%95%99%E5%AD%B8/)



## 基本介紹

### 主要架構

​	

![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202206152030525.png)

![https://ithelp.ithome.com.tw/upload/images/20201001/20129737wF5PKYvbLN.png](https://ithelp.ithome.com.tw/upload/images/20201001/20129737wF5PKYvbLN.png)



#### Master Node

- ##### 管理和調度集群資源

- ##### Master Node主要用來管理Work Node(也就是Slave Node, Kubernetes Node)，進行工作的調配與規劃..等

  - ###### 取得master node components的狀態 `kubectl get componentstatuses`

  - ###### Get components detail `kubectl describe componentstatuses controller-manager`

##### ETCD(狀態存取數據庫)

- ##### 以Key-Value方式儲存資料

- ##### 常用來儲存設定檔或服務狀態

- ##### 提供Rest API 並以Json格式回傳

- ##### 用來存放 `K8s Cluster` 的資料作為備份，可以把他想像為整個集群的database，會記錄整個集群的狀態及資料。當 `Controller Plane` 故障時，可以透過 `etcd` 幫我們還原 `Kubernetes` 的狀態。

- ##### 優點

  - ###### 健康檢查: 服務節點定期向etcd發送心跳更新自己訊息的TTL

  - ###### 服務主動註冊: 同一類型的服務啟動後, 主動註冊到相同服務目錄下

  - ###### 方便透過服務名稱就能查詢到服務提供給外部訪問的IP與Port

  - ###### 服務之間能彼此即時感知, 新增節點、丟棄不可用的服務節點.


##### API Server

- ##### 提供HTTP Rest介面的關鍵服務處理程序，是集群中各個節點的溝通橋樑，並管理整個 `K8s` 所需 API 的接口`(Endpoint)`。

- ##### 提供集群管理的 REST API ，包括認證、授權、數據檢驗以及集群狀態變更等

- ##### 提供其他模組之間的數據交互和通訊的樞紐，其他模組只能通過 API Server 查詢或者修改數據，只有 API Server 才能直接操作 etcd

- ##### 透過API-Server對外曝露所有的Kubernetes API，亦可以把它當作是Kubernetes Control Plane的前端。而我們操作的Kubernetes ctl也是我們透過kubectl的方式與API-Server進行溝通

- ##### API-Server有著以下幾個功能：

  - ###### 提供API讓使用者能夠取得叢集內部各資源資訊、創建/更改/移除 各資源或下達調度策略對各資源進行調配。

  - ###### 代理群集當中一些額外組件，像是Kubernetes UI、metrics-server..etc

  - ###### 創建Kubernetes server

  - ###### 讓資源進行版本更新

- ###### 通過`kubectl proxy`得知目前叢集最上層的api path為何

##### Kube-Controller Manager

- ###### 這些 Process 會在 Cluster 與預期狀態（desire state）不符時嘗試更新現有狀態（current state）。例如：現在要多開一台機器以應付突然增加的流量，那我的預期狀態就會更新成 N+1，現有狀態為 N，這時相對應的 controller 就會想辦法多開一台機器

- ##### 負責管理並運行 Kubernetes controller 的組件，簡單來說 controller 就是 Kubernetes 裡一個個負責監視 Cluster 狀態的 Process

  - ###### Node controller: 負責當Node出現故障時的訊息通知與增減

  - ###### Replication controller: 負責管理Pods數量與狀態，但現在使用ReplicaSet居多

  - ###### Endpoints controller: 負責生成與維護所有endppoints物件(such as service)

  - ###### Service Account & Token controllers: 負責管理用戶帳戶與服務

##### Scheduler

- ##### 整個 Kubernetes 的 Pods 調度員，scheduler 會監視新建立但還沒有被指定要跑在哪個 Node 上的 Pod，並根據每個 Node 上面資源規定、硬體限制等條件去協調出一個最適合放置的 Node 讓該 Pod 跑

- ###### 依據機器資源、軟體資源(叢集)、調度決策、affinity and anti-affinity親和力與反親和力等多方考量，去決定Pods是否新建與Pods的數量分配(分配至Ｗorker Node)。因為每個Pods都會有自己的requirements(像是平均Memory用量超過50%新建、不建立該種Pod在Node-1上..等)，所以在叢集調度上並非易事，也因此有了該components的產生

- ###### affinity又有分成是Node affinity與 Pod affinity，affinity也是屬於種調度策略

##### 基本建置流程

- ![img](https://miro.medium.com/max/1050/0*5N7SlevIHOdKB-yC)

- ###### 上圖為一個簡易的 Kubernetes Cluster，通常一個 Cluster 中其實會有多個 Master 作為備援，但為了簡化我們只顯示一個

- ###### 當使用者要部 

- ###### 此時指令會經過一層確認使用者身份的認證後，傳遞到 Master Node 中的 API Server，API Server 會把指令備份到 etcd

- ###### 接下來 controller-manager 會從 API Server 收到需要創建一個新的 Pod 的訊息，並檢查如果資源許可，就會建立一個新的 Pod。

- ###### 最後 Scheduler 在定期訪問 API Server 時，會詢問 controller-manager 是否有建置新的 Pod，如果發現新建立的 Pod 時，Scheduler 就會負責把 Pod 配送到最適合的一個 Node 上面。

  

#### Kubernetes  Node

- ##### Worker node是用來部署容器的地方，也就是運行服務的機器，所以每個Node中必備著能夠建置容器的執行環境，像是Docker等。

  - ###### Get all nodes `kubectl get nodes`

  - ###### Describe specific node `kubectl describe nodes <node_name>`

  - ##### Addresses

    - ###### HostName: 該節點的host name，可以透過kubectl —hostname-override 來覆寫他。

    - ###### ExternalIP: 該節點可路由的外部IP，提供群集外部使用。

    - ###### InternalIP: 該節點可路由的內部IP，僅叢集內部能夠路由。

  - ##### Conditions

    - 描述所有運行節點目前的狀態，狀態的描述有以下幾種：

    - |   Node Condition   |                         Description                          |
      | :----------------: | :----------------------------------------------------------: |
      |       Ready        | True表示節點運行狀況良好並準備好接受Pod，False表示節點運行狀況不佳並且不接受Pod，Unknown表示節點控制器最近一次未從節點收到消息node-monitor-grace-period（默認值為40秒） |
      |    DiskPressure    |             True表示磁盤容量不足；除此以外False              |
      |   MemoryPressure   |             True表示節點內存不足; 除此以外False              |
      |    PIDPressure     |          True表示節點上的Process太多；除此以外False          |
      | NetworkUnavailable |           True表示節點的網絡配置不正確，否則 False           |

  - ##### Capacity and Allocatable

    - ###### 描述該節點上可用資源最大數量，包含cpu、memory與pods的數量

  - ##### System Info

    - ###### 該節點上各種軟硬體設備的訊息，包含uuid與版本號....等

##### Kubelet

- ###### Kubernetes是一個分散式的集群管理系統，在每個worker 上運行一個worker process對node上的Container做周期性管理，而這個worker就是Kubelet。

- ##### 主要功能

  - ###### Pod的管理: 如上述，一個pod由一或多個containers組成，彼此共享pod中的資源與port，所以同個pod間能透過localhost進行溝通，因此也可利用volume與mount將資源共享至多個容器當中，kubelet就是負責管理這些pod資源

  - ###### 健康檢查: 創建容器後，如果想確認容器是否正常啟動，可以加入health check在pod/deployment的yaml當中，再啟動pod時kubelet會去執行yaml中的health check，只要health check沒過kubelet就會刪除該pod並依照重啟策略處理(預設為刪除後不進行重啟)

  - ###### 容器監測: 透過建置cAdvisor進行監測。

##### CAdvisor

- ###### cAdvisor是一個worker，並即時性的對該Node上所有的資源與容器進行監測與數據的採集，像是CPU、Memory的用量、網路的流量與Storage的使用量等。cAdvisor集成於Kubelet當中，當使用Kubelet時會自動地啟動cAdvisor。

##### Proxy

- ![img](https://ithelp.ithome.com.tw/upload/images/20201002/20129737lEny7hhLuh.png)

- ###### 每個pod都會有個ip，但pod是經常在發生變化的，每次更新ip位置都會有變。為此kubernetes有個component叫做**service**，每個service都會有一組**固定的虛擬ip(clusterIp)**，並且自動地綁定某種類型的pod，有點類似某種pod的專用通道，所有對於該類型pod的request都會透過service進行load balance與redirect。為了實現該功能，在每個Node上都會有個Kube-Proxy，得以當作service, api-server與pod間溝通的橋樑。

##### POD

- ![img](https://miro.medium.com/max/872/1*Hvc0M9UutuTBNQoMRHMkAw.png)

- ##### Pod是在kubernetes當中，能夠創建與運行的最小執行單位，在Pod當中能夠有著一個或多個Containers，並且這些Containers共享著Pod的資源

  - ##### Pod有以下特點

    - ###### 每個 Pod 都有屬於自己的 [yaml](https://zh.wikipedia.org/wiki/YAML) 檔

    - ###### 一個 Pod 裡面可以包含一個或多個 Docker Container

    - ###### 在同一個 Pod 裡面的 containers，可以用 **local port numbers** 來互相溝通

- ##### yaml file

  - ```powershell
    # my-first-pod.yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-pod
      labels:
        app: webserver
    spec:
      containers:
      - name: pod-demo
        image: sean2416/docker-demo
        ports:
        - containerPort: 80 
        #注意可能要跟著Image裡面的expose port設定(待確認)
    ```

  - **apiVersion**

    - 代表目前 Kubernetes 中該元件的版本號。以上述的例子 `Pod` 是 `v1`，而 `v1也是目前Kubernetes中核心的版本號`

  - **metadata**

    - **name** - 指定名稱
    - **labels** - labels` 是 Kubernetes 的是核心的元件之一，Kubernetes 會透過 `Label Selector` 將Pod分群管理。
    - **annotations** - annotations 的功能與 labels 相似。相較於labels，`annotations 通常是使用者任意自定義的附加資訊`，提供外部進行查詢使用，像是版本號，發布日期等等。

  - ##### **spec**

    - 定義 container，在這個範例中，一個 Pod 只運行一個 container。
    - **name** - 我們可以在這 container 中設定 container 的名稱
    - **image** - Image 則是根據 [Docker Registry](https://docs.docker.com/registry/) 提供的可下載路徑。
    - **container.ports** - 以指定` container 有哪些 port number 是允許外部資源存取`，而在這裡我們只允許container中的port 3000對外開放。

  - ##### 建立Pod

    - `kubectl create -f my-first-pod.yaml`

  - 查看狀態

    - `kubectl get pods `

  - 取得更多描述

    - `kubectl describe pods my-pod`

##### Replication Controller

- ###### Kubernetes上用來管理Pod的數量以及狀態的controller

- ###### 每個Replication Controller都有屬於自己的 [yaml](https://zh.wikipedia.org/wiki/YAML) 檔

- ###### Replication Controller設定檔中`可以指定同時有多少個相同的Pods`運行在Kubernetes Cluster上

- ###### 當某一Pod發生crash, failed，而終止運行時，Replication Controller會幫我們自動偵測，並且自動創建一個新的Pod，確保`Pod運行的數量與設定檔的指定的數量相同`

- ###### 當機器重新開啟時，之前在機器上運行的 Replication Controller 會自動被建立，確保pod隨時都在運行。

- ###### yaml file

  - ```yaml
    apiVersion: v1
    kind: ReplicationController
    metadata:
      name: my-replication-controller
    spec:
      replicas: 3
      selector:
        app: hello-pod-v1
      template:
        metadata:
          labels:
            app: hello-pod-v1
        spec:
          containers:
          - name: my-pod
            image: zxcvbnius/docker-demo
            ports:
            - containerPort: 3000
    ```

  - **apiVersion**

    - 代表目前 Kubernetes 中該元件的版本號。以上述的例子 `Pod` 是 `v1`，而 `v1也是目前Kubernetes中核心的版本號`

  - **metadata**

    - **name** - 指定名稱
    - **labels** - labels` 是 Kubernetes 的是核心的元件之一，Kubernetes 會透過 `Label Selector` 將Pod分群管理。
    - **annotations** - annotations 的功能與 labels 相似。相較於labels，`annotations 通常是使用者任意自定義的附加資訊`，提供外部進行查詢使用，像是版本號，發布日期等等。
    - **replicas & selector**
      - 在`replicas`中，我們必須定義`Pod的數量`，
      - 在`spec.selector`中指定我們要選擇的Pod的條件(labels)。
    - **template** 
      - 定義pod的資訊，包含Pod的labels以及Pod中要運行的container。
    - **template.metadata**
      則是Pod的labels，metadata.labels必須被包含在`select`中，否則在創建Replication Controller物件時，會發生error。
    - **template.spec**
      - 定義container，可以參考 [Pod的yaml檔](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day05/demo-pod/my-first-pod.yaml) 的範例，在我們的範例中，一個Pod只有一個container。

  - ###### 透過 kubectl 操作 Replication Controller 物件

    - 透過`kubectl create`的指令，創建一個新的Replication Controller

      - ![kubectl-create-rc](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day07/kubectl-create-rc.png?raw=true)

    - 使用`kubectl get rc`查看目前狀態

      - 從圖中可以知道，`my-replication-controller`這個物件目前管理3個Pod，且3個Pod的狀態皆為`Ready`
      - ![kubectl-get-rc](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day07/kubectl-get-rc.png?raw=true)

    - 這時我們手動刪除其中一個Pod，我們來看看會發生什麼事情

      - ```
        $ kubectl delete pod my-replication-controller-4ftnj
        pod "my-replication-controller-4ftnj" deleted
        ```

      - ![kubectl-rc-recreate-new-pod](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day07/kubectl-rc-recreate-new-pod-1.png?raw=true)

      - replication controller偵測到一個Pod終止服務時，產生另外一個新的Pod，來確保Pod的數量。

    - 透過`kubectl scale`來scaling Pod的數量

      - ```C#
        $ kubectl scale --replicas=4 -f ./my-replication-controller.yaml
        replicationcontroller "my-replication-controller" scaled
        ```

    - `刪除replication controller`時，要特別注意，由replication controller產生的`pod`也會因此而終止服務。

      - ![kubectl-delete-rc](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day07/kubectl-delete-rc.png?raw=true)

    - 如果你希望刪掉replication controller之後，這些Pod仍然運行，可以指定 `--cascade=false`，指令如下：

      - `$ kubectl delete rc my-replication-controller *--cascade=false*`

##### Deployment

- ##### k8s在V1.2版本開始，引入了deployment控制器，值得一提的是，這種控制器並不直接管理pod而是通過管理replicaset來間接管理pod。

  - ![k8s之deployment詳解](https://i.iter01.com/images/bd6bad13b9e1ea370d4288231c991c6eb6667c922f8700badd9c189b258c4b5f.png)

- ##### [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) 可以幫我們達成以下幾件事情

  - ###### 支援replicaset的所有功能

  - 支援釋出的停止、繼續

  - 支援版本的滾動更新和版本回退

- ##### 自我解讀

  - Deployment 可以透過yaml設定檔達到服務快速佈署
  - 可以做到快速升級及還原

- ##### Yaml

  - ```yaml
    apiVersion: apps/v1beta2 # for kubectl versions >= 1.9.0 use apps/v1
    kind: Deployment
    metadata:
      name: hello-deployment
    spec:
      replicas: 3
      # 同時建立 3 個 my-deployment 的 pod
      # replicaset 的效果套用在帶有 app=my-deployment 的 pod 上
      # 必須要與下面的 pod label 有相符合
      selector:
        matchLabels:
          app: my-deployment
       # .spec.template 其實就是 pod 的定義
      template:
        metadata:
          # 設定給 pod 的 label 資訊
          labels:
            app: my-deployment
        spec:
          containers:
          - name: my-pod
            image: zxcvbnius/docker-demo:latest
            ports:
            - containerPort: 3000
    ```

  - ###### apiVersion

    - **kubectl**的版本 >= 1.9，則需使用`app/v1`；如果版本號是在1.9以前的話，則需使用`apps/v1beta2`，可以用`kubectl version`查看目前的版本號

  - 使用`kubectl create`指令來新建一個 Deployment 物件

    - ```
      $ kubectl create -f ./my-deployment.yaml
      deployment "hello-deployment" created
      ```

  - 用`kubectl get`查看deployment與Pod的狀態

    -  	![img](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day08/kubectl-get-deployment.png?raw=true)
    -  	可以發現 Deployment已自動幫我們創建Pod，且這個Pod都帶有**app=my-deployment**的label，而在同時，Deployment也會自動幫我們建立一個`Replication Set`來管理這些Pod
        -  	READY  就緒幾個/總共幾個 
        -  	UP-TO-DATE 有幾個 pod 副本已經 onboard 
        -  	AVAILABLE 目前有多少pod 副本可以運作 
        -  	Age pod運行時間

  - ###### 升級Pod中的Image

    - 透過 set image 

      - ```powershell
        #透過 set image 升級 hello-deployment 裡面的my-pod 指向新的Container
        > kubectl set image deploy/hello-deployment my-pod=zxcvbnius/docker-demo:v2.0.0
        deployment.apps/hello-deployment image updated
        ```

    - kubectl edit 編輯yaml檔案

      - ```powershell
        > kubectl edit deploy hello-deployment
        deployment.apps/hello-deployment edited
        ```

  - ###### 查看升級狀態

    - ```powershell
      > kubectl rollout status deploy hello-deployment
      Waiting for deployment "hello-deployment" rollout to finish: 2 out of 3 new replicas have been updated...
      ```

  - ###### 查看版本紀錄

    - ```powershell
      > kubectl rollout history deploy hello-deployment
      deployment.apps/hello-deployment
      REVISION  CHANGE-CAUSE
      1         <none>
      7         <none>
      10        <none>
      11        <none>
      ```

  - ###### Rolled back

    - 回溯至前一版本

      - ```powershell
        > kubectl rollout undo deployment hello-deployment
        deployment.apps/hello-deployment rolled back
        ```

    - 回至特定版本

      - ```
        > kubectl rollout undo deploy hello-deployment --to-revision=3
        ```

  - ##### Horizontal Pod Autoscaler

    - ```powershell
      > kubectl  autoscale deployment hello-deployment --min=5 --max=15 --cpu-percent=70
      horizontalpodautoscaler.autoscaling/hello-deployment autoscaled
      ## 上面意思為，我最小需求 POD 為 5 個，最大不能超過 15 個，只要 POD CPU使用率超過 70% 就做擴展。
      ## 所以他啟動時會從 5 個，依照 loading 慢慢往上加。
      
      ## 這邊可以看到產生5個Pods
      > kubectl get pods
      NAME                                READY   STATUS    RESTARTS   AGE
      hello-deployment-58b796b8b5-6mdpg   2/2     Running   0          40s
      hello-deployment-58b796b8b5-6w5bn   2/2     Running   0          66m
      hello-deployment-58b796b8b5-85ztt   2/2     Running   0          54m
      hello-deployment-58b796b8b5-r5cs8   2/2     Running   0          65m
      hello-deployment-58b796b8b5-vfq59   2/2     Running   0          40s
      hello-pod                           1/1     Running   0          91m
      my-pod                              1/1     Running   0          89m
      
      PS > kubectl delete pods hello-deployment-58b796b8b5-6mdpg
      pod "hello-deployment-58b796b8b5-6mdpg" deleted
      
      ## 當其中一個Pod被關閉後，會自動建立新的Pod補足最小五個的規則
      PS D:\IIS\Test> kubectl get pods
      NAME                                READY   STATUS        RESTARTS   AGE
      hello-deployment-58b796b8b5-6mdpg   2/2     Terminating   0          92s
      hello-deployment-58b796b8b5-6w5bn   2/2     Running       0          67m
      hello-deployment-58b796b8b5-85ztt   2/2     Running       0          55m
      hello-deployment-58b796b8b5-m92fh   2/2     Running       0          27s
      hello-deployment-58b796b8b5-r5cs8   2/2     Running       0          66m
      hello-deployment-58b796b8b5-vfq59   2/2     Running       0          92s
      hello-pod                           1/1     Running       0          91m
      my-pod                              1/1     Running       0          90m
      ```

    - 查看HPA 的設定

      - ```powershell
        > kubectl  get hpa
        NAME               REFERENCE                     TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
        hello-deployment   Deployment/hello-deployment   <unknown>/70%   5         15        5          7m55s
        ```

  - ##### RollingUpdateStrategy

    - ###### 決定你在更新當下，可以維持多少 POD 是正常運作的。

    - ###### 如果不想要 RollingUpdate 可以強制把 strategy.type 設定成 `Recreate` (預設是 `RollingUpdate`)，這樣升級策略就會變成，他會一次把全部 POD 關閉，然後再一次把全部 POD 升級上來。這樣服務就無法做到無中斷更新。

    - ```yaml
      ...
        strategy:
          type: RollingUpdate
          rollingUpdate:
            # 升級過程中最多可以比原先設定所多出的 pod 數量 ex 下面是指升級過程中 POD 總數可能會變到 4 個(上面設定 replicas 為 3)
            maxSurge: 1
            # 最多可以有幾個 pod 處在無法服務的狀態 ex 下面為最多一個 POD 為不可服務狀態。
            maxUnavailable: 1
        # 容器內應用程式的啟動時間，Kubernetes 會等待設定的時間後才繼續進行升級流程 (沒設定 POD 完成會直接啟動）
        minReadySeconds: 5
        template:
          metadata:
            labels:
            
            ...
      ```

      

- ##### 常見的指令

  - |                      Deployment相關指令                      |                  指令功能                   |
    | :----------------------------------------------------------: | :-----------------------------------------: |
    |                   kubectl get deployments                    |   取得目前Kubernetes中的deployments的資訊   |
    |                        kubectl get rs                        | 取得目前Kubernetes中的Replication Set的資訊 |
    |          kubectl describe deploy <deployment-name>           |        取得特定deployment的詳細資料         |
    | kubectl set image deploy/ <deployment-name> <pod-name>: <image-path>: <version> |  將deployment管理的pod升級到特定image版本   |
    |            kubectl edit deploy <deployment-name>             |           編輯特定deployment物件            |
    |       kubectl rollout status deploy <deployment-name>        |        查詢目前某deployment升級狀況         |
    |       kubectl rollout history deploy <deployment-name>       |     查詢目前某deployment升級的歷史紀錄      |
    |        kubectl rollout undo deploy <deployment-name>         |            回滾Pod到先前一個版本            |
    | kubectl rollout undo deploy <deployment-name> --to-revision=n |            回滾Pod到某個特定版本            |

###### Health check

- ###### 透過`定期發送一個 HTTP request 給 container` 的方式，來判斷目前 web app container 是否還正常運作。

  - 修改yaml, 在 Pod 中加入 Health check(livenessProbe)

    - **path**
      設定 health checks 要訪問的路徑
    - **port**
      指定我們要訪問的 port，這裡 port number 是 3000
    - **initialDelaySeconds**
      設定當 service 剛啟動時，要延遲幾秒再開始做 health check
    - **periodSeconds**
      代表每隔幾秒訪問一次，預設值為 `10秒`
    - **successThreshold**
      可以設置訪問幾次就代表目前 service 還正常運行
    - **failureThreshold**
      代表 service 回傳不如預期時，在 Kubernetes 放棄該 container 之前，會嘗試的次數，預設為`3`次。

  - ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hello-deployment
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: my-deployment
      template:
        metadata:
          labels:
            app: my-deployment
        spec:
          containers:
          - name: my-pod
            image: zxcvbnius/docker-demo:latest
            ports:
            - name: webapp-port
              containerPort: 3000
            livenessProbe:
              httpGet:
                path: /
                port: webapp-port
              initialDelaySeconds: 15
              periodSeconds: 15
              timeoutSeconds: 30  
              successThreshold: 1
              failureThreshold: 3
    ```

- ###### 相關文章

  - [還在用Replication Controller嗎？不妨考慮Deployment](https://ithelp.ithome.com.tw/articles/10194152)
  - [k8s Deployment 介紹](https://ithelp.ithome.com.tw/articles/10235654)

##### **Service** 

- ###### *Kubernetes Service 是個抽象化的概念，主要定義了邏輯上的一群 Pod 以及如何存取他們的規則。*

- ###### **Service 是 load balancer：**當發生 Replication 時，Service 會自動導流到比較空閑的 Application。（後面講 Deployment 的時候會再提到，可以先想像我們複製了一個 my-app，以防原本的 my-app 壞掉，而這兩個 my-app 都指向同一個 Service，Service 會導流到相對空閑的 my-app）

- ###### **Pod 跟 Service 的生命週期是分開的**

- ![Service](https://tachingchen.com/img/kubernetes-service/k8s-service-pod-access.jpg)

  - ##### 外部使用者會透過 Service 存取內部 Pod 以外 (路徑 1 -> 2)

  - ##### 同集群其他的 Pod 也有可能需要存取 (路徑 3 -> 2)。

  - ##### 兩條路徑的存取方式以及存取的 IP 位址有所不同

- ###### Service 作為中介層，避免使用者和 Pod 進行直接連線，除了讓我們服務維持一定彈性能夠選擇不同的 Pod 來處理請求外，某種程度上亦避免裸露無謂的 Port 而導致資安問題。

- ##### 主要元素:

  - ###### 服務元資料 (Metadata)

    - 簡單來說就是服務的名稱，讓其他人瞭解該服務的用途

      - ```
        metadata:
          name: service-example
        ```

  - 被存取的應用之標籤-

    - 每個 Pod 本身會帶有一至多個標籤，如何將使用者請求送到正確的 Pod，仰賴管理者設定的標籤是否得當。比方說，今天有 Nginx 以及 Apache 兩種網頁伺服器在運作，維運人員希望將流量導向至 Nginx，他們只要在 Pod 的 `spec.selector` 設定一組 `app: nginx` 的標籤，接著在 Service 內定義:

    - ```
      spec:
        selector:
          app: nginx
      ```

    - Service 便會根據定義檔內所設定的標籤，透過 [Label Selector](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) 找到對應的 Pod 後，建立相對應的 Iptable 規則。如此一來，當使用者請求送達 Kubernetes cluster 時，便會依照 Iptable 規則將封包繞送到實際執行的 Pod 內

  - 存取該服務的方式

    - 服務要開放給外界使用時，需要定義該服務的 Port、Protocol

    - ```
      spec:
        ports:
        	  # 讓維運人員瞭解該埠用途
          - name: http 
            # 對外部開放的埠號
            port: 80
            # 實際 Pod 所開放的埠號
            targetPort: 80
            # 該服務使用的協定目前有 TCP/UDP 兩種，預設為 TCP
            protocol: TCP
          - name: https
            port: 443
            targetPort: 443
            protocol: TCP
      ```

  - ##### 完整Yaml範例

    - ```yaml
      # service-example.yaml
      apiVersion: v1
      kind: Service
      metadata:
        name: hello-service
      spec:
        type: NodePort
        ports:
          - name: http-test1
            port: 80  #對應Container Port
            protocol: TCP
            nodePort: 30390
          - name: http-test2
            port: 3000
            protocol: TCP
            nodePort: 30391
        selector:
          app: my-deployment
      ```

  - ##### 建立 Kubernetes Service ` kubectl apply -f service-example.yaml service "service-example" created`

- ##### 產生Service

  - ```
     kubectl create -f ./my-service.yaml
    ```

- ##### 取得Service 清單

  - ```powershell
    > kubectl get services
    NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                       AGE
    hello-service           NodePort    10.108.216.73   <none>        3000:30390/TCP                4m43s
    kubernetes              ClusterIP   10.96.0.1       <none>        443/TCP                       122m
    my-deployment-service   NodePort    10.99.112.135   <none>        3000:32726/TCP,80:31035/TCP   110m
    my-pod-service          NodePort    10.109.252.12   <none>        80:30447/TCP                  118m
    ```

- ##### 刪除Service

  - ```powershell
    > kubectl delete svc/hello-service
    service "hello-service" deleted
    ```

- ##### 取得Service Url

  - ```powershell
    > minikube service hello-service --url
    http://172.31.142.202:30390
    http://172.31.142.202:30391
    ```

- ##### Dynamic Cluster IP

  - ###### 在沒有指定Cluster IP的情形下，Service每次新建立都會重新給定IP

  - ```powershell
    > kubectl get svc
    NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                       AGE
    hello-service   NodePort    10.111.192.111   <none>        80:30390/TCP,3000:30391/TCP   7m13s
    kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP                       137m
    
    > kubectl delete svc/hello-service
    service "hello-service" deleted
    
    > kubectl create -f ./my-service.yaml
    service/hello-service created
    
    >  kubectl get svc
    NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                       AGE
    hello-service   NodePort    10.103.80.198   <none>        80:30390/TCP,3000:30391/TCP   2s
    kubernetes      ClusterIP   10.96.0.1       <none>        443/TCP                       138m
    ```

- ##### NodePort 

  - ###### 預設的Service中，`Service可以指定的nodePort只有3000~32767`

  - 如果想要指定額外的Port號, 可以在創建Node時指定

    - 以 `minikube` 為例，當下次啟動minikube時我們可以加上`--extra-config=apiserver.ServiceNodePortRange={PORT_RANGE}`

    - ```
      minikube stop && minikube start --extra-config=apiserver.ServiceNodePortRange=1-50000
      ```

- ##### 參考

  - [Service Overview](https://godleon.github.io/blog/Kubernetes/k8s-Service-Overview/)


##### Ingress 

- ##### `Ingress` 負責給 `Service` 提供外部訪問的 `URL`、`SSL` 驗證、負載平衡、`HTTP`路由過濾等行為

- ##### 若將 [Service](https://kubernetes.io/docs/concepts/services-networking/service/) 圖像化，可以看到當多個 Service 同時運行時，Node 都需要有相對應的 port number 去對應相每個 [Service](https://kubernetes.io/docs/concepts/services-networking/service/) 的 port number

  - ![img](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day19/describe-service.png?raw=true)

- ##### 通常雲端服務，每台機器都會配置屬於它自己的防火牆(firewall)。這也代表，不論**新增、或是刪除 [Service](https://kubernetes.io/docs/concepts/services-networking/service/) 物件，我們都必須額外調整防火牆的設定，port的管理也相對複雜**。

- ##### 若是使用 [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) ，我們**只需開放一個對外的 port number，[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) 可以在設定檔中設置不同的路徑，決定要將使用者的請求傳送到哪個 Service 物件**

  - ![img](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day19/describe-ingress.png?raw=true)

- ##### 除了讓運維者無需維護多個 port 或頻繁更改防火牆(firewall)外，`可以自設條件`的功能也使得請求的導向更加彈性

- ##### Example 1：將不同路徑的請求對應到不同的 Service 物件

  - ```
    apiVersion: extensions/v1beta1
    kind: Ingress
    metadata:
      name: example-1
    spec:
      rules:
      - http:
          paths:
          - path: /test
            backend:
              serviceName: test
              servicePort: 80
    ```

  - ##### 由上述設定檔我們可以知道，

    - ###### **目前 Ingress 支援的 API 版本** 是 `extensions/v1beta1`

    - ###### 該設定檔中設定了一個規則：Node 收到流量之後，判斷流量路徑，若是請求路徑為 `/test` 則該流量將**導到名稱為 test 的 Service 物件**

- ##### Example 2：將不同 domain name 的請求對應到不同的 Service 物件

  - ```
    apiVersion: extensions/v1beta1
    kind: Ingress
    metadata:
      name: example-2
    spec:
      rules:
      - host: helloworld-v1.example.com
        http:
          paths:
          - path: /
            backend:
              serviceName: hellworld-v1
              servicePort: 80
      - host: helloworld-v2.example.com
        http:
          paths:
          - path: /
            backend:
              serviceName: helloworld-v2
              servicePort: 80
    ```

- ##### 在使用 `Ingress` 之前，**一定需要先運行 [Ingress Controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)**，筆者本身習慣使用 [Nginx](https://www.nginx.com/products/nginx/kubernetes-ingress-controller) 作為平常使用的 `Ingress Controller`

  - `Ingress Controller` 扮演著與 `K8S API` 溝通的腳色，並隨時注意 `Ingress` 規則是否有變化、如果有變化則自行更新規則。

  - ###### 目前主要支援兩種型別 [GCE](https://git.k8s.io/ingress-gce/README.md) 與 [Nginx](https://git.k8s.io/ingress-nginx/README.md)

- 參考

  - [在 Kubernetes 中實現負載平衡 - Ingress Controller](https://ithelp.ithome.com.tw/articles/10196261)

##### Flannel

##### Labels

- ##### **一對具有辨識度的key/value**，以下面為例

  - ###### "release" : "stable"，"release" : "qa"

  - ###### "enviroment": "dev"，"enviroment": "production"

  - ###### "tier": "backend", "tier": "frontend"

  - ###### "department": "enginnerting", "department": "marketing", "department": "finance"

- ##### 特點：

  - ###### 每個物件可以同時擁有許多個labels(multiple labels)

  - ###### 可以透過 [Selector](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)，幫我們縮小要尋找的物件。

  - ###### 目前 API 提供不再只是一個 **key對應一個value(Equality-based requirement)的關係**，我們也可以使用 [matchExpressions](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) 來設定更有彈性的`Labels`。

- ##### Annotations 

  - ##### 如果是**沒有識別用途的標籤**，Kubernetes 也提供了我們一個 [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) 元件。以 Pod 為例，我們可以在Pod的 [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) 紀錄該 Pod的發行時間，發行版本，聯絡人email等。

  - ##### [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) 主要是方便開發者、以及系統管理者管理上的方便，不會直接被 Kubernetes使用。

  - EX.

    - ```
      apiVersion: v1
      kind: Pod
      metadata:
        name: my-pod
        labels:
          app: webserver
          tier: backend   
        annotations:
          version: latest
          release_date: 2017/12/28
          contact: zxcvbnius@gmail.com
      spec:
        containers:
        - name: pod-demo
          image: zxcvbnius/docker-demo
          ports:
          - containerPort: 3000     
      ```

  - ##### 動態新增 Labels

    - 透過 `kubectl label`的指令，來為我們的 Pod 新增標籤

    - ```
      $ kubectl label pods my-pod env=production
          pod "my-pod" labeled
      
          $ kubectl get pods my-pod --show-labels
      NAME      READY     STATUS    RESTARTS   AGE       LABELS
      my-pod    1/1       Running   0          1h        app=webserver,env=production,tier=backend
      ```

  - ##### 透過幫每個 [Node](https://kubernetes.io/docs/concepts/architecture/nodes/) 貼標籤讓 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/) 運行在特定的 Node 上

    - 在 [Node](https://kubernetes.io/docs/concepts/architecture/nodes/) 上貼上標籤
    - 在 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/) 新增 `nodeSelector` 定義
    - ![img](https://github.com/zxcvbnius/k8s-30-day-sharing/blob/master/Day10/kubectl-add-node-selector.png?raw=true)

- 參考

  - [Kubernetes 30天學習筆記 - 詳細操作說明](https://ithelp.ithome.com.tw/users/20103753/ironman/1590)
  - [了解 K8S 的 Ingress](https://ithelp.ithome.com.tw/articles/10224065)

#### Secret 

- ######  [Kubernetes](https://kubernetes.io/) 提供開發者一種存放敏感資訊的方式

- ###### [Kubernetes](https://kubernetes.io/) 本身也使用**相同的機制( secrets mechanism) 存放 access token**，限制 API 的存取權限，確保不會有外部服務隨意操作 Kubernetes API。

- ##### 常見的使用方式

  - ###### 將 [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/) 當成 `環境變數(environment variables)` 使用

  - ###### 將 [Secrets File](https://kubernetes.io/docs/concepts/configuration/secret/) 掛載(mount) 在 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/) 某個檔案路徑底下使用

  - ###### 將這些 sensitive data 統一存放在某一個 Docker Image 中，並將這個 Image 存放在`私有的 Image Registry` 中，透過 `image pull` 下載到 Kubernetes Cluster 中，讓其他 Pods 存取。

#### Namespace 

- ##### 在同一個 K8s 中，每個 Namespaces 的名稱都是要獨特的

- ##### 當一個 Namespaces 被刪除時，在該 Namespace 裡的所有物件也會被刪除

- ##### 可以透過 Resource Quotas 限制一個 Namespaces 所可以存取的資源



# Redis

- ### 使用場景

  - ###### 配合 RDBMS 做高速快取

  - ###### 高頻次，熱門訪問的數據，降低資料庫 I/O

  - ###### 分散式架構，做 session共享

  - ###### 利用多樣的數據結構儲存特定的數據

- ##### 高效能的 key-value 資料庫，因為Redis可以儲存不同型態的資料(也可以透過plugins)，因此可以減少使用不同儲存體(DB、File Base、Cache)

  - ###### 減少不同儲存體之間的溝通，進而減少溝通間的時間成本。加快執行速度

  - ###### 方便維護、擴展

- ##### 特點：

  - ###### 支援資料的持久化，可以將記憶體中的資料儲存在磁碟中，重啟的時候可以再次載入進行使用

  - ###### 不僅僅支援簡單的key-value型別的資料，同時還提供list，set，zset，hash等資料結構的儲存。

  - ###### 支援資料的備份，即master-slave模式的資料備份。

- ##### 優勢

  - ###### Redis 是 **persistent** storage，**全部資料**存在記憶體內，所以資料大小上限受限於記憶體。資料會週期性備份到硬碟上 (RDB) 或是將所有更新寫入 append-only logs (AOF)。因此可以提供最快的操作

  - ###### 預設資料**不會 expire**。可以用 [expire](https://redis.io/commands/expire) 指定 expire 時間。預設是記憶滿了就不能寫入資料，設定 [LRU](https://redis.io/topics/lru-cache) 的模式可以決定是只刪有設 expire 的 keys 或是都刪。例如 `volatile-ttl` 會照 TTL 優先刪掉 TTL 最小的 key 且只會刪有設 expire 的 keys。

  - ###### 供多種常用資料結構如 [sorted set](https://redis.io/commands#sorted_set)、hash、geospatial、publish/subscribe events。可裝 plugin 使用其它資料結構。

  - ###### 主程式在單一 thread 執行，不用擔心 race conditions。但要留意執行太慢的操作會卡住整個系統

    - ###### race conditions: 兩個不同的程序同時對同一個資源進行修改，導致錯誤

  - ###### 因為記憶體操作超快，減少呼叫 Redis 的次數是效率關鍵。

- ##### 與Memory Cache比較

  - ###### Memcached 用 multi-thread 處理請求，Redis 只有 main thread。

  - ###### Memcached 只支援簡單的資料型別。

    - 如果只需要簡單的資料型別，memcached 較能善用 CPU。

- ### 高可用

  - ###### Redis 支援 Master-Slave（主從式架構），主要是將 Master 同步至 Slave，這樣當整體的 Traffic 流量較大時，可以將一些流量導至 Slave 減輕 Master 的負擔，詳細的部分可以參考 [這裡](https://stevenitlife.blogspot.com/2018/09/redis-master-slave.html)。

- ### 資料保留

  - ###### Redis 可以將 memory 的資料保存至硬碟中，有兩種不同的方式可以進行備份，分別為 `RDB` 與 `AOF`，詳細的部分可以參考 [這裡](https://segmentfault.com/a/1190000002906345)。

    - ##### 快照（`RDB`文件）:

      - ###### 在特定間隔時間條件達到時，將Redis在記憶體中的內容保存到RDB檔案(二進位格式)中．也就是在特定時間點的快照．當Redis服務啟動時，可以讀取RDB檔案來恢復到記憶體中．

      - ###### 優點：

        - ###### RDB是存放Redis某個時間點的快照，適合用在備份或是異地備份，提供災難復原使用，且只要備份一個檔案即可．

        - ###### RDB進行中對Redis效能的影響很小，因為Redis的父Process會fork一個子Process獨立進行產生RDB，父Process不需要進行IO操作．

        - ###### 當Redis重新啟動時，如有大量資料的情況下，RDB比AOF有更短的啟動時間．

      - ###### 缺點：

        - ###### 因為RDB是某個時間點的快照，不是最新的內容，故有可以會發生資料遺失的狀況．

        - ###### 如果資料量極大且產生快照RDB的頻率太高時，有可以會因此耗用較多的CPU效能，影響到父Process的客戶端操作回應．

    - ######  異動日誌（`AOF`文件）:

      - ###### 將Redis服務所收到的每個操作成功記錄，日誌為RESP協定格式儲存在日誌文字檔．並在每次新增在現有日誌檔的最後面，當日誌檔案過大時，Redis會透過覆寫的方式來持續寫入日誌檔，當Redis服務啟動時會將日誌檔載入來產生記憶體中的資料內容。

      - ###### 優點：

        - ###### 資料完整且持續，搭配不同的fsync策略 (關閉fsync、每秒fsync、每次操作fsync)，可以兼具效能與完整持續性，最多只會一秒的資料遺失。

        - ###### 因寫入日誌檔是透過持續操作新增在檔案最後，故不需要搜尋時間與擔心資料毀損 (可以透過redis-check-aof aof日誌檔 ，來確認檔案是否有問題，有問題可以加入redis-check-aof --fix aof日誌檔，進行修復)。

        - ###### 當aof日誌檔案過大時，Redis服務會自動使用背景方式覆寫aof檔案。

        - ###### aof日誌檔內容為RESP協定格式儲存，人可以容易閱讀。

      - ###### 缺點：

        - ###### 以相同資料量來比較rdb與aof檔案，aof通常會大於rdb檔案。

        - ###### 依據所使用的fsync策略aof寫入速度可能會較rdb慢，如果關閉fsync，即使是在大量操作時，aof與rdb速度會接近一樣快。

  - ### 重啟如何恢復資料呢？ 

    - ###### Redis啟動前會先檢查AOF檔案，不存在才會去載入RDB檔案，因為AOF的資料完整性高，最多也就損失1秒的資料。

- ### 記憶體淘汰策略

  - ###### noeviction： 不刪除，直接返回報錯資訊。

  - ###### allkeys-lru：移除最久未使用（使用頻率最少）使用的key。推薦使用這種。

  - ###### volatile-lru：在設定了過期時間key中，移除最久未使用的key。

  - ###### allkeys-random：隨機移除某個key。

  - ###### volatile-random：在設定了過期時間的key中，隨機移除某個key。

  - ###### volatile-ttl： 在設定了過期時間的key中，移除準備過期的key。

  - ###### allkeys-lfu：移除最近最少使用的key。

  - ###### volatile-lfu：在設定了過期時間的key中，移除最近最少使用的key。

- ### 過期鍵刪除策略

  - ##### 定時刪除

    - ###### 在設定鍵的過期時間的同時，建立一個定時器，讓定時器在講的過期時間來臨時，執行對鍵的刪除操作

    - ###### 定時刪除會佔用CPU時間，響應伺服器的響應時間和吞吐量

  - ##### 惰性刪除

    - ###### 任由鍵過期先不刪除，但是每次從鍵空間中獲取鍵時都檢查取得的鍵是否過期，如果過期則刪除鍵

    - ###### 惰性刪除浪費太多記憶體，有記憶體洩漏的危險

  - ##### 定期刪除

    - ###### 每隔一段時間，程式就對資料庫進行一次檢查，刪除裡面的過期鍵。至於刪除多少過期鍵，則根據多少個過期鍵和演算法決定

    - ###### 定期刪除是前兩種策略的整合和折中。因為是批量操作，並限定了執行時長和頻率，可以有效減少刪除操作對CPU的響應，也避免了記憶體長久不刪除的導致的浪費

## 資料型態

- #### **String**

  - ##### *String 是 Redis 中最基礎的資料型別，透過 binary 形式儲存，且保證不更改資料內容 (binary-safe)，因此 String 可儲存任何資料，例如一般字串，數字，檔案以及序列化後的物件等。*

- #### List

  - ##### List 是由多個 redis 的 String 所組成，List 中成員會依照插入的順序儲存，其提供由頭尾插入，以及頭尾拿出的功能，List 能實作的功能很多，例如任務隊列，以及優先權隊列等。

- #### Set

  - ##### Set 是多個 Redis 中 String 以無序的方式所組成，其保證內部不會有重複的元素，此外 Redis 提供了多個 Set 之間交集，差集，聯集的操作。

  - ```C#
    redis 127.0.0.1:6379> SADD runoobkey redis
    (integer) 1
    redis 127.0.0.1:6379> SADD runoobkey mongodb
    (integer) 1
    redis 127.0.0.1:6379> SADD runoobkey mysql
    (integer) 1
    redis 127.0.0.1:6379> SADD runoobkey mysql
    (integer) 0
    redis 127.0.0.1:6379> SMEMBERS runoobkey
    
    1) "mysql"
    2) "mongodb"
    3) "redis"
    ```

- #### Hash

  - ##### Hash是用來儲存多組欄位值，可以是數字或字串．使用者可以對值進行操作，跟資料結構中的dictionary概念很像．

  - ##### Hash在Redis內部可能是ziplist or a hash table，基本上被設計為高效能的雙向鏈結表(dually linked list)，且整數資料類型被真實儲存為整數而非字串。

  - ##### Hash如果欄位值個數 < 512且總長度 < 64 bytes，則使用ziplist，其餘使用hashtable．

  - ##### Hash優點

    - ###### 將所有相關的field and value放在同一個key中儲存，減少記憶體消耗

    - ###### 多個field只需要一個key，減少key重覆的可能

    - ###### 可以一次存取多個field and value只需要一個取得key的指令，減少CPU與記憶體的消耗

    - ###### String能做到的Hash也都可以

  - ##### Hash缺點

    - ###### Field不能設定過期時間

    - ###### 沒有bit相關操作

    - ###### 當值很大時，無法分散到其他伺服器(Redis Cluster架構)

  - ##### 由於透過[string](https://dotblogs.com.tw/ricochen/2017/01/11/092137)資料型別儲存其他屬性必須進行序列化和反序列化，而且修改某一屬性必須把整個entity取回並lock對並發情況進行保護

    - ###### 這時Hash就提供了很好的解決方法，假設今天要儲存使用者資訊，key依然是使用者ID，但value是一個map，這個map的key是屬性名，value是屬性值，當要修改或存取內部的key，可以透過key(使用者ID)+field(屬性名)操作對應屬性值，如此便可避免序列化、反序列化花費，和併發修改控制的問題，但要注意map的屬性名不可過多，因為Redis為單一執行緒，map列舉過多可能會相當耗時。

    - ![img](https://dotblogsfile.blob.core.windows.net/user/ricochen/133abc51-46b4-42bf-afe5-8d90fa527abe/1484494713_94683.png)

  - ![img](https://dotblogsfile.blob.core.windows.net/user/ricochen/133abc51-46b4-42bf-afe5-8d90fa527abe/1484494735_40553.png)


## Transaction

- ### MULTI

  - ##### 開啟Transaction(類似beginTraction)

- ### EXEC

  - ##### 執行Multi開始的所有命令(類似Commit)

  - ```powershell
    127.0.0.1:6379> MULTI
    OK
    127.0.0.1:6379> get foo
    QUEUED
    127.0.0.1:6379> set ff test
    QUEUED
    127.0.0.1:6379> exec
    1) "test"
    2) OK
    ```

- ### DISCARD

  - ##### 取消Multi開始的所有命令(rollback)

  - ```powershell
    127.0.0.1:6379> MULTI
    OK
    127.0.0.1:6379> set t 123
    QUEUED
    127.0.0.1:6379> get foo
    QUEUED
    127.0.0.1:6379> set k 234
    QUEUED
    127.0.0.1:6379> DISCARD
    OK
    127.0.0.1:6379> get t
    (nil)
    127.0.0.1:6379> get k
    (nil)
    ```

- ### WATCH

  - ##### 針對特定 key 進行監控，如果被監控的 key 被異動過，則執行 `EXEC` 時會失敗

    - ###### 举个例子， 如果客户端 A 和 B 都读取了键原来的值， 比如 `10` ， 那么两个客户端都会将键的值设为 `11` ， 但正确的结果应该是 `12` 才对。如果在 [WATCH](http://redisdoc.com/transaction/watch.html#watch) 执行之后， [EXEC](http://redisdoc.com/transaction/exec.html#exec) 执行之前， 有其他客户端修改了 `mykey` 的值， 那么当前客户端的事务就会失败。(樂觀鎖) 

  - ```powershell
    > SET mykey 0
    OK
    > WATCH mykey
    OK
    > SET mykey 1
    OK
    > MULTI
    OK
    > SET mykey 2
    QUEUED
    > EXEC
    (nil)
    > GET mykey
    "1"
    ```

- ###### 我們必須了解到 Redis transaction，能夠被實現的條件是基於 check-and-set 的 two-phase commit，而 check-and-set 則是因 Redis 2.2 後有 optimistic lock 得以實作。其中 `WATCH` 便是我們的 optimistic lock 實作出的方法，針對單一 key value 進行監控，配合 `EXEC` 確保本次 transaction 的原子性(atomic)，保證我們這一系列的操作都可以如預期地被完成。

## Cluster 

- ##### **Scalability** : 幫你將資料分散在不同的機器上，即便資料量變大，你也可以透過橫向擴展來 Handle 大量資料。

- ##### **Availability** : 提供 Fail-Over 功能，即便某個機器掛掉了，不僅不會影響 Client 向 Cluster 讀寫資料，Client 還可在別台活著的機器上找到掛點機器的資料。

- ##### Gossip:

  - ##### 由種子節點發起，當一個種子節點有狀態需要更新到網絡中的其他節點時，它會隨機的選擇周圍幾個節點散播消息，收到消息的節點也會重複該過程，直至最終網絡中所有的節點都收到了消息。

    - ###### Gossip 是周期性的散播消息，把周期限定為 1 秒

    - ###### 被感染節點隨機選擇 k 個鄰接節點（fan-out）散播消息，這裡把 fan-out 設置為 3，每次最多往 3 個節點散播。

    - ###### 每次散播消息都選擇**尚未發送過的節點**進行散播

    - ###### 收到消息的節點不再往發送節點散播，比如 A -> B，那麼 B 進行散播的時候，不再發給 A。

    - ![img](http://i1.kknews.cc/4rvEv6ofey7UaadDz5lSgtLCHyzhvxKx6g/0.jpg)

  - ##### 特點

    - ###### 擴展性:  允許節點的任意增加和減少，新增加的節點的狀態最終會與其他節點一致。

    - ###### 容錯: 任何節點的宕機和重啟都不會影響 Gossip 消息的傳播，Gossip 協議具有天然的分布式系統容錯特性

    - ###### 去中心化:  不要求任何中心節點，所有節點都可以是對等的，任何一個節點無需知道整個網絡狀況，只要網絡是連通的，任意一個節點就可以把消息散播到全網。

    - ###### 一致性收斂: 協議中的消息會以一傳十、十傳百一樣的指數級速度在網絡中快速傳播，因此系統狀態的不一致可以在很快的時間內收斂到一致。

  - ##### 缺陷

    - ###### 消息的延遲:  節點只會隨機向少數幾個節點發送消息，消息最終是通過多個輪次的散播而到達全網的，因此使用 Gossip 協議會造成不可避免的消息延遲。**不適合用在對實時性要求較高的場景下。**

    - ###### 消息冗餘: 節點會定期隨機選擇周圍節點發送消息，而收到消息的節點也會重複該步驟，因此就不可避免的存在消息重複發送給同一節點的情況，造成了**消息的冗餘**，同時也增加了收到消息的節點的處理壓力。而且，由於是定期發送而且不反饋，因此，即使節點收到了消息，還是會反覆收到重複消息，加重了消息的冗餘

    - 

      

## 安裝

- 使用Chocolate `choco install redis`

- 測試redis是否正常啟用

  - ```powershell
    > redis-cli ping
    PONG
    ```

- 停止redis 服務`redis-server --service-start`

- 啟用redis 服務`redis-server --service-stop`

- 新增測試值

  - ```powershell
    > redis-cli set Test "hello world"
    OK
    ```

- 查詢資料

  - ```powershell
    > redis-cli get Test
    "hello world"
    ```

- ##### 圖形化使用者管理介面

  -  [Redis Desktop Manager](https://github.com/uglide/RedisDesktopManager/releases/tag/0.8.8)

## 快取擊穿

- ##### 快取擊穿指的是某個 **key 一直在扛著高併發** ，所謂扛著高併發就是說大量的請求都是獲取這個 key 對應的值。而這個 key 在某個時間突然失效了，大量的請求就無法在快取中獲取資料了，而是去請求資料庫了，這樣很有可能導致資料庫被擊垮。這就是快取擊穿。

  - ###### 如何應對呢？既然這個 key受歡迎， 那麼就不要設定過期時間了，如果該key的資料更新了，那麼就通過互斥鎖的方式將其更新。如果不使用互斥鎖的方式很容易導致資料不一致的情況，這裡為了保證快取和資料庫的一致性，就只能犧牲一點點的效率了。

## 快取雪崩

- ##### 由於原有快取失效（或者資料未載入到快取中），新快取未到期間所有原本應該訪問快取的請求都去查詢資料庫了，而對資料庫CPU和記憶體造成巨大壓力，嚴重的會造成資料庫宕機，造成系統的崩潰。

- ##### 在某個時間節點，大量的 key 失效，導致大量的請求從快取中獲取不到資料而去請求資料庫 。

  - ###### 最簡單的情況就是把key的過期時間分散開，也就是在設定key的過期時間的時候再加一個隨機值，就這樣就能完美的解決快取雪崩的問題。

### 快取預熱

- ##### 將一些可能經常使用資料在系統啟動的時候預先設定到快取中，這樣可以避免在使用到的時候先去資料庫中查詢。

- ##### 還有一種方式就是新增一個快取重新整理頁，這樣通過人工干預的方式將一些可能為熱點的key新增到快取中。

## 快取降級

- 

## Redis Replication 

- ##### Redis 支援 Master-Slave（主從式架構），主要是將 Master 同步至 Slave，這樣當整體的 Traffic 流量較大時，可以將一些流量導至 Slave 減輕 Master 的負擔，詳細的部分可以參考 [這裡](https://stevenitlife.blogspot.com/2018/09/redis-master-slave.html)。

- ##### 讀寫分離

  - ###### 當用戶端需要讀寫的時候，必須要透過Master才可以進行讀寫操作．

  - ###### 當用戶端只需要讀取資料而不需要寫入的時後，可以考慮直接連Replica取得資料，減輕Master的負擔．

- ##### Sentinel機制

  - ###### 哨兵模式就是用來監視 Redis 系統，哨兵會監控 Master 是否正常運作。如果遇到 Master 出現故障或是離線時，哨兵之間會開始判斷，直到我們所設定需達到的判斷數量後，哨兵會將其所屬的 Slave 變成 Master，並再將其他的 Slave 指向新的 Master。

    - ![img](https://raw.githubusercontent.com/880831ian/redis-sentinel-docker/master/images/sentinal.png)

  - ##### 功能

    - ###### 監控

      - ###### 哨兵會和要監控的 Master 建立兩條連接，`Cmd` 和 `Pub/Sub`：

        - ###### Cmd 是哨兵用來定期向 Master 發送 `Info` 命令以取得 Master 的訊息，訊息中會包含 Master 有哪些 Slave。當與 Master 獲得 Slave 訊息後，哨兵也會和 Slave 建立連接。

        - ###### 哨兵也會定期透過 `Cmd` 向 Master、Slave 和其他哨兵發送 `Ping` 指令來檢查是否存在，確認節點狀態等。

        - ###### `Pub/Sub` 讓哨兵可以透過訂閱 Master 和 Slave 的 `__Sentinel__:hello` 這個頻道來和其他哨兵定期的進行資訊交換。

    - ###### 主觀下線 (SDOWN)

      - ###### 單個哨兵認為 Master 已經停止服務了，有可能是網路不通或是接收不到訂閱等，而哨兵的判斷是依據傳送 Ping 指令之後一定時間內是否收到回覆或是錯誤訊息，如果有哨兵就會主觀認為這個 Master 已經下線停止服務了。

    - ###### 客觀下線 (ODOWN)

      - ###### 由多個哨兵對同一個 Master 各自進行主觀下線的判斷後，再綜合所有哨兵的判斷。若是認為主觀下線的哨兵到達我們所配置的數量後，即為客觀下線。

    - ###### 故障轉移 (Failover)

      - ###### 當 Master 已經被標記為客觀下線時，起初發現 Master 下線的哨兵會發起一個選舉 (採用的是 Raft 演算法)，並要求其他哨兵選他做為領頭哨兵，領頭哨兵會負責進行故障的恢復。當選的標準是要有超過一半的哨兵同意，所以哨兵的數量建議設定成奇數個。

      - ###### 選出領頭哨兵後，領頭哨兵會開始從下線的 Master 所屬 Slave 中跳選出一個來變成新的 Master，挑選的依據如下：

        1. ###### 所有在線的 Slave 擁有最高優先權的，優先權可以透過 slave-priority 來做設定。

        2. ###### 如果有多個同為最高優先權的 Slave，則會選擇複製最完整的。

        3. ###### 若還是有多個 Slave 皆符合上述條件，則選擇 id 最小的。

      - ###### 接著領頭哨兵會將舊的 Master 更新成新的 Master 的 Slave ，讓其恢復服務後以 Slave 的身份繼續運作。

    - ###### 失效自動切換

      - ###### 組態設定提供

  - ##### 設定檔

    - ```yaml
      port 26379
      
      #設定要監控的 Master，最後的 2 代表判定客觀下線所需的哨兵數
      sentinel monitor mymaster 192.168.176.4 6379 2
      
      #哨兵 Ping 不到 Master 超過此毫秒數會認定主觀下線
      sentinel down-after-milliseconds mymaster 5000
      
      #failover 超過次毫秒數即代表 failover 失敗
      sentinel failover-timeout mymaster 180000
      ```

- ##### Master-Slave範例

  - ###### 透過Docker 建立一台Master redis及一台Slave，並藉由Sential服務監控

    - ```yaml
      version: '3.4'
      
      
      services:
        redis-master:
          container_name: redis-master
          image: redis:5.0.3-alpine3.9
          ports:
            - "6379:6379"
        redis-slave:
          container_name: redis-slave
          image: redis:5.0.3-alpine3.9
          # Slave端設定，指定連接的Master的IP和端口號，也需要與Master保持一致
          command: redis-server --slaveof redis-master 6379
          links:
            - redis-master
          ports:
            - "6380:6379"
      
      ```

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207211949479.png)

  - ###### 透過指令可以看到Master可以進行讀寫動作，而Slave會透過同步取得Master寫入的資料但無法單獨寫入

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207202030240.png)

  - ###### 當Master故障時，Sentinel機制會將Slave轉化為Master。並當原先Master啟動後會變成為Slave腳色

    - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207202036439.png)

## NET Core Example

- 安裝套件 `StackExchange.Redis`

- 連線Redis

  - ```C#
    builder.Services.AddSingleton<IConnectionMultiplexer>(ConnectionMultiplexer.Connect("127.0.0.1:6379,allowAdmin=true"));
    ```

- 新增資料

  - `db.StringSet("Test", value, TimeSpan.FromSeconds(300));`	

- 取得資料

  - ` db.StringGet("Test");` 

- ##### 針對Master-Slave架構

  - ###### 當原本的Master掛掉時，程式端並不會知道新的Master在哪台主機上。因此，需要做另外處理

  - ###### 利用 StackExchange.Redis ConnectionMultiplexer `自動辨識 master` 的特性來做為調整依據

    - ![1automaster](https://cloud.githubusercontent.com/assets/3851540/24083525/573ea7be-0d13-11e7-9f71-c0ec5a0a7d88.png)

  - ```C#
    private static readonly Lazy<ConnectionMultiplexer> Connection;
           /// <summary>
           /// Use EndPoint to connection.
           /// </summary>
           static RedisHaFactory()
           {
               ConfigurationOptions options = new ConfigurationOptions
               {
                   //對應每個節點的redis server
                   EndPoints = { { "127.0.0.1:6379" }, { "127.0.0.1:6380" }, { "127.0.0.1:6381" } },
                    //定義使用的資料庫
                   DefaultDatabase =0
               };
               Connection = new Lazy<ConnectionMultiplexer>(() => ConnectionMultiplexer.Connect(options));
           }
     
           public static ConnectionMultiplexer GetConnection => Connection.Value;
           public static IDatabase RedisDB => GetConnection.GetDatabase();
    ```

- ##### 指定透過Mater 或 Replica操作

  - ```C#
    //寫入的時候只有Mater可以操作，不需要特別指定
    var ab = RedisHaFactory.RedisDB.StringSet("test", "Write string value from another master");
    
    //透過CommandFlags 指定透過replica讀取 (CommandFlags.DemandReplica: 只能透過replica, PreferReplica優先使用replica )
    var stringGet = RedisHaFactory.RedisDB.StringGet("test", CommandFlags.PreferReplica);
    ```

- ##### 簡易搶票實作範例

  - ###### Redis的Lock比較像是一種話語權，取得Lock的request才能進行redis操作。否則只能等待

  - ```C#
    private static readonly TicketService _service = new TicketService(_client);
    private static readonly string _eventCountKey = "Event_Count";
    
    private static async Task Run()
    {
        var result = new ConcurrentStack<bool>();
        var tasks = new List<Task>();
        
        // 發出105個task
        for (var index = 0; index < 105; index++)
        {    
            var number = index;
            tasks.Add(Task.Run(async () =>
            {
                // 透過 TicketService 處理搶票的邏輯，返回bool
                result.Push(await _service.GetTicket(_eventCountKey));
                Console.WriteLine($"{number}");
            }));
        }
        await Task.WhenAll(tasks);
    
        // 驗證拿到成功的client request數量
        Console.WriteLine($"success count: {result.Count(r => r == true)}");
    }
    
    public class TicketService
    {
        private readonly RedisClient _client;
    
        public TicketService(RedisClient redisClient)
        {
            _client = redisClient;
        }
    
        public async Task<bool> GetTicket(string key)
        {
            // 只有在數量還有剩 且 透過Redis的Lock成功，才繼續搶票的動作
            // 這邊Lock的Timeout時間為100毫秒，純粹只是為了測試
            if (await TicketCount(key) > 0 && await _client.Lock(key, TimeSpan.FromMilliseconds(100)))
            {
                try
                {
                    // 遞減數量，會返回剩餘的數量，剩餘數量小於0代表超賣了，會返回失敗
                    var lastCount = await _client.StringDecrement(key);
    
                    return lastCount >= 0;
                }
                finally
                {
                    // 完成後要把Lock釋放
                    await _client.LockRelease(key);
                }
            }
    
            return false;
        }
    
        private async Task<int> TicketCount(string key)
        {
            return (int)await _client.GetString(key);
        }
    }
    
    public class RedisClient
    {
        // 可重用，所以在ctor建立後就放到filed上
        private readonly ConnectionMultiplexer _connection;
    
        public RedisClient()
        {
            var options = new ConfigurationOptions()
            {
                EndPoints = {"localhost"}
            };
            _connection = ConnectionMultiplexer.Connect(options);
        }
    
        public async Task<bool> Lock(string key, TimeSpan expiry)
        {
            // Lock失敗就等200毫秒，再重試，最多10次
            var lockKey = $"Lock_{key}";
            var number = 0;
            do
            {
                try
                {
                    var database = _connection.GetDatabase();
                    if (await database.LockTakeAsync(lockKey, Environment.MachineName, expiry))
                    {
                        return true;
                    }
                }
                catch (Exception)
                {
                    await Task.Delay(200);
                    number++;
                }
            } while (number < 10);
    
            return false;
        }
    
        public async Task SetString(string key, RedisValue value)
        {
            var database = _connection.GetDatabase();
            await database.StringSetAsync(key, value);
        }
    
        public async Task<RedisValue> GetString(string key)
        {
            var database = _connection.GetDatabase();
    
            return await database.StringGetAsync(key);
        }
    
        public async Task<bool> LockRelease(string key)
        {
            var lockKey = $"Lock_{key}";
            var database = _connection.GetDatabase();
    
            return await database.LockReleaseAsync(lockKey, Environment.MachineName);
        }
    
        public async Task<long> StringDecrement(string key)
        {
            var database = _connection.GetDatabase();
    
            return await database.StringDecrementAsync(key);
        }
    }
    ```

    

## 參考

- [ASP.NET Core 註冊 StackExchange.Redis 的方式](https://blog.yowko.com/stackexchange-redis-in-aspdotnet-core/)
- [ASP.NET Core分散式快取Redis主從Sentinel哨兵模式實戰演練](https://www.gushiciku.cn/pl/gvu6/zh-tw)
- [使用 Redis-Sentinel 打造 Redis 的 HA](https://dotblogs.com.tw/supershowwei/2016/02/03/123740)
- [使用Docker-compose 搭建Redis 哨兵模式 - GitHub](https://github.com/880831ian/docker-compose-redis-sentinel)
- [Redis 命令参考](http://redisdoc.com/topic/transaction.html)
- [初識 Redis Cluster](https://vicxu.medium.com/%E5%88%9D%E8%AD%98-redis-cluster-ep-1-redis-cluster-%E6%9E%B6%E6%A7%8B%E7%B0%A1%E4%BB%8B-%E7%95%B6-redis-%E7%BE%A4%E8%81%9A%E5%9C%A8%E4%B8%80%E8%B5%B7-67be41e68654)



# ELK

- #### ELK是開源軟體的集合套件，功能為集中化各來源的資料流與資料分析，可做為網站的日誌分析和監控架構，也能夠協助網站管理者管理網站流量、紀錄造訪資訊進行分析與監控。

  - ###### Elastic Search：儲存資料、資料搜尋檢視的軟體，可以快速搜尋、有效地對資料進行儲存和索引。

  - ###### Logstash：資料處理軟體，可以採集資料、多管道蒐集資料並送到指定位置。

  - ###### Kibana：數據分析和可視化平台，可以快速分析大量的資料，並以視覺化圖表和儀錶板的方式呈現。

- ![ELK](https://www.webcomm.com.tw/blog/wp-content/uploads/2021/12/ELK.png)

- ##### ELK功能為智能數據的應用，除了可以處理規模較大的日誌分析，讓資料檢索更有效率外，也能記錄網站訪客流量的訊息。

  - #####  例如：網站資源的訪問者、訪問的裝置、訪問的結果等等。蒐集流量資料提供了許多後續行銷或商機開發的應用，也能幫助網站管理者更加了解網站的使用者。

## 參考

- [初探.net core NLog - 昕力資訊](https://www.tpisoftware.com/tpu/articleDetails/1337)
- [ELK IN Docker](https://github.com/deviantony/docker-elk/tree/release-7.x)



# Message Queue

## Application Intergration

- ###### 一個系統中，一般不會只有一隻程式在運作，而是會有多隻程式同時負責各種不同的任務，而程式之間難免會有互相傳遞資料進行處理的需求，而這類的需求，以下都統稱為 applcation 的整合。

- ##### 常見的 Application Intergration 方式又分為以下幾種：

  - ###### File Based Intergration

    - ###### source application 根據要處理的任務，產生檔案到特定的路徑，其中任務成功或失敗可以存放到不同 folder 中。而其他接收訊息的 application(或稱 process application) 則是不停監控該路徑有沒有新檔案產生，有則取出檔案進行處理。

    - ![img](https://miro.medium.com/max/1400/1*t9FX6FQKmeTjsRt7hx97NA.png)

  - ###### Shared Database Intergration

    - ###### 與File Based差不多，差別在資料儲存於DB

    - ![img](https://miro.medium.com/max/1400/1*IOI9Z8zymQl5RbVB-2rXEw.png)

  - ###### Direct Connection Intergration

    - ###### source application 直接傳訊息給 process application

    - ###### 可能透過 TCP/IP 或是 named pipe connection 的方式傳遞資料

    - ###### 傳遞資訊的資料格式並沒有限制，由連線兩端的 application 自訂，可以是純文字、XML 或 JSON。

    - ![img](https://miro.medium.com/max/1400/1*AQ5aLr5OTR0_tpthiq2EGA.png)

  - ###### Asynchronous Message Broker

    - ##### 特性：

      - ###### 不限傳遞資料格式

      - ###### 需要額外 message queue middleware 協助，也會被稱作 message broker 或 message bus

      - ###### message broker 收到來自 source application 的訊息後，會轉發給 process application，而在這個方式中，source application 與 process application 通常又各自被稱為 producer 與 consumer。

    - ![img](https://miro.medium.com/max/1400/1*62CxFz1kTKLixkDqr9qtAw.png)

## 訊息佇列

- ##### 從字面意思上看，本質是個佇列，FIFO先入先出，只不過佇列中存放的內容是message。

- ##### 其主要用途：

  - ##### 不同程序 Process 之間

  - ##### 不同執行緒 Thread 之間

  - ##### 不同服務之間 (Microservice)

- ##### 架構由 

  - ##### Producers 負責創建訊息並傳遞訊息至 Message Queue

  - ##### Consumers 負責從 queue 中取出訊息並執行對應的行為。存放在 queue 中的 Message 會在被 Consumers 接收後才會移除。

- ##### 優勢

  - ###### Better performance

    - 非同步處理，Producers拋出訊息後不需要等待回應。
    - consumer 有空時才會處理 message
    - 比起持續 polling 的方式相對有效率(輪詢: 接收端定時查看Producers 狀態決定是否進行下一步，如上述File Based Intergration ,Shared Database Intergration)

  - ###### 解耦

    - 將 publisher 與 consumer 進行 decouple ，程式開發人員可以各自專心負責規模較小 & 單純的程式開發工作
    - publisher 與 consumer 不需要知道雙方的實際的位置(例如：IP address)，只要將資料往 message queue 送就好
    - Break up apps & migrate to microservice

  - ###### Reliablity

    - queue 使 data 不易丟失
    - 即使 consumer 短暫的無法提供服務也沒關係，message queue 可以將資料暫存起來，等待 consumer 重新上線時再送過去

  - ###### Flexiability of scaling

    - producer, queue, consumer 可以依照需求擴張或縮減

- ##### Eaxmple

  - 假設你擁有一個 web service，每秒需要接受大量 request，request 不能被丟失，但 request 又要經過一個大量運算的 function 才能得到 response….
    - ![img](https://miro.medium.com/max/1400/1*ygPEYxQY-PQiaMPQ8cQ5lA.png)

## RabbitMQ 

- ![img](https://miro.medium.com/max/1400/1*PAJJlbfy78PrFSnwYjCnlw.png)

- ##### 元件屬性:

  - ###### Producer

    - 負責丟訊息到 Queue 中，若有定義 Exchange，則丟給 Exchange 決定要給誰。

  - ###### Consumer

    - 負責接收來自 Queue 的訊息。

  - ###### Queue

    - 負責存放所需要的資料，跟資料結構的 Queue 一樣，有先進先出 (FIFO) 特性，每個 Queue 都會有他的名字當 id。

  - ###### Channel

    - Channel是建立在Connection上的一個虛擬通訊管道。一般情況下，往訊息佇列中寫入多條訊息，為了不每條訊息都建立一個TCP連線，所以RabbitMQ的做法是多條訊息可以公用一個Connection，大大提高MQ的負載能力。

  - ###### Exchange

    - ![RabbitMQ Exchange](https://godleon.github.io/blog/images/middleware/message-queue_concept-binding.png)
    - Exchange 是 RabbitMQ 系統中負責轉發訊息的元件， Producer 無法將訊息直接傳到 Queue 中，在 RabbitMQ 中訊息的第一個進入點是 Exchange
    - 實際儲存訊息的 Queue 會根據使用者的設定，與不同的 Exchange 進行綁定
    - 當 Exchange 收到訊息後，就會轉發到與其綁定的 Queue (可能 0 到多個不等)
    - Exchange 僅能將訊息轉發到與其綁定的 Queue 上
    - 至少會有一個預設 Exchange 存在於 RabbitMQ 系統中，稱為 **default exchange**，轉發的模式為 `direct`；每個新建立的 Queue，若是沒指定 exchane 資訊，就會與預設的綁定
    - Exchange 有四種轉發模式
      - Direct: 直接丟給指定的 Queue。
      - Topic: 類似 regular expression，設定 binding 規則，丟給符合的 Queue。
      - Headers: 透過傳送資料的 header 來特別指定所要的 Queue。
      - Fanout: 一次丟給全部負責的 Queue。

- ##### 官網使用情境說明

  - ###### Task Queue

    - ![img](https://miro.medium.com/max/1196/1*B3q0g4uPCTMY5H0kWlvGLg.png)
    - 不透過 Exchange 直接送到指定的 Queue

  - ###### Publish/Subscribe

    - 透過 Exchange 的 fanout 特性，達到訂閱 Queue 的 Consumer 都可以收到訊息。
    - ![img](https://miro.medium.com/max/1128/1*YNKahFDsg2sbaIG-k31SKQ.png)

  - ###### Routing

    - 透過 Exchange 的 direct 特性，達到類似 routing 的功能，將訊息 filter 到特定的 Queue。
    - ![img](https://miro.medium.com/max/1400/1*6lw6dx5h-p4ZBDC5SJGsdg.png)

  - ###### Topics

    - 透過 Exchange 的 topic 特性，每個 Queue 都有屬於自己的分類。
    - ![img](https://miro.medium.com/max/1400/1*_5vbFy2NODg-atHLiC7fRg.png)

  - ###### RPC

    - 如果需要回傳訊息的話則需要透過 RPC

  - ![img](https://miro.medium.com/max/1400/1*rFE7XPQ7_iCkK7LkjCLEvA.png)

- ##### Message 屬性

  - ![img](https://miro.medium.com/max/1400/1*cWUB5yWOeIykQyWcex8ijg.png)

- ##### Queue 屬性

  - ![img](https://miro.medium.com/max/1400/1*-TqB4L1eBEaGdl4VpLz3VA.png)

- ##### Exchange 屬性

  - ![img](https://miro.medium.com/max/1400/1*3_cbKqwgXrPrlUf3CMl06A.png)

### 如何防止訊息丟失

- ##### **生產者丟失訊息**

  - ###### 開啟confirm模式。在生產者哪裡設定開啟了confirm模式之後，每次寫的訊息都會分配一個唯一的id，然後如何寫入了rabbitmq之中，rabbitmq會給你回傳一個ack訊息，告訴你這個訊息傳送OK了；

    - ###### 如果rabbitmq沒能處理這個訊息，會回撥你一個nack介面，告訴你這個訊息失敗了，你可以進行重試。而且你可以結合這個機制知道自己在記憶體裡維護每個訊息的id，如果超過一定時間還沒接收到這個訊息的回撥，那麼你可以進行重發。

    - ```C#
      //開啟confirm
         channel.confirm();
         //傳送成功回撥
         public void ack(String messageId){
           
         }
       
         // 傳送失敗回撥
         public void nack(String messageId){
             //重發該訊息
         }
      ```

    - ###### 一條訊息從生產者傳送到RabbitMQ，首先會傳送到Exchange，對應回撥函式confirm()。第二步從Exchange路由分配到Queue中，對應回撥函式則是returnedMessage()。

    - ![在這裡插入圖片描述](https://i.iter01.com/images/3d2ef089a55d0514f1df535615e0ef3ee2f54bb81790154fc6e6d05ed518ab97.png)

    - 

- ##### rabbitmq自己弄丟了資料

  - ###### 建立queue的時候將其設定為持久化的，這樣就可以保證rabbitmq持久化queue的後設資料，但是不會持久化queue裡面的資料。

  - ###### 傳送訊息的時候將訊息的deliveryMode設定為2，這樣訊息就會被設為持久化方式，此時rabbitmq就會將訊息持久化到磁碟上。 必須要同時開啟這兩個才可以。

  - ###### 而且持久化可以跟生產的confirm機制配合起來，只有訊息持久化到了磁碟之後，才會通知生產者ack，這樣就算是在持久化之前rabbitmq掛了，資料丟了，生產者收不到ack回撥也會進行訊息重發。

- ##### 消費者弄丟了資料

  - ###### 消費者從佇列中獲取到訊息後，會直接確認簽收，假設消費者當機或者程式出現異常，資料沒有正常消費，這種情況就會出現資料丟失。所以關鍵在於把自動簽收改成手動簽收，正常消費則返回確認簽收，如果出現異常，則返回拒絕簽收重回佇列。

  - ###### 使用rabbitmq提供的ack機制，首先關閉rabbitmq的自動ack，然後每次在確保處理完這個訊息之後，在程式碼裡手動呼叫ack。這樣就可以避免訊息還沒有處理完就ack

- ![在這裡插入圖片描述](https://i.iter01.com/images/2220f787e989be7a83cb9ed41cc223b6b8b4a8a0bcaec5fb41a22c9a5eb36469.png)

### Net Core Example

- ##### 安裝MQ

  - ###### 安裝Rabbit時需要同時安裝erlang語言執行環境、RabbitMQ

  - ###### 可以直接透過`Chocolatey` 同步安裝 erlang、MQ

    - `choco install rabbitmq`

- ##### Net Core

  - ###### 安裝套件 `RabbitMQ.Client`

  - ###### 建立Producer

    - ```C#
      const string QUEUENAME = "Tesrt2";
                  //建立連線物件工廠
                  var factory = new ConnectionFactory()
                  {
                      UserName = "admin",
                      Password = "admin",
                      HostName = "localhost",
                      Port = 5672,  //RabbitMQ預設的埠
                  };
      
                  while (true)
                  {
                      using var conn = factory.CreateConnection();
                      var chanel = conn.CreateModel();
      
                      chanel.QueueDeclare(QUEUENAME, true, false, false);
                      chanel.BasicPublish("", QUEUENAME, null, Encoding.Default.GetBytes("hello rabbitmq:"));
                  }
      ```

  - ###### 建立Consumer

    - ```C#
      const string QUEUENAME = "Tesrt2";
      var factory = new ConnectionFactory()
      {
          UserName = "admin",
          Password = "admin",
          HostName = "localhost",
          Port = 5672,
      };
      
      var conn = factory.CreateConnection();
      var chanel = conn.CreateModel();
      chanel.QueueDeclare(QUEUENAME, true, false, false);
      EventingBasicConsumer consumer = new EventingBasicConsumer(chanel);
      
      //持續監聽QUEUE的內容，若有更新會持續接收直到關閉
      consumer.Received += (a, e) =>
      {
          Console.WriteLine($"{DateTime.Now.ToString()}接收到訊息:" + Encoding.Default.GetString(e.Body.ToArray()));
          chanel.BasicAck(e.DeliveryTag, true); //收到回覆後，RabbitMQ會直接在佇列中刪除這條訊息
      };
      chanel.BasicConsume(QUEUENAME, false, consumer);
      ```



# gRPC

- ##### RPC 的全名是 remote procedure call，主要是作為電腦和電腦間溝通使用。

  - ###### A 電腦可以呼叫 B 電腦執行某些程式，B 電腦會將結果回傳給 A 電腦，A 電腦在收到回應後會再繼續處理其他任務。

  - ###### RPC 的好處在於，雖然 A 電腦是發送請求去請 B 電腦做事，但其呼叫的方式，就很像是 A 電腦直接在呼叫自己內部的函式一般。

- ##### gRPC 也是基於這樣的概念，讓想要呼叫 server 處理請求的 client，在使用這支 API 時就好像是呼叫自己內部的函式一樣簡單自然

  - ###### gRPC 就像 Web 常用的 Restful API 一樣，都是在處理請求和回應，並且進行資料交換，但 gRPC 還多了其他的功能和特色。

- ##### gRPC 是由 Google 開發的開源框架，它快速有效、奠基在 HTTP/2 上提供低延遲（low latency），支援串流，更容易做到權限驗證（authentication）。

- ##### 四種 gRPC 的傳輸方式:

  - ###### 單向傳輸(Unary): Client 單向，Server 單向 客戶端發送一個請求並獲取一個響應。

  - ###### Server 單向串流(Streaming-Server): Client 單向，Server 串流 從客戶端獲取請求後，伺服器將響應流發送回去。

  - ###### Client 單向串流(Streaming-Client): Client 串流，Server 單向 客戶端發送一系列消息，等待服務器對其進行處理並收到單個響應。

  - ###### 雙向串流(Streaming-Bidirectional): Client 串流，Server 串流 客戶端和服務器在兩個方向上交換訊息。

## Protocol Buffers

- ##### 在傳統的 Restful API 中，最常使用的資料交換格式通常是 JSON；但到了 gRPC 中，資料交換的格式則是使用名為 [Protocol Buffers](https://developers.google.com/protocol-buffers/docs/overview) 的規範／語言。

  - ###### 當我們想要使用 gRPC 的服務來交換資料前，必須先把資料「格式」和「方法」都定義清楚。

  - ###### Message: 定義資料結構及屬性型別

  - ![img](https://camo.githubusercontent.com/4eb1a534787b679543e7eb36ab74b5ae0fb48d01bfde6c3d708b60880996f84c/68747470733a2f2f692e696d6775722e636f6d2f6f58324b6e54502e706e67)

- #####  使用 gRPC 前，不只需要先把資料交換的格式定義清楚，同時也需要把資料交換的方法定義清楚。

  - ###### Services: 定義方法

  - ```go
    syntax = "proto3";  // 定義要使用的 protocol buffer 版本
    
    //定義所屬package
    package calculator;  // for name space
    option go_package = "proto/calculator";  // generated code 的 full Go import path
    
    message CalculatorRequest {
      int64 a = 1;
      int64 b = 2;
    }
    
    message CalculatorResponse {
      int64 result = 1;
    }
    
    //定義API interface
    service CalculatorService {
      rpc Sum(CalculatorRequest) returns (CalculatorResponse) {};
    }
    ```

##  gRPC 與 HTTP API 比較

- ###### gRPC 訊息是使用 [Protobuf](https://developers.google.com/protocol-buffers/docs/overview)序列化，這是一種有效率的二進位訊息格式。 Protobuf 會在伺服器和用戶端上非常快速地序列化。 Protobuf 序列化會導致小型訊息承載，在行動裝置應用程式等有限頻寬案例中很重要。

- ###### 文件即是程式結構，程式內不用另外寫object mapping資料

- ###### 文件透過binary直接轉譯成程式，支援多種語言

- ###### 資料會經過protobuf編碼，人類無法直接看懂資料，安全性相較於JSON較高（但同時也是缺點，因為人看不懂）

| 特徵               | gRPC                                                         | 使用 ON 的 JS HTTP API        |
| :----------------- | :----------------------------------------------------------- | :---------------------------- |
| 合約               | 必要 (`.proto`)                                              | 選擇性 (OpenAPI)              |
| 通訊協定           | HTTP/2                                                       | HTTP                          |
| Payload            | [Protobuf (小型二進位)](https://docs.microsoft.com/zh-tw/aspnet/core/grpc/comparison?view=aspnetcore-6.0#performance) | JSON (大型、人類可讀)         |
| 規範性             | [嚴格規格](https://docs.microsoft.com/zh-tw/aspnet/core/grpc/comparison?view=aspnetcore-6.0#strict-specification) | 鬆散。 任何 HTTP 都是有效的。 |
| 串流               | [用戶端、伺服器、雙向](https://docs.microsoft.com/zh-tw/aspnet/core/grpc/comparison?view=aspnetcore-6.0#streaming) | 用戶端、伺服器                |
| 瀏覽器支援         | [不需要 grpc-web) (](https://docs.microsoft.com/zh-tw/aspnet/core/grpc/comparison?view=aspnetcore-6.0#limited-browser-support) | 是                            |
| 安全性             | 傳輸 (TLS)                                                   | 傳輸 (TLS)                    |
| 用戶端程式代碼產生 | [是](https://docs.microsoft.com/zh-tw/aspnet/core/grpc/comparison?view=aspnetcore-6.0#code-generation) | OpenAPI + 協力廠商工具        |

## Net Core 

1. ##### 建立`gRPC` Server專案

   - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207021842168.png)

2. 點選專案內`Protos`資料夾，並新增Protoco Buffer File

   - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207021844289.png)

3. 編輯檔案內容

   - 建立 `回傳格式`及 `方法`

   - ```
     syntax = "proto3";
     
     option csharp_namespace = "Discount.Grpc.Protos";
     
     service DiscountProtoService {
     
     	rpc GetDiscount (GetDiscountRequest) returns (CouponModel);
     
     	rpc CreateDiscount (CreateDiscountRequest) returns (CouponModel);
     	rpc UpdateDiscount (UpdateDiscountRequest) returns (CouponModel);
     	rpc DeleteDiscount (DeleteDiscountRequest) returns (DeleteDiscountResponse);	  
     }
     
     message GetDiscountRequest {
       string productName = 1;
     }
     
     message CouponModel {
     	int32 id = 1;
     	string productName = 2;
     	string description = 3;
     	int32 amount = 4;
     }
     ```

4. 新增`Service`繼承xxxProtoService的類別並實作內容

   - 步驟3 新增完後，會自動產生`xxxProtoService`類別(ex.`discount.proto`產生DiscountProtoService)

   - 實作所有.proto內定義的方法

   - ```C#
     public class DiscountService : DiscountProtoService.DiscountProtoServiceBase
       {
           private readonly IDiscountRepository _repository;
           private readonly IMapper _mapper;
           private readonly ILogger<DiscountService> _logger;
     
           public DiscountService(IDiscountRepository repository, IMapper mapper, ILogger<DiscountService> logger)
           {
               _repository = repository ?? throw new ArgumentNullException(nameof(repository));
               _mapper = mapper ?? throw new ArgumentNullException(nameof(mapper));
               _logger = logger ?? throw new ArgumentNullException(nameof(logger));
           }
     
           public override async Task<CouponModel> GetDiscount(GetDiscountRequest request, ServerCallContext context)
           {
               var coupon = await _repository.GetDiscount(request.ProductName);
               if (coupon == null)
               {
                   throw new RpcException(new Status(StatusCode.NotFound, $"Discount with ProductName={request.ProductName} is not found."));
               }
               var couponModel = _mapper.Map<CouponModel>(coupon);
               return couponModel;
           }
     ```

5. 在`Startup.cs` > `Configure`內新增Service Mapping

   - ```C#
     public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
            {
                app.UseEndpoints(endpoints =>
                {
                    endpoints.MapGrpcService<DiscountService>();
      
                    endpoints.MapGet("/", async context =>
                    {
                        await context.Response.WriteAsync("Communication with gRPC endpoints must be made through a gRPC client. To learn how to create a client, visit: https://go.microsoft.com/fwlink/?linkid=2086909");
                    });
                });
     ```

6. 使用gRPC in Client

   1. 在要使用的專案新增參考

      - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207021854787.png)
      - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207021855588.png)
      - ![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202207021856221.png)

   2. 以上步驟建立完後，會產生`Protos`資料夾

   3. 在`Startup.cs` > `ConfigureServices`內新增設定

      - ```C#
        public void ConfigureServices(IServiceCollection services)
        {
            services.AddGrpcClient<DiscountProtoService.DiscountProtoServiceClient>
                (o => o.Address = new Uri(Configuration["GrpcSettings:DiscountUrl"]));
        }
        ```

   4. 用`DiscountProtoService.DiscountProtoServiceClient _discountProtoService` 即可呼叫gRPC服務

      - ```C#
        private readonly DiscountProtoService.DiscountProtoServiceClient _discountProtoService;
        
        public DiscountGrpcService(DiscountProtoService.DiscountProtoServiceClient discountProtoService)
        {
            _discountProtoService = discountProtoService ?? throw new ArgumentNullException(nameof(discountProtoService));
        }
        
        public async Task<CouponModel> GetDiscount(string productName)
        {
            var discountRequest = new GetDiscountRequest { ProductName = productName };
        
            return await _discountProtoService.GetDiscountAsync(discountRequest);
        }
        ```

## 參考

- [BESG gRPC](https://www.youtube.com/watch?v=MYmPY1E17ZM&t=11s)



- 



# Load Balance

- ###### Server Load Balance（SLB）是最早發展的一塊，其功能在於將企業內多部伺服器的負載量作平衡，將過大流量轉向相同功能的其他伺服器，讓每一部伺服器工作量維持平均，保持服務不因流量過大而變慢或中斷。SLB主要應用在入口端的網頁分流，透過SLB轉址到各個伺服器，平均分配網路流量。

- ###### 假設今天開了五台機器，我們希望能夠分流這 1000 人的需求，但不可能讓 DNS 同時對到五台機器，所以在架構上，必須在這五台機器之前架設一台 load balance 的機器來做分流。設定時有幾個重點

  1. 設定後端機器的IP，這樣Load Balance才知道要管理那幾台機器。
  2. 設定判斷後端機器是否正常的方法。通常有幾種方式來判斷後端的機器是否處於正常服務狀態，例如透過SSH、HTTP(S)等，來判斷後端是否是處於一個正常狀態。在Web開發時，建議使用HTTP(S)方式來判斷，畢竟機器正常（SSH可連入），不代表我們的Server程式也正常（HTTP可連入）。因應檢測結果，不正常的後端機器，Load Balance會將其排除於服務外，並持續檢測，直到判斷為正常後，再重新加入到服務內。
  3. HTTPS的設定，因為HTTPS不單單是放在後端機器了，所以在Load Balance上，也必需針對HTTPS做設定。
  4. 設定分流的基準，可以用CPU或記憶體的用量（usage），來判斷這台後端機器是否是忙錄，決定要不要將使用者導向這台後端機器。

  

- ![Untitled.png](https://lh3.googleusercontent.com/p09zvycU01_6-rqqBVtTcn_csWuIc0J7UJ8_iCxsM9yFtT3wTvxk_y6ozXYUz2ElM5VVURogGoqmw1wJSI1wm7hPANT9WXombRGYTTjkRTP6fkzELG88eZg7tpP3Rinh13CvmZnq)

- ##### 實現策略

  - ##### 均勻派發(Even Task Distribution Scheme)

    - ###### 任務將均勻地派發到所有的伺服器進程。在實現時，可以使用隨機派發或者輪流派發(Round Robin)。實際上，由於進程部署環境的不同，其處理能力一般不同，任務處理時間也不盡相同。因此均勻派發的策略並不能很好地將任務負載均灘到各個進程中

    - ![img](http://i2.kknews.cc/uu0tUfeXFOAoHvmLCz4qoITdy_VYztv62VR6bzU/0.jpg)

  - ##### 加權派發(Weighted Task Distribution Scheme)

    - 賦予伺服器進程一個權值，即不同的進程會接受不同數量的任務，具體數量為權值確定。

    - ###### 例如，三個進程的處理任務的能力比率為3:3:2，那麼可以賦予這三個進程3:3:2的權值，即每8個任務中，3個發派給第一個進程，3個發派給第二個進程，2個分派給第三個進程。

    - ![img](http://i1.kknews.cc/v0O0M9oaV7uUDso_XGKRTbjEKcSWKcC-Gf8MRf0/0.jpg)

  - ##### 粘滯會話(Sticky Session Scheme)

    - ###### 前面兩種負載均衡策略並沒有考慮任務之間的依賴關係，在實際中，後面的任務處理常常會依賴於前面的任務。

    - ###### 例如，對於同一個登錄的用戶的請求，用戶購買的請求依賴於用戶登錄的請求，如果用戶的登錄信息保存在進程1中，那麼，如果購買請求被分派到進程2或者進程3，那麼購買請求將不能正確處理。這種請求間的依賴關係也稱為粘滯會話(Sticky Session)，負載均衡策略需要考慮粘滯會話的情況。

    - ![img](http://i1.kknews.cc/p66WWuXWi4C4XQFU_HZheEFM9JgWDBKT4QhFGJg/0.jpg)

    - ###### 粘滯會話的另一種處理策略是使用資料庫或者緩存，將所有會話數據存儲到資料庫或者緩存中。集群內所有進程都可以通過訪問資料庫或者緩存來獲取會話數據，進程內存都不保存會話數據，這樣，負載均衡器便可以使用前面介紹的策略來派發任務。

  - ##### 均勻任務隊列派發(Even Size Task Queue Distribution Scheme)

    - ###### 在均勻隊列派發策略下，負載均衡器為每個進程都創建一個大小相等的任務隊列，這些任務隊列包含了對應進程需要處理的任務。任務處理快的進程，其隊列也會減少得快，這樣負載均衡器會派發更多的任務給這個進程;相應地，任務處理慢的進程，其隊列也會減少得慢，這樣負載均衡器會派發更少的任務給這個進程。因此，通過這些任務隊列，負載均衡器在派發任務時將進程處理任務的能力因素考慮了進去。

    - ![img](http://i1.kknews.cc/DTiF0vP8KA8E6qdEK2uyACziS-85ZksxEuXlb0I/0.jpg)

  - #####  單一隊列(Autonomous Queue Scheme)

    - ###### 單一隊列策略中，實際上並沒有負載均衡器的存在。所有的伺服器進程從隊列中取出任務執行，如果某個進程出現宕機的情況，那麼其他進程仍然可以繼續執行任務。這樣一來，任務隊列並不需要知道服務進程的情況，只需要服務進程知道自己的任務隊列，並不斷執行任務即可。

    - ###### 單一隊列策略實際上也考慮到進程的處理能力，進程處理任務得越快，其從隊列取出任務的速度也越快。

    - ![img](http://i2.kknews.cc/CIterf9UhogBtAHZUKbtNclQ7DQq6SvV0Z1RNlU/0.jpg)

- ##### 作法

  - ##### persistence

    - ###### 通常我們在寫程式時，都是以使用者會連到同一台機器上來撰寫的，正常來說，當這個使用者的 session 存在時，我們會將他導到同一台機器，直到 session 失效。

      - ###### 這種分流會遇到的問題是：當服務請求變的更大時，我們加開的機器，並不會將原本的使用者分流過來，假設目前已經有 1000 人在前面五台機器上，這時候你開了第六台，前面的 1000 人並不會被分流過來，而是第 1001 人才會。

      - ###### 也因為 session 都在固定的機器上，如果今天使用者的 session 在第二台機器上，當第二台機器發生故障被導向第四台的時候，則使用者會被重新登入報錯

  - ##### affinity

    - ###### 根據機器的忙碌程度來決定將使用者導向何處。

      - ###### 那這種作法一樣會有問題發生，例如有使用者透過第一台機器登入了，但因為分流機制將第二個查詢動作給了第五台機器，那第五台機器沒有這個使用者的 session，也就會查不到資料了。很明顯的，各機器有各自的 session，如果要解決這個問題，就必須設計共有的 session 機制。

  - ##### Cluster

    - ###### 可以將多台 server 連在一起，通常要看使用的伺服器有沒有這個功能，一般來說依照設定就可以完成，也因為叢級功能基本上就有「共用 session」的功能了。

    - ###### 也可以用第三方服務來設計「共用 session」，比方 Memcached、AWS dynamoDB。

 



#  API Getway

- ##### 微服務架構中的唯一入口，它提供一個單獨且統一的API入口用於訪問內部一個或多個API。

- 具有**身份驗證，監控，負載均衡，快取，請求分片與管理**，靜態響應處理等

- ##### API閘道器方式的核心要點是，所有的客戶端和消費端都通過統一的閘道器接入微服務，在閘道器層處理所有的非業務功能

- ##### 通常，閘道器也是提供REST/HTTP的訪問API。服務端通過API-GW註冊和管理服務。

## **Ocelot**

- ##### 用.NET Core實現並且開源的API閘道器，它功能強大，包括了：路由、請求聚合、服務發現、認證、鑑權、限流熔斷、並內建了負載均衡器與Service Fabric、Butterfly Tracing整合。

- **工作流程**

  - **基本整合**

    - ######  根據configuration.json中配置內容，把接收所有的客戶端請求，路由到對應的下游伺服器進行處理，再將請求結果返回。而這個上下游請求的對應關係也被稱之為路由。

    - ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/91882e5808b330a088525cb2ff2d4c99d8b471d70dc895f9c6c079277aa86ad3.png)

  -  **整合IdentityServer**

    - ###### 當我們涉及到授權認證的時候，我們可以跟Identity Server進行結合。當閘道器需要請求認證資訊的時候會與Identity Server伺服器進行互動來完成。

    - ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/11ab960e17a64720aaeb26a4a55b9dab00108b48c2d425cde0e251358f2a4562.png)

  - **閘道器叢集配置**

    - ###### 可以部署多臺Ocelot閘道器。當然這個時候在多臺閘道器前，你還需要一臺負載均衡器

    - ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/03dfb62b8d55f9c65f89594b4b28785a720130593bcb2ea0562470df4671599e.png)

  - ##### 結合Consul服務發現

    - ###### Ocelot已經支援簡單的負載功能，當下遊服務存在多個結點的時候，Ocelot能夠承擔起負載均衡的作用。但是沒提供健康檢查，服務的註冊也只能通過手動在配置檔案裡面新增完成。這不夠靈活並且在一定程度下會有風險。這個時候我們就可以用Consul來做服務發現，它能與Ocelot完美結合。

    - ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/43971b816c33ad6d9fd39e5b0766ca6ab9b4bf892a1ffadb24079f527cb0445d.png)

  - ##### 結合Service Fabric

    - ![.NET Core 微服務—API閘道器(Ocelot) 教程 [一]](https://i.iter01.com/images/640d4efeb9194ffb891b1025be49f34c9ef0834dc5051f2885cbc99ee7810419.png)

  - 

