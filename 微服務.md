# Docker

## 基本概念

### Docker Daemon

- ###### Docker Client通过命令与Docker Damon通信，完成Docker相关操作。Daemon的主要功能包括镜像管理、镜像构建、REST API、身份验证、安全、核心网络以及编排。

### IMAGE

- ###### Docker 映像檔就是一個唯讀的模板

- ###### 例如：一個映像檔可以包含一個完整的 ubuntu 作業系統環境，裡面僅安裝了 Apache 或使用者需要的其它應用程式。

- ###### 映像檔可以用來建立 Docker 容器。

- ###### Docker 提供了一個很簡單的機制來建立映像檔或者更新現有的映像檔，使用者甚至可以直接從其他人那裡下載一個已經做好的映像檔來直接使用。

### Container	

- ###### Docker 利用容器來執行應用

- ###### 容器是從映像檔建立的執行實例。它可以被啟動、開始、停止、刪除。每個容器都是相互隔離的、保證安全的平台。

- ###### 可以把容器看做是一個簡易版的 Linux 環境（包括root使用者權限、程式空間、使用者空間和網路空間等）和在其中執行的應用程式。

- ###### 映像檔是唯讀的，容器在啟動的時候建立一層可寫層作為最上層

- ##### 狀態

  - ###### Exited表示container暫時性地被關閉，並且不會在使用環境的任何資源，下次再啟動時，必須重新執行該container。
  
  - ###### Paused表示container暫時性地被暫停，但依舊會使用著環境資源(memories)，下次在unpause同時，會從上次暫停的地方繼續執行。
  
  - ![https://ithelp.ithome.com.tw/upload/images/20200919/20129737XZeelnsEOj.png](https://ithelp.ithome.com.tw/upload/images/20200919/20129737XZeelnsEOj.png)
  
    
  

### Registry



### Docker Volume

- ![img](https://myapollo.com.tw/images/docker-volumes/volume-types.png)

- ###### 讓 Docker Container 保存與共用資料的機制，原本 Docker Container 的資料只會存在該 container 內，並不會與外部或是其他 container 共享，如果在 container 運作時新增了一些資料，而在 container 移除時又沒有將該 container commit 成 image，則當 container 被刪除時，資料就會遺失。

- ###### 要避免資料遺失，就可以使用 Docker Volume。你可以建立一個 volume，將它指定到 container 內的某個目錄，這樣該目錄的資料就可以永續保存著，不會因為 container 移除而被移除。

- ##### Docker實現Volume的原理

  - ###### Volume: Container將Volume存放在Docker area，以Linux來說預設為Var/lib/docker/volume。

  - ###### BindMount: 可以為主機路徑下任何地方。

  - ###### tmpfsMount:主機的memory。



## 基本操作

### [Docker Hub](https://hub.docker.com/_/mysql)

- 倉庫是集中存放映像檔檔案的場所。有時候會把倉庫和倉庫註冊伺服器（Registry）混為一談，並不嚴格區分。實際上，倉庫註冊伺服器上往往存放著多個倉庫，每個倉庫中又包含了多個映像檔，每個映像檔有不同的標籤（tag）。
- 倉庫分為公開倉庫（Public）和私有倉庫（Private）兩種形式
- 當使用者建立了自己的映像檔之後就可以使用 `push` 命令將它上傳到公有或者私有倉庫，這樣下次在另外一台機器上使用這個映像檔時候，只需要從倉庫上 `pull` 下來就可以了。
- Docker 倉庫的概念跟 [Git](http://git-scm.com/) 類似，註冊伺服器可以理解為 GitHub 這樣的託管服務。

### Search Image

- ###### `docker search mysql`

### Pull Image

- ###### `docker pull mysql`

### List Image

- ###### `docker images`

### Build Image

- ```powershell
  # ImageName 需小寫
  # 須注意 Dockerfile 的路徑
  docker build -t [ImageName]:[Tag] -f [Dockerfile Name] .
  
  #1. 準備好DockerFile
  #2. 建立image
      # 啟動 Powershell 或 cmd
      # 移至專案 Dockerfile 所在位置的上層資料夾
      # 執行 Docker build 指令, 建立 Image, 參考指令如下
      # -t: Image 名稱及 Tag
      # -f: Dockerfile 檔案路徑
   注意：確保在名稱後面放置一個空格和句點 - 很容易錯過！
   
   docker build -t icw_biosecurity_api:latest -f .\ICW.BioSecurity.Api\Dockerfile .
    
  #OR直接到DockerFile那層
  
  docker build -t icw_biosecurity_api:latest .
  
  ```

### Remove Image

- ```powershell
  docker rmi [ImageID]
  docker image rm [ImageID]
  docker rmi [ImageName]:[Tag]
  
  # remove all images
  docker rmi $(docker images -q) -f
  
  # remove all none images (None Image 是在 build 過程中產生)
  docker rmi $(docker images -f "dangling=true" -q)
  ```

### Run Container

- ```powershell
  # icw 代表Container Name
  # icw_cloud代表Image Name
  # -it: 啟動互動式容器
  # --rm: exit 後刪除 container
  # -p: Port 對應 [外部 IP]:[內部 IP] (可設立多個 mapping)
  # -d: 背景執行
  # docker run  -p  -d [外部 ip]: [內部 ip] --name [容器名稱] [RepositoryName]:[Tag]
  docker run -d -p  8096:80 --name icw icw_cloud
  ```

### List Container

- ```powershell
  docker container ls
  # show all container (includes stopped container)
  docker container ls -all
  docker ps
  ```

### Stop Container

- ```powershell
  docker stop $(docker ps -a -q)
  
  docker stop <CONTAINER ID>
  ```

### Remove Container

- ```powershell
  # remove all stopped container
  docker container prune
  # remove container by container id
  docker container rm [ContainerID]
  # remove ALL
  docker rm $(docker ps -a -q)
  ```

  

## 微服務佈署流程說明

### 	1. 製作 Dockerfile 檔案

  * #### .net core

    ```powershell
    # https://hub.docker.com/_/microsoft-dotnet
    FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build
    ENV ASPNETCORE_ENVIRONMENT Stage
    EXPOSE 80
    WORKDIR /source
    
    # copy csproj and restore as distinct layers
    COPY *.sln .
    COPY Tool/*.csproj ./Tool/
    RUN dotnet restore
    
    # copy everything else and build app
    COPY Tool/. ./Tool/
    WORKDIR /source/Tool
    RUN dotnet publish -c release -o /app --no-restore
    
    # final stage/image
    FROM mcr.microsoft.com/dotnet/aspnet:5.0
    WORKDIR /app
    COPY --from=build /app ./
    ENTRYPOINT ["dotnet", "Tool.dll"]
    
    ```

  * #### Vue.js

    * ```powershell
      # build stage
      FROM node:lts-alpine as build-stage
      WORKDIR /app
      COPY package*.json ./
      RUN yarn install
      COPY . .
      RUN yarn build
      
      # production stage
      FROM nginx:stable-alpine as production-stage
      COPY --from=build-stage /app/dist /usr/share/nginx/html
      COPY default.conf /etc/nginx/conf.d/default.conf
      EXPOSE 80
      CMD ["nginx", "-g", "daemon off;"]
      ```


- default .conf是 vue佈署在Docker上面的時候因為 router history-Mode再 `nginx` 導頁會產生錯誤的解決方式

  - ```powershell
    server {
        listen       80;
        server_name  localhost;
    
      root   /usr/share/nginx/html;
    
      index index.html;
    
    
      location / {
        try_files $uri $uri/ @rewrites;
      }
    
      location @rewrites {
        rewrite ^(.+)$ /index.html last;
      }
    
      location ~* \.(?:ico|css|js|gif|jpe?g|png)$ {
        # Some basic cache-control for static files to be sent to the browser
        expires max;
        add_header Pragma public;
        add_header Cache-Control "public, must-revalidate, proxy-revalidate";
      }
    
    }
    ```


### 2. 建立 Image檔案

```powershell
docker build -t icw_cloud:latest .
```

### 3. 建立Container

```powershell
docker run -d -p  80:80 --name icw_cloud icw_cloud
```



````
# build stage

FROM node:lts-alpine as build-stage
WORKDIR /app
COPY package*.json ./
RUN yarn install
COPY . .
RUN yarn build

# production stage
FROM nginx:stable-alpine as production-stage
COPY --from=build-stage /app/dist /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```
````

2. 製作 Image

```powershell
# 啟動 Powershell 或 cmd
# 移至專案 Dockerfile 所在位置的上層資料夾
# 執行 Docker build 指令, 建立 Image, 參考指令如下
# -t: Image 名稱及 Tag
# -f: Dockerfile 檔案路徑

docker build -t icw_developer_identityserver:latest -f .\ICW.Developer.IdentityServer\Dockerfile .
# example
# docker build -t icw_dev_id4svr:v1.0.19060301 -f .\ICW.Developer.IdentityServer\Dockerfile .
```

3. Push 至私人註冊所

   ```powershell
   docker tag [ImageName] [DockerUserID]/[ImageName]:[Tag]
   # example
   # docker tag icw_dev_id4svr:v1.0.19060301 192.168.1.102:5000/icw_dev_id4svr:v1.0.19060301
   
   docker push [ImageName]
   # example
   # docker push 192.168.1.102:5000/icw_dev_id4svr:v1.0.19060301
   ```

4. 至遠端主機啟動 container

   ```powershell
   # 方法一. 使用 docker run
   docker pull [ImageName]
   docker run --name [容器名稱] -p [外部 ip]: [內部 ip] -d --rm [RepositoryName]:[Tag]
   
   # 方法二. 使用 Docker-compose
   docker-compose up -d
   ```


## MySql 安裝

```powershell
docker search mysql

docker pull mysql
# docker run --name [MySql 名稱] -e MYSQL_ROOT_PASSWORD=my-password -d -p 3306:3306 mysql
# MYSQL_ROOT_PASSWORD = root 的密碼
docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d -p 3306:3306 mysql
```

## Private registry 安裝

### Crceate private registry

```powershell
# 下載 registry image
docker pull registry
# 建立 container
# ex: docker run --name [私人註冊庫名稱] -p [外部 IP]:[內部 IP] -v [實體檔案路徑]:[Container 路徑]
docker run --name icw-registry --restart always -p 5000:5000 -v D:/docker/registry:/var/lib/registry -d registry

# 建立 WebUI 管理介面
# docker run -d -p 8080:8080 --name registry-web --link [Name] -e REGISTRY_URL=http://[IP]:5000/v2 hyper/docker-registry-web
docker run -d -p 8080:8080 --name registry-web --link icw-registry -e REGISTRY_URL=http://192.168.1.177:5000/v2 hyper/docker-registry-web

# 需開啟防火牆 Port: 5000, 8080
```



# Kubernetes 

## Install Kubernetes on windows 10

- 

- ###### 參考文章

  - [How to install Kubernetes on windows 10](https://github.com/twtrubiks/k8s-tutorial/tree/master/How_to_install_k8s_on_win10)
  - [Minikube 安裝與配置](https://ithelp.ithome.com.tw/articles/10192490)
  - [Kubernetes - minikube (輕鬆建立本地端的 K8S 集群工具) 安裝教學](https://blog.kennycoder.io/2020/03/15/Kubernetes-minikube-%E8%BC%95%E9%AC%86%E5%BB%BA%E7%AB%8B%E6%9C%AC%E5%9C%B0%E7%AB%AF%E7%9A%84K8S%E9%9B%86%E7%BE%A4%E5%B7%A5%E5%85%B7-%E5%AE%89%E8%A3%9D%E6%95%99%E5%AD%B8/)



## 基本介紹

### 主要架構

​	

![img](https://raw.githubusercontent.com/Sean2416/Pic/master/img/202206152030525.png)

![https://ithelp.ithome.com.tw/upload/images/20201001/20129737wF5PKYvbLN.png](https://ithelp.ithome.com.tw/upload/images/20201001/20129737wF5PKYvbLN.png)

- #### Master Node

  - ##### Master Node主要用來管理Work Node(也就是Slave Node, Kubernetes Node)，進行工作的調配與規劃..等

    - ###### 取得master node components的狀態 `kubectl get componentstatuses`

    - ###### Get components detail `kubectl describe componentstatuses controller-manager`

  - ##### ETCD

    - ###### 每個Cluster都會有著一個以上的etcd，etcd用一致且高可用的鍵值方式儲存Kubernetes叢集的資料，Kubernetes Cluster會預設將etcd資料作為備份

  - ##### API Server

    - ###### 透過API-Server對外曝露所有的Kubernetes API，亦可以把它當作是Kubernetes Control Plane的前端。而我們操作的Kubernetes ctl也是我們透過kubectl的方式與API-Server進行溝通

    - ###### API-Server有著以下幾個功能：

      - ###### 提供API讓使用者能夠取得叢集內部各資源資訊、創建/更改/移除 各資源或下達調度策略對各資源進行調配。

      - ###### 代理群集當中一些額外組件，像是Kubernetes UI、metrics-server..etc

      - ###### 創建Kubernetes server

      - ###### 讓資源進行版本更新

    - ###### 通過`kubectl proxy`得知目前叢集最上層的api path為何

  - ##### Kube-Controller Manager

    - ###### 負責管理並運行 Kubernetes controller 的組件，簡單來說 controller 就是 Kubernetes 裡一個個負責監視 Cluster 狀態的 Process，例如：Node Controller、Replication Controller

    - ###### 這些 Process 會在 Cluster 與預期狀態（desire state）不符時嘗試更新現有狀態（current state）。例如：現在要多開一台機器以應付突然增加的流量，那我的預期狀態就會更新成 N+1，現有狀態為 N，這時相對應的 controller 就會想辦法多開一台機器

    - ###### controller-manager 的監視與嘗試更新也都需要透過訪問 kube-apiserver 達成

      - ###### Node controller: 負責當Node出現故障時的訊息通知與增減

      - ###### Replication controller: 負責管理Pods數量與狀態，但現在使用ReplicaSet居多

      - ###### Endpoints controller: 負責生成與維護所有endppoints物件(such as service)

      - ###### Service Account & Token controllers: 負責管理用戶帳戶與服務

  - ##### Scheduler

    - ###### 整個 Kubernetes 的 Pods 調度員，scheduler 會監視新建立但還沒有被指定要跑在哪個 Node 上的 Pod，並根據每個 Node 上面資源規定、硬體限制等條件去協調出一個最適合放置的 Node 讓該 Pod 跑

    - ###### 依據機器資源、軟體資源(叢集)、調度決策、affinity and anti-affinity親和力與反親和力等多方考量，去決定Pods是否新建與Pods的數量分配(分配至Ｗorker Node)。因為每個Pods都會有自己的requirements(像是平均Memory用量超過50%新建、不建立該種Pod在Node-1上..等)，所以在叢集調度上並非易事，也因此有了該components的產生

    - ###### affinity又有分成是Node affinity與 Pod affinity，affinity也是屬於種調度策略

  - ##### 基本建置流程

    - ![img](https://miro.medium.com/max/1050/0*5N7SlevIHOdKB-yC)

    - ###### 上圖為一個簡易的 Kubernetes Cluster，通常一個 Cluster 中其實會有多個 Master 作為備援，但為了簡化我們只顯示一個

    - ###### 當使用者要部署一個新的 Pod 到 Kubernetes Cluster 時，使用者要先透過 User Command（kubectl）輸入建立 Pod 的對應指令（下面會在解說如何實際動手操作來建立一個 Pod）。

    - ###### 此時指令會經過一層確認使用者身份的認證後，傳遞到 Master Node 中的 API Server，API Server 會把指令備份到 etcd

    - ###### 接下來 controller-manager 會從 API Server 收到需要創建一個新的 Pod 的訊息，並檢查如果資源許可，就會建立一個新的 Pod。

    - ###### 最後 Scheduler 在定期訪問 API Server 時，會詢問 controller-manager 是否有建置新的 Pod，如果發現新建立的 Pod 時，Scheduler 就會負責把 Pod 配送到最適合的一個 Node 上面。

- ##### Kubernetes  Node

  - ##### Worker node是用來部署容器的地方，也就是運行服務的機器，所以每個Node中必備著能夠建置容器的執行環境，像是Docker等。

    - ###### Get all nodes `kubectl get nodes`

    - ###### Describe specific node `kubectl describe nodes <node_name>`

    - ##### Addresses

      - ###### HostName: 該節點的host name，可以透過kubectl —hostname-override 來覆寫他。

      - ###### ExternalIP: 該節點可路由的外部IP，提供群集外部使用。

      - ###### InternalIP: 該節點可路由的內部IP，僅叢集內部能夠路由。

    - ##### Conditions

      - 描述所有運行節點目前的狀態，狀態的描述有以下幾種：

      - |   Node Condition   |                         Description                          |
        | :----------------: | :----------------------------------------------------------: |
        |       Ready        | True表示節點運行狀況良好並準備好接受Pod，False表示節點運行狀況不佳並且不接受Pod，Unknown表示節點控制器最近一次未從節點收到消息node-monitor-grace-period（默認值為40秒） |
        |    DiskPressure    |             True表示磁盤容量不足；除此以外False              |
        |   MemoryPressure   |             True表示節點內存不足; 除此以外False              |
        |    PIDPressure     |          True表示節點上的Process太多；除此以外False          |
        | NetworkUnavailable |           True表示節點的網絡配置不正確，否則 False           |

    - ##### Capacity and Allocatable

      - ###### 描述該節點上可用資源最大數量，包含cpu、memory與pods的數量

    - ##### System Info

      - ###### 該節點上各種軟硬體設備的訊息，包含uuid與版本號....等

  - ##### Kubelet

    - ###### Kubernetes是一個分散式的集群管理系統，在每個worker 上運行一個worker process對node上的Container做周期性管理，而這個worker就是Kubelet。

    - ##### 主要功能

      - ###### Pod的管理: 如上述，一個pod由一或多個containers組成，彼此共享pod中的資源與port，所以同個pod間能透過localhost進行溝通，因此也可利用volume與mount將資源共享至多個容器當中，kubelet就是負責管理這些pod資源

      - ###### 健康檢查: 創建容器後，如果想確認容器是否正常啟動，可以加入health check在pod/deployment的yaml當中，再啟動pod時kubelet會去執行yaml中的health check，只要health check沒過kubelet就會刪除該pod並依照重啟策略處理(預設為刪除後不進行重啟)

      - ###### 容器監測: 透過建置cAdvisor進行監測。

  - ##### CAdvisor

    - ###### cAdvisor是一個worker，並即時性的對該Node上所有的資源與容器進行監測與數據的採集，像是CPU、Memory的用量、網路的流量與Storage的使用量等。cAdvisor集成於Kubelet當中，當使用Kubelet時會自動地啟動cAdvisor。

  - ##### Proxy

    - ![img](https://ithelp.ithome.com.tw/upload/images/20201002/20129737lEny7hhLuh.png)

    - ###### 每個pod都會有個ip，但pod是經常在發生變化的，每次更新ip位置都會有變。為此kubernetes有個component叫做**service**，每個service都會有一組**固定的虛擬ip(clusterIp)**，並且自動地綁定某種類型的pod，有點類似某種pod的專用通道，所有對於該類型pod的request都會透過service進行load balance與redirect。為了實現該功能，在每個Node上都會有個Kube-Proxy，得以當作service, api-server與pod間溝通的橋樑。

  - ##### POD

    - ![img](https://miro.medium.com/max/872/1*Hvc0M9UutuTBNQoMRHMkAw.png)

    - ##### Pod是在kubernetes當中，能夠創建與運行的最小執行單位，在Pod當中能夠有著一個或多個Containers，並且這些Containers共享著Pod的資源

      - ##### Pod有以下特點

        - ###### 每個 Pod 都有屬於自己的 [yaml](https://zh.wikipedia.org/wiki/YAML) 檔

        - ###### 一個 Pod 裡面可以包含一個或多個 Docker Container

        - ###### 在同一個 Pod 裡面的 containers，可以用 **local port numbers** 來互相溝通
    
    - ##### 建立Pod

- **Service** 

  - ![img](https://miro.medium.com/max/872/1*56YXHMCke33F7J-SCPus5g.png)

  - ###### **Service 是永久的 IP Address**

  - ###### **Service 是 load balancer：**當發生 Replication 時，Service 會自動導流到比較空閑的 Application。（後面講 Deployment 的時候會再提到，可以先想像我們複製了一個 my-app，以防原本的 my-app 壞掉，而這兩個 my-app 都指向同一個 Service，Service 會導流到相對空閑的 my-app）

  - ###### **Pod 跟 Service 的生命週期是分開的**

- ##### Ingress 





# Load Balance

- ###### Server Load Balance（SLB）是最早發展的一塊，其功能在於將企業內多部伺服器的負載量作平衡，將過大流量轉向相同功能的其他伺服器，讓每一部伺服器工作量維持平均，保持服務不因流量過大而變慢或中斷。SLB主要應用在入口端的網頁分流，透過SLB轉址到各個伺服器，平均分配網路流量。

- ###### 假設今天開了五台機器，我們希望能夠分流這 1000 人的需求，但不可能讓 DNS 同時對到五台機器，所以在架構上，必須在這五台機器之前架設一台 load balance 的機器來做分流。設定時有幾個重點

  1. 設定後端機器的IP，這樣Load Balance才知道要管理那幾台機器。
  2. 設定判斷後端機器是否正常的方法。通常有幾種方式來判斷後端的機器是否處於正常服務狀態，例如透過SSH、HTTP(S)等，來判斷後端是否是處於一個正常狀態。在Web開發時，建議使用HTTP(S)方式來判斷，畢竟機器正常（SSH可連入），不代表我們的Server程式也正常（HTTP可連入）。因應檢測結果，不正常的後端機器，Load Balance會將其排除於服務外，並持續檢測，直到判斷為正常後，再重新加入到服務內。
  3. HTTPS的設定，因為HTTPS不單單是放在後端機器了，所以在Load Balance上，也必需針對HTTPS做設定。
  4. 設定分流的基準，可以用CPU或記憶體的用量（usage），來判斷這台後端機器是否是忙錄，決定要不要將使用者導向這台後端機器。

  

- ![Untitled.png](https://lh3.googleusercontent.com/p09zvycU01_6-rqqBVtTcn_csWuIc0J7UJ8_iCxsM9yFtT3wTvxk_y6ozXYUz2ElM5VVURogGoqmw1wJSI1wm7hPANT9WXombRGYTTjkRTP6fkzELG88eZg7tpP3Rinh13CvmZnq)

- ##### 實現策略

  - ##### 均勻派發(Even Task Distribution Scheme)

    - ###### 任務將均勻地派發到所有的伺服器進程。在實現時，可以使用隨機派發或者輪流派發(Round Robin)。實際上，由於進程部署環境的不同，其處理能力一般不同，任務處理時間也不盡相同。因此均勻派發的策略並不能很好地將任務負載均灘到各個進程中

    - ![img](http://i2.kknews.cc/uu0tUfeXFOAoHvmLCz4qoITdy_VYztv62VR6bzU/0.jpg)

  - ##### 加權派發(Weighted Task Distribution Scheme)

    - 賦予伺服器進程一個權值，即不同的進程會接受不同數量的任務，具體數量為權值確定。

    - ###### 例如，三個進程的處理任務的能力比率為3:3:2，那麼可以賦予這三個進程3:3:2的權值，即每8個任務中，3個發派給第一個進程，3個發派給第二個進程，2個分派給第三個進程。

    - ![img](http://i1.kknews.cc/v0O0M9oaV7uUDso_XGKRTbjEKcSWKcC-Gf8MRf0/0.jpg)

  - ##### 粘滯會話(Sticky Session Scheme)

    - ###### 前面兩種負載均衡策略並沒有考慮任務之間的依賴關係，在實際中，後面的任務處理常常會依賴於前面的任務。

    - ###### 例如，對於同一個登錄的用戶的請求，用戶購買的請求依賴於用戶登錄的請求，如果用戶的登錄信息保存在進程1中，那麼，如果購買請求被分派到進程2或者進程3，那麼購買請求將不能正確處理。這種請求間的依賴關係也稱為粘滯會話(Sticky Session)，負載均衡策略需要考慮粘滯會話的情況。

    - ![img](http://i1.kknews.cc/p66WWuXWi4C4XQFU_HZheEFM9JgWDBKT4QhFGJg/0.jpg)

    - ###### 粘滯會話的另一種處理策略是使用資料庫或者緩存，將所有會話數據存儲到資料庫或者緩存中。集群內所有進程都可以通過訪問資料庫或者緩存來獲取會話數據，進程內存都不保存會話數據，這樣，負載均衡器便可以使用前面介紹的策略來派發任務。

  - ##### 均勻任務隊列派發(Even Size Task Queue Distribution Scheme)

    - ###### 在均勻隊列派發策略下，負載均衡器為每個進程都創建一個大小相等的任務隊列，這些任務隊列包含了對應進程需要處理的任務。任務處理快的進程，其隊列也會減少得快，這樣負載均衡器會派發更多的任務給這個進程;相應地，任務處理慢的進程，其隊列也會減少得慢，這樣負載均衡器會派發更少的任務給這個進程。因此，通過這些任務隊列，負載均衡器在派發任務時將進程處理任務的能力因素考慮了進去。

    - ![img](http://i1.kknews.cc/DTiF0vP8KA8E6qdEK2uyACziS-85ZksxEuXlb0I/0.jpg)

  - #####  單一隊列(Autonomous Queue Scheme)

    - ###### 單一隊列策略中，實際上並沒有負載均衡器的存在。所有的伺服器進程從隊列中取出任務執行，如果某個進程出現宕機的情況，那麼其他進程仍然可以繼續執行任務。這樣一來，任務隊列並不需要知道服務進程的情況，只需要服務進程知道自己的任務隊列，並不斷執行任務即可。

    - ###### 單一隊列策略實際上也考慮到進程的處理能力，進程處理任務得越快，其從隊列取出任務的速度也越快。

    - ![img](http://i2.kknews.cc/CIterf9UhogBtAHZUKbtNclQ7DQq6SvV0Z1RNlU/0.jpg)

- ##### 作法

  - ##### persistence

    - ###### 通常我們在寫程式時，都是以使用者會連到同一台機器上來撰寫的，正常來說，當這個使用者的 session 存在時，我們會將他導到同一台機器，直到 session 失效。

      - ###### 這種分流會遇到的問題是：當服務請求變的更大時，我們加開的機器，並不會將原本的使用者分流過來，假設目前已經有 1000 人在前面五台機器上，這時候你開了第六台，前面的 1000 人並不會被分流過來，而是第 1001 人才會。

      - ###### 也因為 session 都在固定的機器上，如果今天使用者的 session 在第二台機器上，當第二台機器發生故障被導向第四台的時候，則使用者會被重新登入報錯

  - ##### affinity

    - ###### 根據機器的忙碌程度來決定將使用者導向何處。

      - ###### 那這種作法一樣會有問題發生，例如有使用者透過第一台機器登入了，但因為分流機制將第二個查詢動作給了第五台機器，那第五台機器沒有這個使用者的 session，也就會查不到資料了。很明顯的，各機器有各自的 session，如果要解決這個問題，就必須設計共有的 session 機制。

  - ##### Cluster

    - ###### 可以將多台 server 連在一起，通常要看使用的伺服器有沒有這個功能，一般來說依照設定就可以完成，也因為叢級功能基本上就有「共用 session」的功能了。

    - ###### 也可以用第三方服務來設計「共用 session」，比方 Memcached、AWS dynamoDB。

 